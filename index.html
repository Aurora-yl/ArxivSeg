<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2024-06-28T00:00:00Z">2024-06-28</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">88</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Web2Code: A Large-scale Webpage-to-Code <span class="highlight-title">Dataset</span> and Evaluation Framework
  for Multimodal LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20098v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20098v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sukmin Yun, Haokun Lin, Rusiru Thushara, Mohammad Qazim Bhat, Yongxin Wang, Zutao Jiang, Mingkai Deng, Jinhong Wang, Tianhua Tao, Junbo Li, Haonan Li, Preslav Nakov, Timothy Baldwin, Zhengzhong Liu, Eric P. Xing, Xiaodan Liang, Zhiqiang Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) have shown impressive success across
modalities such as image, video, and audio in a variety of understanding and
generation tasks. However, current MLLMs are surprisingly poor at understanding
webpage screenshots and generating their corresponding HTML code. To address
this problem, we propose Web2Code, a benchmark consisting of a new large-scale
webpage-to-code dataset for instruction tuning and an evaluation framework for
the webpage understanding and HTML code translation abilities of MLLMs. For
dataset construction, we leverage pretrained LLMs to enhance existing
webpage-to-code datasets as well as generate a diverse pool of new webpages
rendered into images. Specifically, the inputs are webpage images and
instructions, while the responses are the webpage's HTML code. We further
include diverse natural language QA pairs about the webpage content in the
responses to enable a more comprehensive understanding of the web content. To
evaluate model performance in these tasks, we develop an evaluation framework
for testing MLLMs' abilities in webpage understanding and web-to-code
generation. Extensive experiments show that our proposed dataset is beneficial
not only to our proposed tasks but also in the general visual domain, while
previous datasets result in worse performance. We hope our work will contribute
to the development of general MLLMs suitable for web-based content generation
and task automation. Our data and code will be available at
https://github.com/MBZUAI-LLM/web2code.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Website at https://mbzuai-llm.github.io/webpage2code/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLaRA: Supercharging Robot Learning Data for Vision-Language Policy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) equipped with extensive world knowledge and
strong reasoning skills can tackle diverse tasks across domains, often by
posing them as conversation-style instruction-response pairs. In this paper, we
propose LLaRA: Large Language and Robotics Assistant, a framework which
formulates robot action policy as conversations, and provides improved
responses when trained with auxiliary data that complements policy learning.
LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity
to process state information as visual-textual prompts and generate optimal
policy decisions in text. To train such action policy VLMs, we first introduce
an automated pipeline to generate diverse high-quality robotics instruction
data from existing behavior cloning data. A VLM finetuned with the resulting
collection of datasets based on a conversation-style formulation tailored for
robotics tasks, can generate meaningful robot action policy decisions. Our
experiments across multiple simulated and real-world environments demonstrate
the state-of-the-art performance of the proposed LLaRA framework. The code,
datasets, and pretrained models are available at
https://github.com/LostXine/LLaRA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Synthetic Data Creation with 1,000,000,000 Personas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20094v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20094v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel persona-driven data synthesis methodology that leverages
various perspectives within a large language model (LLM) to create diverse
synthetic data. To fully exploit this methodology at scale, we introduce
Persona Hub -- a collection of 1 billion diverse personas automatically curated
from web data. These 1 billion personas (~13% of the world's total population),
acting as distributed carriers of world knowledge, can tap into almost every
perspective encapsulated within the LLM, thereby facilitating the creation of
diverse synthetic data at scale for various scenarios. By showcasing Persona
Hub's use cases in synthesizing high-quality mathematical and logical reasoning
problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs
and tools (functions) at scale, we demonstrate persona-driven data synthesis is
versatile, scalable, flexible, and easy to use, potentially driving a paradigm
shift in synthetic data creation and applications in practice, which may have a
profound impact on LLM research and development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProgressGym: Alignment with a Millennium of Moral Progress 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20087v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20087v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Qiu, Yang Zhang, Xuchuan Huang, Jasmine Xinze Li, Jiaming Ji, Yaodong Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Frontier AI systems, including large language models (LLMs), hold increasing
influence over the epistemology of human users. Such influence can reinforce
prevailing societal values, potentially contributing to the lock-in of
misguided moral beliefs and, consequently, the perpetuation of problematic
moral practices on a broad scale. We introduce progress alignment as a
technical solution to mitigate this imminent risk. Progress alignment
algorithms learn to emulate the mechanics of human moral progress, thereby
addressing the susceptibility of existing alignment methods to contemporary
moral blindspots. To empower research in progress alignment, we introduce
ProgressGym, an experimental framework allowing the learning of moral progress
mechanics from history, in order to facilitate future progress in real-world
moral decisions. Leveraging 9 centuries of historical text and 18 historical
LLMs, ProgressGym enables codification of real-world progress alignment
challenges into concrete benchmarks. Specifically, we introduce three core
challenges: tracking evolving values (PG-Follow), preemptively anticipating
moral progress (PG-Predict), and regulating the feedback loop between human and
AI value shifts (PG-Coevolve). Alignment methods without a temporal dimension
are inapplicable to these tasks. In response, we present lifelong and
extrapolative algorithms as baseline methods of progress alignment, and build
an open leaderboard soliciting novel algorithms and challenges. The framework
and the leaderboard are available at
https://github.com/PKU-Alignment/ProgressGym and
https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20086v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20086v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheridan Feucht, David Atkinson, Byron Wallace, David Bau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs process text as sequences of tokens that roughly correspond to words,
where less common words are represented by multiple tokens. However, individual
tokens are often semantically unrelated to the meanings of the words/concepts
they comprise. For example, Llama-2-7b's tokenizer splits the word
"northeastern" into the tokens ['_n', 'ort', 'he', 'astern'], none of which
correspond to semantically meaningful units like "north" or "east." Similarly,
the overall meanings of named entities like "Neil Young" and multi-word
expressions like "break a leg" cannot be directly inferred from their
constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups
of tokens into useful higher-level representations? In this work, we find that
last token representations of named entities and multi-token words exhibit a
pronounced "erasure" effect, where information about previous and current
tokens is rapidly forgotten in early layers. Using this observation, we propose
a method to "read out" the implicit vocabulary of an autoregressive LLM by
examining differences in token representations across layers, and present
results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is
the first attempt to probe the implicit vocabulary of an LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 14 figures. Code and data at
  https://footprints.baulab.info/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Molecular Facts: Desiderata for Decontextualization in LLM Fact
  Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20079v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20079v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anisha Gunjal, Greg Durrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic factuality verification of large language model (LLM) generations
is becoming more and more widely used to combat hallucinations. A major point
of tension in the literature is the granularity of this fact-checking: larger
chunks of text are hard to fact-check, but more atomic facts like propositions
may lack context to interpret correctly. In this work, we assess the role of
context in these atomic facts. We argue that fully atomic facts are not the
right representation, and define two criteria for molecular facts:
decontextuality, or how well they can stand alone, and minimality, or how
little extra information is added to achieve decontexuality. We quantify the
impact of decontextualization on minimality, then present a baseline
methodology for generating molecular facts automatically, aiming to add the
right amount of information. We compare against various methods of
decontextualization and find that molecular facts balance minimality with fact
verification accuracy in ambiguous settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Applying RLAIF for Code Generation with API-usage in Lightweight LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20060v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20060v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sujan Dutta, Sayantan Mahinder, Raviteja Anantha, Bortik Bandyopadhyay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning from AI Feedback (RLAIF) has demonstrated significant
potential across various domains, including mitigating harm in LLM outputs,
enhancing text summarization, and mathematical reasoning. This paper introduces
an RLAIF framework for improving the code generation abilities of lightweight
(<1B parameters) LLMs. We specifically focus on code generation tasks that
require writing appropriate API calls, which is challenging due to the
well-known issue of hallucination in LLMs. Our framework extracts AI feedback
from a larger LLM (e.g., GPT-3.5) through a specialized prompting strategy and
uses this data to train a reward model towards better alignment from smaller
LLMs. We run our experiments on the Gorilla dataset and meticulously assess the
quality of the model-generated code across various metrics, including AST,
ROUGE, and Code-BLEU, and develop a pipeline to compute its executability rate
accurately. Our approach significantly enhances the fine-tuned LLM baseline's
performance, achieving a 4.5% improvement in executability rate. Notably, a
smaller LLM model (780M parameters) trained with RLAIF surpasses a much larger
fine-tuned baseline with 7B parameters, achieving a 1.0% higher code
executability rate.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ To Word Senses and Beyond: Inducing Concepts with Contextualized
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20054v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20054v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bastien Liétard, Pascal Denis, Mikaella Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Polysemy and synonymy are two crucial interrelated facets of lexical
ambiguity. While both phenomena have been studied extensively in NLP, leading
to dedicated systems, they are often been considered independently. While many
tasks dealing with polysemy (e.g. Word Sense Disambiguiation or Induction)
highlight the role of a word's senses, the study of synonymy is rooted in the
study of concepts, i.e. meaning shared across the lexicon. In this paper, we
introduce Concept Induction, the unsupervised task of learning a soft
clustering among words that defines a set of concepts directly from data. This
task generalizes that of Word Sense Induction. We propose a bi-level approach
to Concept Induction that leverages both a local lemma-centric view and a
global cross-lexicon perspective to induce concepts. We evaluate the obtained
clustering on SemCor's annotated data and obtain good performances (BCubed F1
above 0.60). We find that the local and the global levels are mutually
beneficial to induce concepts and also senses in our setting. Finally, we
create static embeddings representing our induced concepts and use them on the
Word-in-Context task, obtaining competitive performances with the
State-of-the-Art.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20053v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20053v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danny Halawi, Alexander Wei, Eric Wallace, Tony T. Wang, Nika Haghtalab, Jacob Steinhardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Black-box finetuning is an emerging interface for adapting state-of-the-art
language models to user needs. However, such access may also let malicious
actors undermine model safety. To demonstrate the challenge of defending
finetuning interfaces, we introduce covert malicious finetuning, a method to
compromise model safety via finetuning while evading detection. Our method
constructs a malicious dataset where every individual datapoint appears
innocuous, but finetuning on the dataset teaches the model to respond to
encoded harmful requests with encoded harmful responses. Applied to GPT-4, our
method produces a finetuned model that acts on harmful instructions 99% of the
time and avoids detection by defense mechanisms such as dataset inspection,
safety evaluations, and input/output classifiers. Our findings question whether
black-box finetuning access can be secured against sophisticated adversaries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding and Mitigating Language Confusion in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20052v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20052v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kelly Marchisio, Wei-Yin Ko, Alexandre Bérard, Théo Dehaze, Sebastian Ruder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate a surprising limitation of LLMs: their inability to
consistently generate text in a user's desired language. We create the Language
Confusion Benchmark (LCB) to evaluate such failures, covering 15 typologically
diverse languages with existing and newly-created English and multilingual
prompts. We evaluate a range of LLMs on monolingual and cross-lingual
generation reflecting practical use cases, finding that Llama Instruct and
Mistral models exhibit high degrees of language confusion and even the
strongest models fail to consistently respond in the correct language. We
observe that base and English-centric instruct models are more prone to
language confusion, which is aggravated by complex prompts and high sampling
temperatures. We find that language confusion can be partially mitigated via
few-shot prompting, multilingual SFT and preference tuning. We release our
language confusion benchmark, which serves as a first layer of efficient,
scalable multilingual evaluation at
https://github.com/for-ai/language-confusion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BioMNER: A <span class="highlight-title">Dataset</span> for Biomedical Method Entity Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20038v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20038v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Tang, Bohao Yang, Kun Zhao, Bo Lv, Chenghao Xiao, Frank Guerin, Chenghua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Named entity recognition (NER) stands as a fundamental and pivotal task
within the realm of Natural Language Processing. Particularly within the domain
of Biomedical Method NER, this task presents notable challenges, stemming from
the continual influx of domain-specific terminologies in scholarly literature.
Current research in Biomedical Method (BioMethod) NER suffers from a scarcity
of resources, primarily attributed to the intricate nature of methodological
concepts, which necessitate a profound understanding for precise delineation.
In this study, we propose a novel dataset for biomedical method entity
recognition, employing an automated BioMethod entity recognition and
information retrieval system to assist human annotation. Furthermore, we
comprehensively explore a range of conventional and contemporary open-domain
NER methodologies, including the utilization of cutting-edge large-scale
language models (LLMs) customised to our dataset. Our empirical findings reveal
that the large parameter counts of language models surprisingly inhibit the
effective assimilation of entity extraction patterns pertaining to biomedical
methods. Remarkably, the approach, leveraging the modestly sized ALBERT model
(only 11MB), in conjunction with conditional random fields (CRF), achieves
state-of-the-art (SOTA) performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20030v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20030v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renzhi Wang, Piji Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) require continual knowledge updates to stay
abreast of the ever-changing world facts, prompting the formulation of lifelong
model editing task. While recent years have witnessed the development of
various techniques for single and batch editing, these methods either fail to
apply or perform sub-optimally when faced with lifelong editing. In this paper,
we introduce LEMoE, an advanced Mixture of Experts (MoE) adaptor for lifelong
model editing. We first analyze the factors influencing the effectiveness of
conventional MoE adaptor in lifelong editing, including catastrophic
forgetting, inconsistent routing and order sensitivity. Based on these
insights, we propose a tailored module insertion method to achieve lifelong
editing, incorporating a novel KV anchor routing to enhance routing consistency
between training and inference stage, along with a concise yet effective
clustering-based editing order planning. Experimental results demonstrate the
effectiveness of our method in lifelong editing, surpassing previous model
editing techniques while maintaining outstanding performance in batch editing
task. Our code will be available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for
  Tool-Augmented Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20015v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20015v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tool-augmented large language models (LLMs) are rapidly being integrated into
real-world applications. Due to the lack of benchmarks, the community still
needs to fully understand the hallucination issues within these models. To
address this challenge, we introduce a comprehensive diagnostic benchmark,
ToolBH. Specifically, we assess the LLM's hallucinations through two
perspectives: depth and breadth. In terms of depth, we propose a multi-level
diagnostic process, including (1) solvability detection, (2) solution planning,
and (3) missing-tool analysis. For breadth, we consider three scenarios based
on the characteristics of the toolset: missing necessary tools, potential
tools, and limited functionality tools. Furthermore, we developed seven tasks
and collected 700 evaluation samples through multiple rounds of manual
annotation. The results show the significant challenges presented by the ToolBH
benchmark. The current advanced models Gemini-1.5-Pro and GPT-4o only achieve a
total score of 45.3 and 37.0, respectively, on a scale of 100. In this
benchmark, larger model parameters do not guarantee better performance; the
training data and response strategies also play a crucial role in tool-enhanced
LLM scenarios. Our diagnostic analysis indicates that the primary reason for
model errors lies in assessing task solvability. Additionally, open-weight
models suffer from performance drops with verbose replies, whereas proprietary
models excel with longer reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The SIFo Benchmark: Investigating the Sequential Instruction Following
  Ability of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Chen, Baohao Liao, Jirui Qi, Panagiotis Eustratiadis, Christof Monz, Arianna Bisazza, Maarten de Rijke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Following multiple instructions is a crucial ability for large language
models (LLMs). Evaluating this ability comes with significant challenges: (i)
limited coherence between multiple instructions, (ii) positional bias where the
order of instructions affects model performance, and (iii) a lack of
objectively verifiable tasks. To address these issues, we introduce a benchmark
designed to evaluate models' abilities to follow multiple instructions through
sequential instruction following (SIFo) tasks. In SIFo, the successful
completion of multiple instructions is verifiable by examining only the final
instruction. Our benchmark evaluates instruction following using four tasks
(text modification, question answering, mathematics, and security rule
following), each assessing different aspects of sequential instruction
following. Our evaluation of popular LLMs, both closed-source and open-source,
shows that more recent and larger models significantly outperform their older
and smaller counterparts on the SIFo tasks, validating the benchmark's
effectiveness. All models struggle with following sequences of instructions,
hinting at an important lack of robustness of today's language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Single Parent Family: A Spectrum of Family Members from a Single
  <span class="highlight-title">Pre-Train</span>ed Foundation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19995v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19995v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Habib Hajimolahoseini, Mohammad Hassanpour, Foozhan Ataiefard, Boxing Chen, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel method of Progressive Low Rank Decomposition
(PLRD) tailored for the compression of large language models. Our approach
leverages a pre-trained model, which is then incrementally decompressed to
smaller sizes using progressively lower ranks. This method allows for
significant reductions in computational overhead and energy consumption, as
subsequent models are derived from the original without the need for retraining
from scratch. We detail the implementation of PLRD, which strategically
decreases the tensor ranks, thus optimizing the trade-off between model
performance and resource usage. The efficacy of PLRD is demonstrated through
extensive experiments showing that models trained with PLRD method on only 1B
tokens maintain comparable performance with traditionally trained models while
using 0.1% of the tokens. The versatility of PLRD is highlighted by its ability
to generate multiple model sizes from a single foundational model, adapting
fluidly to varying computational and memory budgets. Our findings suggest that
PLRD could set a new standard for the efficient scaling of LLMs, making
advanced AI more feasible on diverse platforms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Into the Unknown: Generating Geospatial Descriptions for New
  Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19967v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19967v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulating Financial Market via Large Language Model based Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19966v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19966v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shen Gao, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, Shuo Shang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most economic theories typically assume that financial market participants
are fully rational individuals and use mathematical models to simulate human
behavior in financial markets. However, human behavior is often not entirely
rational and is challenging to predict accurately with mathematical models. In
this paper, we propose \textbf{A}gent-based \textbf{S}imulated
\textbf{F}inancial \textbf{M}arket (ASFM), which first constructs a simulated
stock market with a real order matching system. Then, we propose a large
language model based agent as the stock trader, which contains the profile,
observation, and tool-learning based action module. The trading agent can
comprehensively understand current market dynamics and financial policy
information, and make decisions that align with their trading strategy. In the
experiments, we first verify that the reactions of our ASFM are consistent with
the real stock market in two controllable scenarios. In addition, we also
conduct experiments in two popular economics research directions, and we find
that conclusions drawn in our \model align with the preliminary findings in
economics research. Based on these observations, we believe our proposed ASFM
provides a new paradigm for economic research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BESTOW: Efficient and Streamable Speech Language Model with the Best of
  Two Worlds in <span class="highlight-title">GPT</span> and T5 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19954v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19954v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhehuai Chen, He Huang, Oleksii Hrinchuk, Krishna C. Puvvada, Nithin Rao Koluguri, Piotr Żelasko, Jagadeesh Balam, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Incorporating speech understanding capabilities into pretrained
large-language models has become a vital research direction (SpeechLLM). The
previous architectures can be categorized as: i) GPT-style, prepend speech
prompts to the text prompts as a sequence of LLM inputs like a decoder-only
model; ii) T5-style, introduce speech cross-attention to each layer of the
pretrained LLMs. We propose BESTOW architecture to bring the BESt features from
TwO Worlds into a single model that is highly efficient and has strong
multitask capabilities. Moreover, there is no clear streaming solution for
either style, especially considering the solution should generalize to speech
multitask. We reformulate streamable SpeechLLM as a read-write policy problem
and unifies the offline and streaming research with BESTOW architecture. Hence
we demonstrate the first open-source SpeechLLM solution that enables Streaming
and Multitask at scale (beyond ASR) at the same time. This streamable solution
achieves very strong performance on a wide range of speech tasks (ASR, AST,
SQA, unseen DynamicSuperb). It is end-to-end optimizable, with lower
training/inference cost, and demonstrates LLM knowledge transferability to
speech.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mining Reasons For And Against Vaccination From Unstructured Data Using
  Nichesourcing and AI Data Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19951v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19951v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Damián Ariel Furman, Juan Junqueras, Z. Burçe Gümüslü, Edgar Altszyler, Joaquin Navajas, Ophelia Deroy, Justin Sulik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Reasons For and Against Vaccination (RFAV), a dataset for
predicting reasons for and against vaccination, and scientific authorities used
to justify them, annotated through nichesourcing and augmented using GPT4 and
GPT3.5-Turbo. We show how it is possible to mine these reasons in
non-structured text, under different task definitions, despite the high level
of subjectivity involved and explore the impact of artificially augmented data
using in-context learning with GPT4 and GPT3.5-Turbo. We publish the dataset
and the trained models along with the annotation manual used to train
annotators and define the task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages + references and appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Calibrating LLMs with Preference Optimization on Thought Trees for
  Generating Rationale in Science Question Scoring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19949v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19949v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiazheng Li, Hainiu Xu, Zhaoyue Sun, Yuxiang Zhou, David West, Cesare Aloisi, Yulan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating rationales that justify scoring decisions has been a promising way
to facilitate explainability in automated scoring systems. However, existing
methods do not match the accuracy of classifier-based methods. Plus, the
generated rationales often contain hallucinated information. To address these
issues, we propose a novel framework capable of generating more faithful
rationales and, more importantly, matching performance with classifier-based
black-box scoring systems. We first mimic the human assessment process by
querying Large Language Models (LLMs) to generate a thought tree. We then
summarise intermediate assessment decisions from each thought tree path for
creating synthetic rationale data and rationale preference data. Finally, we
utilise the generated synthetic data to calibrate LLMs through a two-step
training process: supervised fine-tuning and preference optimization. Extensive
experimental results demonstrate that our framework achieves a 38% assessment
performance improvement in the QWK score compared to prior work while producing
higher-quality rationales, as recognised by human evaluators and LLMs. Our work
sheds light on the effectiveness of performing preference optimization using
synthetic preference data obtained from thought tree paths.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From the Least to the Most: Building a Plug-and-Play Visual Reasoner via
  Data Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19934v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19934v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore multi-step reasoning in vision-language models (VLMs). The problem
is challenging, as reasoning data consisting of multiple steps of visual and
language processing are barely available. To overcome the challenge, we first
introduce a least-to-most visual reasoning paradigm, which interleaves steps of
decomposing a question into sub-questions and invoking external tools for
resolving sub-questions. Based on the paradigm, we further propose a novel data
synthesis approach that can automatically create questions and multi-step
reasoning paths for an image in a bottom-up manner. Our approach divides the
complex synthesis task into a few simple sub-tasks, and (almost entirely)
relies on open-sourced models to accomplish the sub-tasks. Therefore, the
entire synthesis process is reproducible and cost-efficient, and the
synthesized data is quality guaranteed. With the approach, we construct $50$k
visual reasoning examples. Then, we develop a visual reasoner through
supervised fine-tuning, which is capable of generally enhancing the reasoning
abilities of a wide range of existing VLMs in a plug-and-play fashion.
Extensive experiments indicate that the visual reasoner can consistently and
significantly improve four VLMs on four VQA benchmarks. Our code and dataset
are available at https://github.com/steven-ccq/VisualReasoner.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactive Topic Models with Optimal Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Garima Dhanania, Sheshera Mysore, Chau Minh Pham, Mohit Iyyer, Hamed Zamani, Andrew McCallum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic models are widely used to analyze document collections. While they are
valuable for discovering latent topics in a corpus when analysts are unfamiliar
with the corpus, analysts also commonly start with an understanding of the
content present in a corpus. This may be through categories obtained from an
initial pass over the corpus or a desire to analyze the corpus through a
predefined set of categories derived from a high level theoretical framework
(e.g. political ideology). In these scenarios analysts desire a topic modeling
approach which incorporates their understanding of the corpus while supporting
various forms of interaction with the model. In this work, we present EdTM, as
an approach for label name supervised topic modeling. EdTM models topic
modeling as an assignment problem while leveraging LM/LLM based document-topic
affinities and using optimal transport for making globally coherent
topic-assignments. In experiments, we show the efficacy of our framework
compared to few-shot LLM classifiers, and topic models based on clustering and
LDA. Further, we show EdTM's ability to incorporate various forms of analyst
feedback and while remaining robust to noisy analyst inputs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print; Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Paraphrase Types Elicit <span class="highlight-title">Prompt</span> Engineering Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19898v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19898v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Philip Wahle, Terry Ruas, Yang Xu, Bela Gipp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Much of the success of modern language models depends on finding a suitable
prompt to instruct the model. Until now, it has been largely unknown how
variations in the linguistic expression of prompts affect these models. This
study systematically and empirically evaluates which linguistic features
influence models through paraphrase types, i.e., different linguistic changes
at particular positions. We measure behavioral changes for five models across
120 tasks and six families of paraphrases (i.e., morphology, syntax, lexicon,
lexico-syntax, discourse, and others). We also control for other prompt
engineering factors (e.g., prompt length, lexical diversity, and proximity to
training data). Our results show a potential for language models to improve
tasks when their prompts are adapted in specific paraphrase types (e.g., 6.7%
median gain in Mixtral 8x7B; 5.5% in LLaMA 3 8B). In particular, changes in
morphology and lexicon, i.e., the vocabulary used, showed promise in improving
prompts. These findings contribute to developing more robust language models
capable of handling variability in linguistic expression.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Untangling the Unrestricted Web: Automatic Identification of
  Multilingual Registers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19892v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19892v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erik Henriksson, Amanda Myntti, Anni Eskelinen, Selcen Erten-Johansson, Saara Hellström, Veronika Laippala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article explores deep learning models for the automatic identification
of registers - text varieties such as news reports and discussion forums - in
web-based datasets across 16 languages. Web register (or genre) identification
would provide a robust solution for understanding the content of web-scale
datasets, which have become crucial in computational linguistics. Despite
recent advances, the potential of register classifiers on the noisy web remains
largely unexplored, particularly in multilingual settings and when targeting
the entire unrestricted web. We experiment with a range of deep learning models
using the new Multilingual CORE corpora, which includes 16 languages annotated
using a detailed, hierarchical taxonomy of 25 registers designed to cover the
entire unrestricted web. Our models achieve state-of-the-art results, showing
that a detailed taxonomy in a hierarchical multi-label setting can yield
competitive classification performance. However, all models hit a glass ceiling
at approximately 80% F1 score, which we attribute to the non-discrete nature of
web registers and the inherent uncertainty in labeling some documents. By
pruning ambiguous examples, we improve model performance to over 90%. Finally,
multilingual models outperform monolingual ones, particularly benefiting
languages with fewer training examples and smaller registers. Although a
zero-shot setting decreases performance by an average of 7%, these drops are
not linked to specific registers or languages. Instead, registers show
surprising similarity across languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating the Timescales of Language Processing with EEG and
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19884v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19884v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Turco, Conor Houghton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores the temporal dynamics of language processing by examining
the alignment between word representations from a pre-trained transformer-based
language model, and EEG data. Using a Temporal Response Function (TRF) model,
we investigate how neural activity corresponds to model representations across
different layers, revealing insights into the interaction between artificial
language models and brain responses during language comprehension. Our analysis
reveals patterns in TRFs from distinct layers, highlighting varying
contributions to lexical and compositional processing. Additionally, we used
linear discriminant analysis (LDA) to isolate part-of-speech (POS)
representations, offering insights into their influence on neural responses and
the underlying mechanisms of syntactic processing. These findings underscore
EEG's utility for probing language processing dynamics with high temporal
resolution. By bridging artificial language models and neural activity, this
study advances our understanding of their interaction at fine timescales.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 2024 Conference on Cognitive Computational
  Neuroscience (CCN 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Detecting Subtle Differences between Human and Model Languages Using
  Spectrum of Relative Likelihood 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19874v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19874v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Xu, Yu Wang, Hao An, Zhichen Liu, Yongyuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human and model-generated texts can be distinguished by examining the
magnitude of likelihood in language. However, it is becoming increasingly
difficult as language model's capabilities of generating human-like texts keep
evolving. This study provides a new perspective by using the relative
likelihood values instead of absolute ones, and extracting useful features from
the spectrum-view of likelihood for the human-model text detection task. We
propose a detection procedure with two classification methods, supervised and
heuristic-based, respectively, which results in competitive performances with
previous zero-shot detection methods and a new state-of-the-art on short-text
detection. Our method can also reveal subtle differences between human and
model languages, which find theoretical roots in psycholinguistics studies. Our
code is available at https://github.com/CLCS-SUSTech/FourierGPT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ YuLan: An Open-source Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19853v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19853v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutao Zhu, Kun Zhou, Kelong Mao, Wentong Chen, Yiding Sun, Zhipeng Chen, Qian Cao, Yihan Wu, Yushuo Chen, Feng Wang, Lei Zhang, Junyi Li, Xiaolei Wang, Lei Wang, Beichen Zhang, Zican Dong, Xiaoxue Cheng, Yuhan Chen, Xinyu Tang, Yupeng Hou, Qiangqiang Ren, Xincheng Pang, Shufang Xie, Wayne Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ze-Feng Gao, Yueguo Chen, Weizheng Lu, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become the foundation of many applications,
leveraging their extensive capabilities in processing and understanding natural
language. While many open-source LLMs have been released with technical
reports, the lack of training details hinders further research and development.
This paper presents the development of YuLan, a series of open-source LLMs with
$12$ billion parameters. The base model of YuLan is pre-trained on
approximately $1.7$T tokens derived from a diverse corpus, including massive
English, Chinese, and multilingual texts. We design a three-stage pre-training
method to enhance YuLan's overall capabilities. Subsequent phases of training
incorporate instruction-tuning and human alignment, employing a substantial
volume of high-quality synthesized data. To facilitate the learning of complex
and long-tail knowledge, we devise a curriculum-learning framework throughout
across these stages, which helps LLMs learn knowledge in an easy-to-hard
manner. YuLan's training is finished on Jan, 2024 and has achieved performance
on par with state-of-the-art LLMs across various English and Chinese
benchmarks. This paper outlines a comprehensive technical roadmap for
developing LLMs from scratch. Our model and codes are available at
https://github.com/RUC-GSAI/YuLan-Chat.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through
  low-confidence single-token predictions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19840v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19840v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Waligóra Witold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces AnomaLLMy, a novel technique for the automatic
detection of anomalous tokens in black-box Large Language Models (LLMs) with
API-only access. Utilizing low-confidence single-token predictions as a
cost-effective indicator, AnomaLLMy identifies irregularities in model
behavior, addressing the issue of anomalous tokens degrading the quality and
reliability of models. Validated on the cl100k_base dataset, the token set of
GPT-4, AnomaLLMy detected 413 major and 65 minor anomalies, demonstrating the
method's efficiency with just \$24.39 spent in API credits. The insights from
this research are expected to be beneficial for enhancing the robustness of and
accuracy of LLMs, particularly in the development and assessment of tokenizers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for
  Multi-hop Question Answering <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19820v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19820v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Chu, Jingchang Chen, Qianglong Chen, Haotian Wang, Kun Zhu, Xiyuan Du, Weijiang Yu, Ming Liu, Bing Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated strong reasoning capabilities.
Nevertheless, they still suffer from factual errors when tackling
knowledge-intensive tasks. Retrieval-augmented reasoning represents a promising
approach. However, significant challenges still persist, including inaccurate
and insufficient retrieval for complex questions, as well as difficulty in
integrating multi-source knowledge. To address this, we propose Beam
Aggregation Reasoning, BeamAggR, a reasoning framework for knowledge-intensive
multi-hop QA. BeamAggR explores and prioritizes promising answers at each hop
of question. Concretely, we parse the complex questions into trees, which
include atom and composite questions, followed by bottom-up reasoning. For
atomic questions, the LLM conducts reasoning on multi-source knowledge to get
answer candidates. For composite questions, the LLM combines beam candidates,
explores multiple reasoning paths through probabilistic aggregation, and
prioritizes the most promising trajectory. Extensive experiments on four
open-domain multi-hop reasoning datasets show that our method significantly
outperforms SOTA methods by 8.5%. Furthermore, our analysis reveals that
BeamAggR elicits better knowledge collaboration and answer aggregation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable and Domain-General Abstractive Proposition Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19803v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19803v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Javad Hosseini, Yang Gao, Tim Baumgärtner, Alex Fabrikant, Reinald Kim Amplayo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Segmenting text into fine-grained units of meaning is important to a wide
range of NLP applications. The default approach of segmenting text into
sentences is often insufficient, especially since sentences are usually complex
enough to include multiple units of meaning that merit separate treatment in
the downstream task. We focus on the task of abstractive proposition
segmentation: transforming text into simple, self-contained, well-formed
sentences. Several recent works have demonstrated the utility of proposition
segmentation with few-shot prompted LLMs for downstream tasks such as
retrieval-augmented grounding and fact verification. However, this approach
does not scale to large amounts of text and may not always extract all the
facts from the input text. In this paper, we first introduce evaluation metrics
for the task to measure several dimensions of quality. We then propose a
scalable, yet accurate, proposition segmentation model. We model proposition
segmentation as a supervised task by training LLMs on existing annotated
datasets and show that training yields significantly improved results. We
further show that by using the fine-tuned LLMs as teachers for annotating large
amounts of multi-domain synthetic distillation data, we can train smaller
student models with results similar to the teacher LLMs. We then demonstrate
that our technique leads to effective domain generalization, by annotating data
in two domains outside the original training data and evaluating on them.
Finally, as a key contribution of the paper, we share an easy-to-use API for
NLP practitioners to use.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NLPerturbator: Studying the Robustness of Code LLMs to Natural Language
  Variations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19783v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19783v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junkai Chen, Zhenhao Li, Xing Hu, Xin Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) achieve promising results in code generation
based on a given natural language description. They have been integrated into
open-source projects and commercial products to facilitate daily coding
activities. The natural language description in the prompt is crucial for LLMs
to comprehend users' requirements. Prior studies uncover that LLMs are
sensitive to the changes in the prompts, including slight changes that look
inconspicuous. However, the natural language descriptions often vary in
real-world scenarios (e.g., different formats, grammar, and wording). Prior
studies on the robustness of LLMs are often based on random perturbations and
such perturbations may not actually happen. In this paper, we conduct a
comprehensive study to investigate how are code LLMs robust to variations of
natural language description in real-world scenarios. We summarize 18
categories of perturbations of natural language and 3 combinations of
co-occurred categories based on our literature review and an online survey with
practitioners. We propose an automated framework, NLPerturbator, which can
perform perturbations of each category given a set of prompts. Through a series
of experiments on code generation using six code LLMs, we find that the
perturbed prompts can decrease the performance of code generation by a
considerable margin (e.g., up to 21.2%, and 4.8% to 6.1% on average). Our study
highlights the importance of enhancing the robustness of LLMs to real-world
variations in the prompts, as well as the essentiality of attentively
constructing the prompts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Direct Preference Knowledge Distillation for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19774v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19774v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixing Li, Yuxian Gu, Li Dong, Dequan Wang, Yu Cheng, Furu Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the field of large language models (LLMs), Knowledge Distillation (KD) is
a critical technique for transferring capabilities from teacher models to
student models. However, existing KD methods face limitations and challenges in
distillation of LLMs, including efficiency and insufficient measurement
capabilities of traditional KL divergence. It is shown that LLMs can serve as
an implicit reward function, which we define as a supplement to KL divergence.
In this work, we propose Direct Preference Knowledge Distillation (DPKD) for
LLMs. DPKD utilizes distribution divergence to represent the preference loss
and implicit reward function. We re-formulate KD of LLMs into two stages: first
optimizing and objective consisting of implicit reward and reverse KL
divergence and then improving the preference probability of teacher outputs
over student outputs. We conducted experiments and analysis on various datasets
with LLM parameters ranging from 120M to 13B and demonstrate the broad
applicability and effectiveness of our DPKD approach. Meanwhile, we prove the
value and effectiveness of the introduced implicit reward and output preference
in KD through experiments and theoretical analysis. The DPKD method outperforms
the baseline method in both output response precision and exact match
percentage. Code and data are available at https://aka.ms/dpkd.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Belief Revision: The Adaptability of Large Language Models Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19764v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19764v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bryan Wilie, Samuel Cahyawijaya, Etsuko Ishii, Junxian He, Pascale Fung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The capability to reason from text is crucial for real-world NLP
applications. Real-world scenarios often involve incomplete or evolving data.
In response, individuals update their beliefs and understandings accordingly.
However, most existing evaluations assume that language models (LMs) operate
with consistent information. We introduce Belief-R, a new dataset designed to
test LMs' belief revision ability when presented with new evidence. Inspired by
how humans suppress prior inferences, this task assesses LMs within the newly
proposed delta reasoning ($\Delta R$) framework. Belief-R features sequences of
premises designed to simulate scenarios where additional information could
necessitate prior conclusions drawn by LMs. We evaluate $\sim$30 LMs across
diverse prompting strategies and found that LMs generally struggle to
appropriately revise their beliefs in response to new information. Further,
models adept at updating often underperformed in scenarios without necessary
updates, highlighting a critical trade-off. These insights underscore the
importance of improving LMs' adaptiveness to changing information, a step
toward more reliable AI systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case
  Reformulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19760v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19760v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenlong Deng, Kelong Mao, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal case retrieval for sourcing similar cases is critical in upholding
judicial fairness. Different from general web search, legal case retrieval
involves processing lengthy, complex, and highly specialized legal documents.
Existing methods in this domain often overlook the incorporation of legal
expert knowledge, which is crucial for accurately understanding and modeling
legal cases, leading to unsatisfactory retrieval performance. This paper
introduces KELLER, a legal knowledge-guided case reformulation approach based
on large language models (LLMs) for effective and interpretable legal case
retrieval. By incorporating professional legal knowledge about crimes and law
articles, we enable large language models to accurately reformulate the
original legal case into concise sub-facts of crimes, which contain the
essential information of the case. Extensive experiments on two legal case
retrieval benchmarks demonstrate superior retrieval performance and robustness
on complex legal case queries of KELLER over existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Breaking the Script Barrier in Multilingual <span class="highlight-title">Pre-Train</span>ed Language Models
  with Transliteration-Based Post-Training Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19759v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19759v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Orgest Xhelili, Yihong Liu, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilingual pre-trained models (mPLMs) have shown impressive performance on
cross-lingual transfer tasks. However, the transfer performance is often
hindered when a low-resource target language is written in a different script
than the high-resource source language, even though the two languages may be
related or share parts of their vocabularies. Inspired by recent work that uses
transliteration to address this problem, our paper proposes a
transliteration-based post-pretraining alignment (PPA) method aiming to improve
the cross-lingual alignment between languages using diverse scripts. We select
two areal language groups, $\textbf{Mediterranean-Amharic-Farsi}$ and
$\textbf{South+East Asian Languages}$, wherein the languages are mutually
influenced but use different scripts. We apply our method to these language
groups and conduct extensive experiments on a spectrum of downstream tasks. The
results show that after PPA, models consistently outperform the original model
(up to 50% for some tasks) in English-centric transfer. In addition, when we
use languages other than English as sources in transfer, our method obtains
even larger improvements. We will make our code and models publicly available
at \url{https://github.com/cisnlp/Transliteration-PPA}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MM-Instruct: Generated Visual Instructions for Large Multimodal Model
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihao Liu, Xin Huang, Jinliang Zheng, Boxiao Liu, Jia Wang, Osamu Yoshie, Yu Liu, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces MM-Instruct, a large-scale dataset of diverse and
high-quality visual instruction data designed to enhance the
instruction-following capabilities of large multimodal models (LMMs). While
existing visual instruction datasets often focus on question-answering, they
struggle to generalize to broader application scenarios such as creative
writing, summarization, or image analysis. To address these limitations, we
propose a novel approach to constructing MM-Instruct that leverages the strong
instruction-following capabilities of existing LLMs to generate novel visual
instruction data from large-scale but conventional image captioning datasets.
MM-Instruct first leverages ChatGPT to automatically generate diverse
instructions from a small set of seed instructions through augmenting and
summarization. It then matches these instructions with images and uses an
open-sourced large language model (LLM) to generate coherent answers to the
instruction-image pairs. The LLM is grounded by the detailed text descriptions
of images in the whole answer generation process to guarantee the alignment of
the instruction data. Moreover, we introduce a benchmark based on the generated
instruction data to evaluate the instruction-following capabilities of existing
LMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5
model on the generated data, denoted as LLaVA-Instruct, which exhibits
significant improvements in instruction-following capabilities compared to
LLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models
are available at https://github.com/jihaonew/MM-Instruct.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset and models are available at
  https://github.com/jihaonew/MM-Instruct</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Message du troisi{è}me type : irruption d'un tiers dans un dialogue en
  ligne 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19731v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19731v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ludovic Tanguy, Céline Poudat, Lydia-Mai Ho-Dac
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our study focuses on Wikipedia talk pages, from a global perspective
analyzing contributors' behaviors in online interactions. Using a corpus
comprising all Wikipedia talk pages in French, totaling more than 300,000
discussion threads, we examine how discussions with more than two participants
(multiparty conversation) unfold and we specifically investigate the role of a
third participant's intervention when two Wikipedians have already initiated an
exchange. In this regard, we concentrate on the sequential structure of these
interactions in terms of articulation among different participants and aim to
specify this third message by exploring its lexical particularities, while also
proposing an initial typology of the third participant's message role and how
it aligns with preceding messages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>in French language. JADT 2024 - 17es Journ{\'e}es internationales
  d'Analyse statistique des Donn{\'e}es Textuelles, SeSLa (S{\'e}minaire des
  Sciences du Langage de l'UCLouvain -- Site Saint-Louis); LASLA (Laboratoire
  d'Analyse statistique des Langues anciennes de l'Universit{\'e} de
  Li{\`e}ge), 2024, Bruxelles, Belgique</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Le sens de la famille : analyse du vocabulaire de la parent{é} par les
  plongements de mots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ludovic Tanguy, Cécile Fabre, Nabil Hathout, Lydia-Mai Ho-Dac
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we propose a corpus analysis of an area of the French lexicon
that is both dense and highly structured: the vocabulary of family
relationships. Starting with a lexicon of 25 nouns designating the main
relationships (son, cousin, mother, grandfather, sister-in-law etc.), we
examine how these terms are positioned in relation to each other through
distributional analyses based on the use of these terms in corpora. We show
that distributional information can capture certain features that organize this
vocabulary (descent, alliance, siblings, genre), in ways that vary according to
the different corpora compared.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>in French language. JADT 2024 - 17es Journ{\'e}es internationales
  d'Analyse statistique des Donn{\'e}es Textuelles, SeSLa (S{\'e}minaire des
  Sciences du Langage de l'UCLouvain -- Site Saint-Louis), 2024, Bruxelles,
  Belgique</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncertainty Quantification in Large Language Models Through Convex Hull
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ferhat Ozgur Catak, Murat Kuzlu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Uncertainty quantification approaches have been more critical in large
language models (LLMs), particularly high-risk applications requiring reliable
outputs. However, traditional methods for uncertainty quantification, such as
probabilistic models and ensemble techniques, face challenges when applied to
the complex and high-dimensional nature of LLM-generated outputs. This study
proposes a novel geometric approach to uncertainty quantification using convex
hull analysis. The proposed method leverages the spatial properties of response
embeddings to measure the dispersion and variability of model outputs. The
prompts are categorized into three types, i.e., `easy', `moderate', and
`confusing', to generate multiple responses using different LLMs at varying
temperature settings. The responses are transformed into high-dimensional
embeddings via a BERT model and subsequently projected into a two-dimensional
space using Principal Component Analysis (PCA). The Density-Based Spatial
Clustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster
the embeddings and compute the convex hull for each selected cluster. The
experimental results indicate that the uncertainty of the model for LLMs
depends on the prompt complexity, the model, and the temperature setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Less is More: Accurate Speech Recognition & Translation without
  Web-Scale Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krishna C. Puvvada, Piotr Żelasko, He Huang, Oleksii Hrinchuk, Nithin Rao Koluguri, Kunal Dhawan, Somshubra Majumdar, Elena Rastorgueva, Zhehuai Chen, Vitaly Lavrukhin, Jagadeesh Balam, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in speech recognition and translation rely on hundreds of
thousands of hours of Internet speech data. We argue that state-of-the art
accuracy can be reached without relying on web-scale data. Canary -
multilingual ASR and speech translation model, outperforms current
state-of-the-art models - Whisper, OWSM, and Seamless-M4T on English, French,
Spanish, and German languages, while being trained on an order of magnitude
less data than these models. Three key factors enables such data-efficient
model: (1) a FastConformer-based attention encoder-decoder architecture (2)
training on synthetic data generated with machine translation and (3) advanced
training techniques: data-balancing, dynamic data blending, dynamic bucketing
and noise-robust fine-tuning. The model, weights, and training code will be
open-sourced.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Interspeech-2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark
  for Incoherence Detection, Reasoning, and Rewriting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19650v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19650v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanming Zhang, Anthony Diaz, Zixun Chen, Qingyang Wu, Kun Qian, Erik Voss, Zhou Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coherence in writing, an aspect that second-language (L2) English learners
often struggle with, is crucial in assessing L2 English writing. Existing
automated writing evaluation systems primarily use basic surface linguistic
features to detect coherence in writing. However, little effort has been made
to correct the detected incoherence, which could significantly benefit L2
language learners seeking to improve their writing. To bridge this gap, we
introduce DECOR, a novel benchmark that includes expert annotations for
detecting incoherence in L2 English writing, identifying the underlying
reasons, and rewriting the incoherent sentences. To our knowledge, DECOR is the
first coherence assessment dataset specifically designed for improving L2
English writing, featuring pairs of original incoherent sentences alongside
their expert-rewritten counterparts. Additionally, we fine-tuned models to
automatically detect and rewrite incoherence in student essays. We find that
incorporating specific reasons for incoherence during fine-tuning consistently
improves the quality of the rewrites, achieving a result that is favored in
both automatic and human evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 5 figures, 20 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Designing and Evaluating Multi-Chatbot Interface for Human-AI
  Communication: Preliminary Findings from a Persuasion Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19648v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19648v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sion Yoon, Tae Eun Kim, Yoo Jung Oh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The dynamics of human-AI communication have been reshaped by language models
such as ChatGPT. However, extant research has primarily focused on dyadic
communication, leaving much to be explored regarding the dynamics of human-AI
communication in group settings. The availability of multiple language model
chatbots presents a unique opportunity for scholars to better understand the
interaction between humans and multiple chatbots. This study examines the
impact of multi-chatbot communication in a specific persuasion setting:
promoting charitable donations. We developed an online environment that enables
multi-chatbot communication and conducted a pilot experiment utilizing two
GPT-based chatbots, Save the Children and UNICEF chatbots, to promote
charitable donations. In this study, we present our development process of the
multi-chatbot interface and present preliminary findings from a pilot
experiment. Analysis of qualitative and quantitative feedback are presented,
and limitations are addressed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlocking Varied Perspectives: A Persona-Based Multi-Agent Framework
  with Debate-Driven Text Planning for Argument Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19643v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19643v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhe Hu, Hou Pong Chan, Jing Li, Yu Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Writing persuasive arguments is a challenging task for both humans and
machines. It entails incorporating high-level beliefs from various perspectives
on the topic, along with deliberate reasoning and planning to construct a
coherent narrative. Current language models often generate surface tokens
autoregressively, lacking explicit integration of these underlying controls,
resulting in limited output diversity and coherence. In this work, we propose a
persona-based multi-agent framework for argument writing. Inspired by the human
debate, we first assign each agent a persona representing its high-level
beliefs from a unique perspective, and then design an agent interaction process
so that the agents can collaboratively debate and discuss the idea to form an
overall plan for argument writing. Such debate process enables fluid and
nonlinear development of ideas. We evaluate our framework on argumentative
essay writing. The results show that our framework can generate more diverse
and persuasive arguments through both automatic and human evaluations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IDT: Dual-Task Adversarial Attacks for Privacy Protection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedro Faustini, Shakila Mahjabin Tonni, Annabelle McIver, Qiongkai Xu, Mark Dras
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural language processing (NLP) models may leak private information in
different ways, including membership inference, reconstruction or attribute
inference attacks. Sensitive information may not be explicit in the text, but
hidden in underlying writing characteristics. Methods to protect privacy can
involve using representations inside models that are demonstrated not to detect
sensitive attributes or -- for instance, in cases where users might not trust a
model, the sort of scenario of interest here -- changing the raw text before
models can have access to it. The goal is to rewrite text to prevent someone
from inferring a sensitive attribute (e.g. the gender of the author, or their
location by the writing style) whilst keeping the text useful for its original
intention (e.g. the sentiment of a product review). The few works tackling this
have focused on generative techniques. However, these often create extensively
different texts from the original ones or face problems such as mode collapse.
This paper explores a novel adaptation of adversarial attack techniques to
manipulate a text to deceive a classifier w.r.t one task (privacy) whilst
keeping the predictions of another classifier trained for another task
(utility) unchanged. We propose IDT, a method that analyses predictions made by
auxiliary and interpretable models to identify which tokens are important to
change for the privacy task, and which ones should be kept for the utility
task. We evaluate different datasets for NLP suitable for different tasks.
Automatic and human evaluations show that IDT retains the utility of text,
while also outperforming existing methods when deceiving a classifier w.r.t
privacy task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mixture of In-Context Experts Enhance LLMs' Long Context Awareness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongzhan Lin, Ang Lv, Yuhan Chen, Chen Zhu, Yang Song, Hengshu Zhu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many studies have revealed that large language models (LLMs) exhibit uneven
awareness of different contextual positions.Their limited context awareness can
lead to overlooking critical information and subsequent task failures. While
several approaches have been proposed to enhance LLMs' context awareness,
achieving both effectiveness and efficiency remains challenging.In this paper,
for LLMs utilizing RoPE as position embeddings, we introduce a novel method
called ``Mixture of In-Context Experts'' (MoICE) to address this challenge.
MoICE comprises two key components: a router integrated into each attention
head within LLMs and a lightweight router-only training optimization strategy:
(1) MoICE views each RoPE angle as an `in-context' expert, demonstrated to be
capable of directing the attention of a head to specific contextual positions.
Consequently, each attention head flexibly processes tokens using multiple RoPE
angles dynamically selected by the router to attend to the needed positions.
This approach mitigates the risk of overlooking essential contextual
information. (2) The router-only training strategy entails freezing LLM
parameters and exclusively updating routers for only a few steps. When applied
to open-source LLMs including Llama and Mistral, MoICE surpasses prior methods
across multiple tasks on long context understanding and generation, all while
maintaining commendable inference efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SK-VQA: Synthetic Knowledge Generation at Scale for Training
  Context-Augmented Multimodal LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19593v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19593v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Su, Man Luo, Kris W Pan, Tien Pei Chou, Vasudev Lal, Phillip Howard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data generation has gained significant attention recently for its
utility in training large vision and language models. However, the application
of synthetic data to the training of multimodal context-augmented generation
systems has been relatively unexplored. This gap in existing work is important
because existing vision and language models (VLMs) are not trained specifically
for context-augmented generation. Resources for adapting such models are
therefore crucial for enabling their use in retrieval-augmented generation
(RAG) settings, where a retriever is used to gather relevant information that
is then subsequently provided to a generative model via context augmentation.
To address this challenging problem, we generate SK-VQA: a large synthetic
multimodal dataset containing over 2 million question-answer pairs which
require external knowledge to determine the final answer. Our dataset is both
larger and significantly more diverse than existing resources of its kind,
possessing over 11x more unique questions and containing images from a greater
variety of sources than previously-proposed datasets. Through extensive
experiments, we demonstrate that our synthetic dataset can not only serve as a
challenging benchmark, but is also highly effective for adapting existing
generative multimodal models for context-augmented generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoMix: Automatically Mixing Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.12963v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.12963v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranjal Aggarwal, Aman Madaan, Ankit Anand, Srividya Pranavi Potharaju, Swaroop Mishra, Pei Zhou, Aditya Gupta, Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay, Manaal Faruqui,  Mausam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are now available from cloud API providers in
various sizes and configurations. While this diversity offers a broad spectrum
of choices, effectively leveraging the options to optimize computational cost
and performance remains challenging. In this work, we present Automix, an
approach that strategically routes queries to larger LMs, based on the
approximate correctness of outputs from a smaller LM. Central to Automix are
two key technical contributions. First, it has a few-shot self-verification
mechanism, which estimates the reliability of its own outputs without requiring
extensive training. Second, given that self-verification can be noisy, it
employs a POMDP based router that can effectively select an appropriately sized
model, based on answer confidence. Experiments across five language models and
five challenging datasets show that Automix consistently surpasses strong
baselines, reducing computational cost by over 50% for comparable performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally. Work started and partly
  done during Aman's internship at Google. This version adds results on
  additional models and datasets</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MBIAS: Mitigating Bias in Large Language Models While Retaining Context 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11290v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11290v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaina Raza, Ananya Raval, Veronica Chatrath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The deployment of Large Language Models (LLMs) in diverse applications
necessitates an assurance of safety without compromising the contextual
integrity of the generated content. Traditional approaches, including
safety-specific fine-tuning or adversarial testing, often yield safe outputs at
the expense of contextual meaning. This can result in a diminished capacity to
handle nuanced aspects of bias and toxicity, such as underrepresentation or
negative portrayals across various demographics. To address these challenges,
we introduce MBIAS, an LLM framework carefully instruction fine-tuned on a
custom dataset designed specifically for safety interventions. MBIAS is
designed to significantly reduce biases and toxic elements in LLM outputs while
preserving the main information. This work also details our further use of
LLMs: as annotator under human supervision and as evaluator of generated
content. Empirical analysis reveals that MBIAS achieves a reduction in bias and
toxicity by over 30\% in standard evaluations, and by more than 90\% in diverse
demographic tests, highlighting the robustness of our approach. We make the
dataset and the fine-tuned model available to the research community for
further investigation and ensure reproducibility. The code for this project can
be accessed here https://github.com/shainarazavi/MBIAS/tree/main.
  Warning: This paper contains examples that may be offensive or upsetting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MKRAG: Medical Knowledge Retrieval Augmented Generation for Medical
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.16035v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.16035v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucheng Shi, Shaochen Xu, Tianze Yang, Zhengliang Liu, Tianming Liu, Xiang Li, Ninghao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs), although powerful in general domains, often
perform poorly on domain-specific tasks like medical question answering (QA).
Moreover, they tend to function as "black-boxes," making it challenging to
modify their behavior. To address the problem, our study delves into retrieval
augmented generation (RAG), aiming to improve LLM responses without the need
for fine-tuning or retraining. Specifically, we propose a comprehensive
retrieval strategy to extract medical facts from an external knowledge base,
and then inject them into the query prompt for LLMs. Focusing on medical QA
using the MedQA-SMILE dataset, we evaluate the impact of different retrieval
models and the number of facts provided to the LLM. Notably, our
retrieval-augmented Vicuna-7B model exhibited an accuracy improvement from
44.46% to 48.54%. This work underscores the potential of RAG to enhance LLM
performance, offering a practical approach to mitigate the challenges of
black-box LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AMIA 2024 Annual Symposium</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLMs and Memorization: On Quality and Specificity of Copyright
  Compliance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18492v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18492v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix B Mueller, Rebekka Görge, Anna K Bernzen, Janna C Pirk, Maximilian Poretschkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Memorization in large language models (LLMs) is a growing concern. LLMs have
been shown to easily reproduce parts of their training data, including
copyrighted work. This is an important problem to solve, as it may violate
existing copyright laws as well as the European AI Act. In this work, we
propose a systematic analysis to quantify the extent of potential copyright
infringements in LLMs using European law as an example. Unlike previous work,
we evaluate instruction-finetuned models in a realistic end-user scenario. Our
analysis builds on a proposed threshold of 160 characters, which we borrow from
the German Copyright Service Provider Act and a fuzzy text matching algorithm
to identify potentially copyright-infringing textual reproductions. The
specificity of countermeasures against copyright infringement is analyzed by
comparing model behavior on copyrighted and public domain data. We investigate
what behaviors models show instead of producing protected text (such as refusal
or hallucination) and provide a first legal assessment of these behaviors. We
find that there are huge differences in copyright compliance, specificity, and
appropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous
perform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing
a particularly low absolute number of potential copyright violations. Code will
be published soon.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Small and Fast <span class="highlight-title">BERT</span> for Chinese Medical Punctuation Restoration <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.12568v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.12568v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tongtao Ling, Yutao Lai, Lei Chen, Shilei Huang, Yi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In clinical dictation, utterances after automatic speech recognition (ASR)
without explicit punctuation marks may lead to the misunderstanding of dictated
reports. To give a precise and understandable clinical report with ASR,
automatic punctuation restoration is required. Considering a practical
scenario, we propose a fast and light pre-trained model for Chinese medical
punctuation restoration based on 'pretraining and fine-tuning' paradigm. In
this work, we distill pre-trained models by incorporating supervised
contrastive learning and a novel auxiliary pre-training task (Punctuation Mark
Prediction) to make it well-suited for punctuation restoration. Our experiments
on various distilled models reveal that our model can achieve 95% performance
while 10% model size relative to state-of-the-art Chinese RoBERTa.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures, Accepted by INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distributed Speculative Inference of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14105v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14105v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Moshe Wasserblat, Tomer Galanti, Michal Gordon, David Harel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accelerating the inference of large language models (LLMs) is an important
challenge in artificial intelligence. This paper introduces distributed
speculative inference (DSI), a novel distributed inference algorithm that is
provably faster than speculative inference (SI) [leviathan2023fast,
chen2023accelerating, miao2023specinfer] and traditional autoregressive
inference (non-SI). Like other SI algorithms, DSI works on frozen LLMs,
requiring no training or architectural modifications, and it preserves the
target distribution.
  Prior studies on SI have demonstrated empirical speedups (compared to non-SI)
but require a fast and accurate drafter LLM. In practice, off-the-shelf LLMs
often do not have matching drafters that are sufficiently fast and accurate. We
show a gap: SI gets slower than non-SI when using slower or less accurate
drafters. We close this gap by proving that DSI is faster than both SI and
non-SI given any drafters. By orchestrating multiple instances of the target
and drafters, DSI is not only faster than SI but also supports LLMs that cannot
be accelerated with SI.
  Our simulations show speedups of off-the-shelf LLMs in realistic settings:
DSI is 1.29-1.92x faster than SI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How well Chat<span class="highlight-title">GPT</span> understand Malaysian English? An Evaluation on Named
  Entity Recognition and Relation Extraction <span class="chip">EMNLP
  2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11583v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11583v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohan Raj Chanthran, Lay-Ki Soon, Huey Fang Ong, Bhawani Selvaretnam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, ChatGPT has attracted a lot of interest from both researchers and
the general public. While the performance of ChatGPT in named entity
recognition and relation extraction from Standard English texts is
satisfactory, it remains to be seen if it can perform similarly for Malaysian
English. Malaysian English is unique as it exhibits morphosyntactic and
semantical adaptation from local contexts. In this study, we assess ChatGPT's
capability in extracting entities and relations from the Malaysian English News
(MEN) dataset. We propose a three-step methodology referred to as
\textbf{\textit{educate-predict-evaluate}}. The performance of ChatGPT is
assessed using F1-Score across 18 unique prompt settings, which were carefully
engineered for a comprehensive review. From our evaluation, we found that
ChatGPT does not perform well in extracting entities from Malaysian English
news articles, with the highest F1-Score of 0.497. Further analysis shows that
the morphosyntactic adaptation in Malaysian English caused the limitation.
However, interestingly, this morphosyntactic adaptation does not impact the
performance of ChatGPT for relation extraction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Generation, Evaluation & Metrics (GEM) Workshop at EMNLP
  2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are LLM-based Evaluators Confusing NLG Quality Criteria? <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.12055v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.12055v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Hu, Mingqi Gao, Sen Hu, Yang Zhang, Yicheng Chen, Teng Xu, Xiaojun Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Some prior work has shown that LLMs perform well in NLG evaluation for
different tasks. However, we discover that LLMs seem to confuse different
evaluation criteria, which reduces their reliability. For further verification,
we first consider avoiding issues of inconsistent conceptualization and vague
expression in existing NLG quality criteria themselves. So we summarize a clear
hierarchical classification system for 11 common aspects with corresponding
different criteria from previous studies involved. Inspired by behavioral
testing, we elaborately design 18 types of aspect-targeted perturbation attacks
for fine-grained analysis of the evaluation behaviors of different LLMs. We
also conduct human annotations beyond the guidance of the classification system
to validate the impact of the perturbations. Our experimental results reveal
confusion issues inherent in LLMs, as well as other noteworthy phenomena, and
necessitate further research and improvements for LLM-based evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NoteChat: A <span class="highlight-title">Dataset</span> of Synthetic Doctor-Patient Conversations
  Conditioned on Clinical Notes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.15959v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.15959v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junda Wang, Zonghai Yao, Zhichao Yang, Huixue Zhou, Rumeng Li, Xun Wang, Yucheng Xu, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce NoteChat, a novel cooperative multi-agent framework leveraging
Large Language Models (LLMs) to generate patient-physician dialogues. NoteChat
embodies the principle that an ensemble of role-specific LLMs, through
structured role-play and strategic prompting, can perform their assigned roles
more effectively. The synergy among these role-playing LLMs results in a
cohesive and efficient dialogue generation. Evaluation on MTS-dialogue, a
benchmark dataset for patient-physician dialogues-note pairs, shows that models
trained with the augmented synthetic patient-physician dialogues by NoteChat
outperforms other state-of-the-art models for generating clinical notes. Our
comprehensive automatic and human evaluation demonstrates that NoteChat
substantially surpasses state-of-the-art models like ChatGPT and GPT-4 up to
22.78% by domain experts in generating superior synthetic patient-physician
dialogues based on clinical notes. NoteChat has the potential to engage
patients directly and help clinical documentation, a leading cause of physician
burnout.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning
  and Professional Question Answering Capability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17887v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17887v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junda Wang, Zhichao Yang, Zonghai Yao, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated a remarkable potential in
medical knowledge acquisition and question-answering. However, LLMs can
potentially hallucinate and yield factually incorrect outcomes, even with
domain-specific pretraining. Previously, retrieval augmented generation (RAG)
has limited success in addressing hallucinations. Unlike previous methods in
RAG where the retrieval model was trained separately from the LLM, we introduce
JMLR (for Jointly trains LLM and information Retrieval) during the fine-tuning
phase. The synchronized training mechanism enhances JMLR's ability to retrieve
clinical guidelines and leverage medical knowledge to reason and answer
questions and reduces the demand for computational resources. We evaluated JMLR
on the important medical question-answering application. Our experimental
results demonstrate that JMLR-13B (70.5%) outperforms a previous
state-of-the-art open-source model using conventional pre-training and
fine-tuning Meditron-70B (68.9%) and Llama2-13B with RAG (67.7%) on a medical
question-answering dataset. Comprehensive evaluations reveal JMLR-13B enhances
reasoning quality and reduces hallucinations better than Claude3-Opus.
Additionally, JMLR-13B (148 GPU hours) also trains much faster than
Meditron-70B (42630 GPU hours). Through this work, we provide a new and
efficient knowledge enhancement method for healthcare, demonstrating the
potential of integrating retrieval and LLM training for medical
question-answering systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LatentExplainer: Explaining Latent Representations in Deep Generative
  Models with Multi-modal Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14862v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14862v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models like VAEs and diffusion models have advanced various
generation tasks by leveraging latent variables to learn data distributions and
generate high-quality samples. Despite the field of explainable AI making
strides in interpreting machine learning models, understanding latent variables
in generative models remains challenging. This paper introduces
LatentExplainer, a framework for automatically generating semantically
meaningful explanations of latent variables in deep generative models.
LatentExplainer tackles three main challenges: inferring the meaning of latent
variables, aligning explanations with inductive biases, and handling varying
degrees of explainability. By perturbing latent variables and interpreting
changes in generated data, the framework provides a systematic approach to
understanding and controlling the data generation process, enhancing the
transparency and interpretability of deep generative models. We evaluate our
proposed method on several real-world and synthetic datasets, and the results
demonstrate superior performance in generating high-quality explanations of
latent variables.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Unified Data Augmentation Framework for Low-Resource Multi-Domain
  Dialogue Generation <span class="chip">ECML-PKDD</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09881v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09881v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongkang Liu, Ercong Nie, Shi Feng, Zheng Hua, Zifeng Ding, Daling Wang, Yifei Zhang, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current state-of-the-art dialogue systems heavily rely on extensive training
datasets. However, challenges arise in domains where domain-specific training
datasets are insufficient or entirely absent. To tackle this challenge, we
propose a novel data \textbf{A}ugmentation framework for
\textbf{M}ulti-\textbf{D}omain \textbf{D}ialogue \textbf{G}eneration, referred
to as \textbf{AMD$^2$G}. The AMD$^2$G framework consists of a data augmentation
process and a two-stage training approach: domain-agnostic training and domain
adaptation training. We posit that domain corpora are a blend of
domain-agnostic and domain-specific features, with certain representation
patterns shared among diverse domains. Domain-agnostic training aims to enable
models to learn these common expressive patterns. To construct domain-agnostic
dialogue corpora, we employ a \textit{\textbf{de-domaining}} data processing
technique used to remove domain-specific features. By mitigating the effects of
domain-specific features, the model trained on the de-domained corpora can
effectively learn common expression patterns in different domains.
Subsequently, we adapt the learned domain-agnostic features to the target
domain through domain adaptation training. We conduct experiments on Chinese
dialogue datasets from five different domains and show that AMD$^2$G achieves
superior performance compared to both direct training on the target domain
corpus and collective training on all five domain corpora. Our work underscores
AMD$^2$G as a viable alternative solution for low-resource multi-domain
dialogue generation. Code and data associated with our work are available on
GitHub repository$^{\text 1}$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17pages,ECML-PKDD</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do <span class="highlight-title">prompt</span> positions really matter? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14493v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14493v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyu Mao, Stuart E. Middleton, Mahesan Niranjan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt-based models have gathered a lot of attention from researchers due to
their remarkable advancements in the fields of zero-shot and few-shot learning.
Developing an effective prompt template plays a critical role. However, prior
studies have mainly focused on prompt vocabulary searching or embedding
initialization within a predefined template with the prompt position fixed. In
this empirical study, we conduct the most comprehensive analysis to date of
prompt position for diverse Natural Language Processing (NLP) tasks. Our
findings quantify the substantial impact prompt position has on model
performance. We observe that the prompt positions used in prior studies are
often sub-optimal, and this observation is consistent even in widely used
instruction-tuned models. These findings suggest prompt position optimisation
as a valuable research direction to augment prompt engineering methodologies
and prompt position-aware instruction tuning as a potential way to build more
robust models in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Airport Tower Command Recognition: Integrating
  Squeeze-and-Excitation and Broadcasted Residual Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18313v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18313v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanxi Lin, Tonglin Zhou, Yang Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate recognition of aviation commands is vital for flight safety and
efficiency, as pilots must follow air traffic control instructions precisely.
This paper addresses challenges in speech command recognition, such as noisy
environments and limited computational resources, by advancing keyword spotting
technology. We create a dataset of standardized airport tower commands,
including routine and emergency instructions. We enhance broadcasted residual
learning with squeeze-and-excitation and time-frame frequency-wise
squeeze-and-excitation techniques, resulting in our BC-SENet model. This model
focuses on crucial information with fewer parameters. Our tests on five keyword
spotting models, including BC-SENet, demonstrate superior accuracy and
efficiency. These findings highlight the effectiveness of our model
advancements in improving speech command recognition for aviation safety and
efficiency in noisy, high-stakes environments. Additionally, BC-SENet shows
comparable performance on the common Google Speech Command dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IALP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19232v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19232v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ekaterina Taktasheva, Maxim Bazhukov, Kirill Koncha, Alena Fenogenova, Ekaterina Artemova, Vladislav Mikhailov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Minimal pairs are a well-established approach to evaluating the grammatical
knowledge of language models. However, existing resources for minimal pairs
address a limited number of languages and lack diversity of language-specific
grammatical phenomena. This paper introduces the Russian Benchmark of
Linguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that
differ in grammaticality and isolate a morphological, syntactic, or semantic
phenomenon. In contrast to existing benchmarks of linguistic minimal pairs,
RuBLiMP is created by applying linguistic perturbations to automatically
annotated sentences from open text corpora and carefully curating test data. We
describe the data collection protocol and present the results of evaluating 25
language models in various scenarios. We find that the widely used language
models for Russian are sensitive to morphological and agreement-oriented
contrasts but fall behind humans on phenomena requiring understanding of
structural relations, negation, transitivity, and tense. RuBLiMP, the codebase,
and other materials are publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in
  Large Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Haotian Wang, Ming Liu, Bing Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Grasping the concept of time is a fundamental facet of human cognition,
indispensable for truly comprehending the intricacies of the world. Previous
studies typically focus on specific aspects of time, lacking a comprehensive
temporal reasoning benchmark. To address this, we propose TimeBench, a
comprehensive hierarchical temporal reasoning benchmark that covers a broad
spectrum of temporal reasoning phenomena. TimeBench provides a thorough
evaluation for investigating the temporal reasoning capabilities of large
language models. We conduct extensive experiments on GPT-4, LLaMA2, and other
popular LLMs under various settings. Our experimental results indicate a
significant performance gap between the state-of-the-art LLMs and humans,
highlighting that there is still a considerable distance to cover in temporal
reasoning. Besides, LLMs exhibit capability discrepancies across different
reasoning categories. Furthermore, we thoroughly analyze the impact of multiple
aspects on temporal reasoning and emphasize the associated challenges. We
aspire for TimeBench to serve as a comprehensive benchmark, fostering research
in temporal reasoning. Resources are available at:
https://github.com/zchuz/TimeBench
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A synthetic data approach for domain generalization of NLI models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.12368v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.12368v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Javad Hosseini, Andrey Petrov, Alex Fabrikant, Annie Louis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural Language Inference (NLI) remains an important benchmark task for
LLMs. NLI datasets are a springboard for transfer learning to other semantic
tasks, and NLI models are standard tools for identifying the faithfulness of
model-generated text. There are several large scale NLI datasets today, and
models have improved greatly by hill-climbing on these collections. Yet their
realistic performance on out-of-distribution/domain data is less
well-understood. We explore the opportunity for synthetic high-quality datasets
to adapt NLI models for zero-shot use in downstream applications across new and
unseen text domains. We demonstrate a new approach for generating NLI data in
diverse domains and lengths, so far not covered by existing training sets. The
resulting examples have meaningful premises, the hypotheses are formed in
creative ways rather than simple edits to a few premise tokens, and the labels
have high accuracy. We show that models trained on this data ($685$K synthetic
examples) have the best generalization to completely new downstream test
settings. On the TRUE benchmark, a T5-small model trained with our data
improves around $7\%$ on average compared to training on the best alternative
dataset. The improvements are more pronounced for smaller models, while still
meaningful on a T5 XXL model. We also demonstrate gains on test sets when
in-domain training data is augmented with our domain-general synthetic data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Chitchat as Interference: Adding User Backstories to Task-Oriented
  Dialogues <span class="chip">LREC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15248v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15248v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Armand Stricker, Patrick Paroubek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  During task-oriented dialogues (TODs), human users naturally introduce
chitchat that is beyond the immediate scope of the task, interfering with the
flow of the conversation. To address this issue without the need for expensive
manual data creation, we use few-shot prompting with Llama-2-70B to enhance the
MultiWOZ dataset with user backstories, a typical example of chitchat
interference in TODs. We assess the impact of this addition by testing two
models: one trained solely on TODs and another trained on TODs with a
preliminary chitchat interaction. Our analysis demonstrates that our enhanced
dataset poses a challenge for these systems. Moreover, we demonstrate that our
dataset can be effectively used for training purposes, enabling a system to
consistently acknowledge the user's backstory while also successfully moving
the task forward in the same turn, as confirmed by human evaluation. These
findings highlight the benefits of generating novel chitchat-TOD scenarios to
test TOD systems more thoroughly and improve their resilience to natural user
interferences
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted @ LREC-COLING 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MathChat: Converse to Tackle Challenging Math Problems with LLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.01337v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.01337v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Employing Large Language Models (LLMs) to address mathematical problems is an
intriguing research endeavor, considering the abundance of math problems
expressed in natural language across numerous science and engineering fields.
LLMs, with their generalized ability, are used as a foundation model to build
AI agents for different tasks. In this paper, we study the effectiveness of
utilizing LLM agents to solve math problems through conversations. We propose
MathChat, a conversational problem-solving framework designed for math
problems. MathChat consists of an LLM agent and a user proxy agent which is
responsible for tool execution and additional guidance. This synergy
facilitates a collaborative problem-solving process, where the agents engage in
a dialogue to solve the problems. We perform evaluation on difficult high
school competition problems from the MATH dataset. Utilizing Python, we show
that MathChat can further improve previous tool-using prompting methods by 6%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Update version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Unified Approach to Emotion Detection and Task-Oriented Dialogue
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.13789v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.13789v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Armand Stricker, Patrick Paroubek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In current text-based task-oriented dialogue (TOD) systems, user emotion
detection (ED) is often overlooked or is typically treated as a separate and
independent task, requiring additional training. In contrast, our work
demonstrates that seamlessly unifying ED and TOD modeling brings about mutual
benefits, and is therefore an alternative to be considered. Our method consists
in augmenting SimpleToD, an end-to-end TOD system, by extending belief state
tracking to include ED, relying on a single language model. We evaluate our
approach using GPT-2 and Llama-2 on the EmoWOZ benchmark, a version of MultiWOZ
annotated with emotions. Our results reveal a general increase in performance
for ED and task results. Our findings also indicate that user emotions provide
useful contextual conditioning for system responses, and can be leveraged to
further refine responses in terms of empathy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted @ IWSDS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16783v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16783v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rishabh Maheshwary, Vikas Yadav, Hoang Nguyen, Khyati Mahajan, Sathwik Tejaswi Madhusudhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction finetuning (IFT) is critical for aligning Large Language Models
(LLMs) to follow instructions. While many effective IFT datasets have been
introduced recently, they predominantly focus on high-resource languages like
English. To better align LLMs across a broad spectrum of languages and tasks,
we propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,
Multi-turn instruction finetuning dataset, called M2Lingual. It is constructed
by first selecting a diverse set of seed examples and then utilizing the
proposed Evol taxonomy to convert these seeds into complex and challenging
multi-turn instructions. We demonstrate the effectiveness of M2Lingual by
training LLMs of varying sizes and showcasing the enhanced performance across a
diverse set of languages. We contribute the 2 step Evol taxonomy with the
guided generation code: https://github.com/ServiceNow/M2Lingual, as well as the
first fully synthetic, general and task-oriented, multi-turn, multilingual
dataset built with Evol - M2Lingual:
https://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K
total IFT pairs, covering 70 languages and 17+ NLP tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>39 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity
  Text Embeddings Through Self-Knowledge Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03216v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03216v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, Zheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a new embedding model, called M3-Embedding, which
is distinguished for its versatility in Multi-Linguality, Multi-Functionality,
and Multi-Granularity. It can support more than 100 working languages, leading
to new state-of-the-art performances on multi-lingual and cross-lingual
retrieval tasks. It can simultaneously perform the three common retrieval
functionalities of embedding model: dense retrieval, multi-vector retrieval,
and sparse retrieval, which provides a unified model foundation for real-world
IR applications. It is able to process inputs of different granularities,
spanning from short sentences to long documents of up to 8192 tokens. The
effective training of M3-Embedding involves the following technical
contributions. We propose a novel self-knowledge distillation approach, where
the relevance scores from different retrieval functionalities can be integrated
as the teacher signal to enhance the training quality. We also optimize the
batching strategy, enabling a large batch size and high training throughput to
ensure the discriminativeness of embeddings. To the best of our knowledge,
M3-Embedding is the first embedding model which realizes such a strong
versatility. The model and code will be publicly available at
https://github.com/FlagOpen/FlagEmbedding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Enhanced Clustering for News Event Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10552v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10552v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adane Nega Tarekegn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The news landscape is continuously evolving, with an ever-increasing volume
of information from around the world. Automated event detection within this
vast data repository is essential for monitoring, identifying, and categorizing
significant news occurrences across diverse platforms. This paper presents an
event detection framework that leverages Large Language Models (LLMs) combined
with clustering analysis to detect news events from the Global Database of
Events, Language, and Tone (GDELT). The framework enhances event clustering
through both pre-event detection tasks (keyword extraction and text embedding)
and post-event detection tasks (event summarization and topic labelling). We
also evaluate the impact of various textual embeddings on the quality of
clustering outcomes, ensuring robust news categorization. Additionally, we
introduce a novel Cluster Stability Assessment Index (CSAI) to assess the
validity and robustness of clustering results. CSAI utilizes multiple feature
vectors to provide a new way of measuring clustering quality. Our experiments
indicate that the use of LLM embedding in the event detection framework has
significantly improved the results, demonstrating greater robustness in terms
of CSAI scores. Moreover, post-event detection tasks generate meaningful
insights, facilitating effective interpretation of event clustering results.
Overall, our experimental results indicate that the proposed framework offers
valuable insights and could enhance the accuracy in news analysis and
reporting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SampleAttention: Near-Lossless Acceleration of Long Context LLM
  Inference with Adaptive Structured Sparse Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15486v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15486v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianchao Zhu, Jiangfei Duan, Chang Chen, Siran Liu, Xiuhong Li, Guanyu Feng, Xin Lv, Huanqi Cao, Xiao Chuanfu, Xingcheng Zhang, Dahua Lin, Chao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) now support extremely long context windows, but
the quadratic complexity of vanilla attention results in significantly long
Time-to-First-Token (TTFT) latency. Existing approaches to address this
complexity require additional pretraining or finetuning, and often sacrifice
model accuracy. In this paper, we first provide both theoretical and empirical
foundations for near-lossless sparse attention. We find dynamically capturing
head-specific sparse patterns at runtime with low overhead is crucial. To
address this, we propose SampleAttention, an adaptive structured and
near-lossless sparse attention. Leveraging observed significant sparse
patterns, SampleAttention attends to a fixed percentage of adjacent tokens to
capture local window patterns, and employs a two-stage query-guided key-value
filtering approach, which adaptively select a minimum set of key-values with
low overhead, to capture column stripe patterns. Comprehensive evaluations show
that SampleAttention can seamlessly replace vanilla attention in off-the-shelf
LLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\times$
compared with FlashAttention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SciBench: Evaluating College-Level Scientific Problem-Solving Abilities
  of Large Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.10635v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.10635v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Arjun R. Loomba, Shichang Zhang, Yizhou Sun, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most of the existing Large Language Model (LLM) benchmarks on scientific
problem reasoning focus on problems grounded in high-school subjects and are
confined to elementary algebraic operations. To systematically examine the
reasoning capabilities required for solving complex scientific problems, we
introduce an expansive benchmark suite SciBench for LLMs. SciBench contains a
carefully curated dataset featuring a range of collegiate-level scientific
problems from mathematics, chemistry, and physics domains. Based on the
dataset, we conduct an in-depth benchmarking study of representative
open-source and proprietary LLMs with various prompting strategies. The results
reveal that the current LLMs fall short of delivering satisfactory performance,
with the best overall score of merely 43.22%. Furthermore, through a detailed
user study, we categorize the errors made by LLMs into ten problem-solving
abilities. Our analysis indicates that no single prompting strategy
significantly outperforms the others and some strategies that demonstrate
improvements in certain problem-solving skills could result in declines in
other skills. We envision that SciBench will catalyze further developments in
the reasoning abilities of LLMs, thereby ultimately contributing to scientific
research and discovery.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Active Preference Learning for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.08114v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.08114v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Muldrew, Peter Hayes, Mingtian Zhang, David Barber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) become more capable, fine-tuning techniques
for aligning with human intent are increasingly important. A key consideration
for aligning these models is how to most effectively use human resources, or
model resources in the case where LLMs themselves are used as oracles.
Reinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most
prominent example of such a technique, but is complex and often unstable.
Direct Preference Optimization (DPO) has recently been proposed as a simpler
and more stable alternative. In this work, we develop an active learning
strategy for DPO to make better use of preference labels. We propose a
practical acquisition function for prompt/completion pairs based on the
predictive entropy of the language model and a measure of certainty of the
implicit preference model optimized by DPO. We demonstrate how our approach
improves both the rate of learning and final performance of fine-tuning on
pairwise preference data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 5 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniGen: A Unified Framework for Textual <span class="highlight-title">Dataset</span> Generation Using Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18966v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18966v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, Lichao Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly
impacted various fields by enabling high-quality synthetic data generation and
reducing dependence on expensive human-generated datasets. Despite this,
challenges remain in the areas of generalization, controllability, diversity,
and truthfulness within the existing generative frameworks. To address these
challenges, this paper presents UniGen, a comprehensive LLM-powered framework
designed to produce diverse, accurate, and highly controllable datasets. UniGen
is adaptable, supporting all types of text datasets and enhancing the
generative process through innovative mechanisms. To augment data diversity,
UniGen incorporates an attribute-guided generation module and a group checking
feature. For accuracy, it employs a code-based mathematical assessment for
label verification alongside a retrieval-augmented generation technique for
factual validation. The framework also allows for user-specified constraints,
enabling customization of the data generation process to suit particular
requirements. Extensive experiments demonstrate the superior quality of data
generated by UniGen, and each module within UniGen plays a critical role in
this enhancement. Additionally, UniGen is applied in two practical scenarios:
benchmarking LLMs and data augmentation. The results indicate that UniGen
effectively supports dynamic and evolving benchmarking, and that data
augmentation improves LLM capabilities in various domains, including
agent-oriented abilities and reasoning skills.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Concept-aware Data Construction Improves In-context Learning of Language
  Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09703v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09703v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michal Štefánik, Marek Kadlčík, Petr Sojka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many recent language models (LMs) are capable of in-context learning (ICL),
manifested in the LMs' ability to perform a new task solely from
natural-language instruction. Previous work curating in-context learners
assumes that ICL emerges from a vast over-parametrization or the scale of
multi-task training. However, recent theoretical work attributes the ICL
ability to concept-dependent training data and creates functional in-context
learners even in small-scale, synthetic settings.
  In this work, we practically explore this newly identified axis of ICL
quality. We propose Concept-aware Training (CoAT), a framework for constructing
training scenarios that make it beneficial for the LM to learn to utilize the
analogical reasoning concepts from demonstrations. We find that by using CoAT,
pre-trained transformers can learn to better utilise new latent concepts from
demonstrations and that such ability makes ICL more robust to the functional
deficiencies of the previous models. Finally, we show that concept-aware
in-context learning is more effective for a majority of new tasks when compared
to traditional instruction tuning, resulting in a performance comparable to the
previous in-context learners using magnitudes of more training data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Long paper to appear in Findings of ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Logic Tree Extraction for Event Sequence Explanation from LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01124v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01124v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zitao Song, Chao Yang, Chaojie Wang, Bo An, Shuang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern high-stakes systems, such as healthcare or robotics, often generate
vast streaming event sequences. Our goal is to design an efficient,
plug-and-play tool to elicit logic tree-based explanations from Large Language
Models (LLMs) to provide customized insights into each observed event sequence.
Built on the temporal point process model for events, our method employs the
likelihood function as a score to evaluate generated logic trees. We propose an
amortized Expectation-Maximization (EM) learning framework and treat the logic
tree as latent variables. In the E-step, we evaluate the posterior distribution
over the latent logic trees using an LLM prior and the likelihood of the
observed event sequences. LLM provides a high-quality prior for the latent
logic trees, however, since the posterior is built over a discrete
combinatorial space, we cannot get the closed-form solution. We propose to
generate logic tree samples from the posterior using a learnable GFlowNet,
which is a diversity-seeking generator for structured discrete variables. The
M-step employs the generated logic rules to approximate marginalization over
the posterior, facilitating the learning of model parameters and refining the
tunable LLM prior parameters. In the online setting, our locally built,
lightweight model will iteratively extract the most relevant rules from LLMs
for each sequence using only a few iterations. Empirical demonstrations
showcase the promising performance and adaptability of our framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Logical Closed Loop: Uncovering Object Hallucinations in Large
  Vision-Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11622v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11622v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfei Wu, Qiang Liu, Ding Wang, Jinghao Zhang, Shu Wu, Liang Wang, Tieniu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object hallucination has been an Achilles' heel which hinders the broader
applications of large vision-language models (LVLMs). Object hallucination
refers to the phenomenon that the LVLMs claim non-existent objects in the
image. To mitigate the object hallucinations, instruction tuning and external
model-based detection methods have been proposed, which either require
large-scare computational resources or depend on the detection result of
external models. However, there remains an under-explored field to utilize the
LVLM itself to alleviate object hallucinations. In this work, we adopt the
intuition that the LVLM tends to respond logically consistently for existent
objects but inconsistently for hallucinated objects. Therefore, we propose a
Logical Closed Loop-based framework for Object Hallucination Detection and
Mitigation, namely LogicCheckGPT. In specific, we devise logical consistency
probing to raise questions with logical correlations, inquiring about
attributes from objects and vice versa. Whether their responses can form a
logical closed loop serves as an indicator of object hallucination. As a
plug-and-play method, it can be seamlessly applied to all existing LVLMs.
Comprehensive experiments conducted on three benchmarks across four LVLMs have
demonstrated significant improvements brought by our method, indicating its
effectiveness and generality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ANLS* -- A Universal Document Processing Metric for Generative Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03848v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03848v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Peer, Philemon Schöpf, Volckmar Nebendahl, Alexander Rietzler, Sebastian Stabinger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditionally, discriminative models have been the predominant choice for
tasks like document classification and information extraction. These models
make predictions that fall into a limited number of predefined classes,
facilitating a binary true or false evaluation and enabling the direct
calculation of metrics such as the F1 score. However, recent advancements in
generative large language models (GLLMs) have prompted a shift in the field due
to their enhanced zero-shot capabilities, which eliminate the need for a
downstream dataset and computationally expensive fine-tuning. However,
evaluating GLLMs presents a challenge as the binary true or false evaluation
used for discriminative models is not applicable to the predictions made by
GLLMs.
  This paper introduces a new metric for generative models called ANLS* for
evaluating a wide variety of tasks, including information extraction and
classification tasks. The ANLS* metric extends existing ANLS metrics as a
drop-in-replacement and is still compatible with previously reported ANLS
scores. An evaluation of 7 different datasets, and more than 10 different GLLMs
together with 3 different prompting methods using the ANLS* metric is also
provided, demonstrating the importance of the proposed metric.
  We also benchmark a novel approach to generate prompts for documents, called
SFT, against other prompting techniques such as LATIN. In 6 out of 7 cases, SFT
outperforms other techniques and improves the state-of-the-art, sometimes by as
much as $10$ percentage points.
  Sources are available at https://github.com/deepopinion/anls_star_metric
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does Geo-co-location Matter? A Case Study of Public Health Conversations
  during COVID-19 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17710v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17710v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paiheng Xu, Louiqa Raschid, Vanessa Frias-Martinez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media platforms like Twitter (now X) have been pivotal in information
dissemination and public engagement, especially during COVID-19. A key goal for
public health experts was to encourage prosocial behavior that could impact
local outcomes such as masking and social distancing. Given the importance of
local news and guidance during COVID-19, the objective of our research is to
analyze the effect of localized engagement, on social media conversations. This
study examines the impact of geographic co-location, as a proxy for localized
engagement between public health experts (PHEs) and the public, on social
media. We analyze a Twitter conversation dataset from January 2020 to November
2021, comprising over 19 K tweets from nearly five hundred PHEs, along with
approximately 800 K replies from 350 K participants. Our findings reveal that
geo-co-location is associated with higher engagement rates, especially in
conversations on topics including masking, lockdowns, and education, and in
conversations with academic and medical professionals. Lexical features
associated with emotion and personal experiences were more common in
geo-co-located contexts. This research provides insights into how geographic
co-location influences social media engagement and can inform strategies to
improve public health messaging.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Apollo: A Lightweight Multilingual Medical LLM towards Democratizing
  Medical AI to 6B People 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03640v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03640v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xidong Wang, Nuo Chen, Junyin Chen, Yan Hu, Yidong Wang, Xiangbo Wu, Anningzhe Gao, Xiang Wan, Haizhou Li, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the vast repository of global medical knowledge predominantly being
in English, local languages are crucial for delivering tailored healthcare
services, particularly in areas with limited medical resources. To extend the
reach of medical AI advancements to a broader population, we aim to develop
medical LLMs across the six most widely spoken languages, encompassing a global
population of 6.1 billion. This effort culminates in the creation of the
ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the
multilingual medical benchmark, the released Apollo models, at various
relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best
performance among models of equivalent size. Especially, Apollo-7B is the
state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite
models could be used to improve the multi-lingual medical capabilities of
larger models without fine-tuning in a proxy-tuning fashion. We will
open-source training corpora, code, model weights and evaluation benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SafeAligner: Safety Alignment against Jailbreak Attacks via Response
  Disparity Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18118v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18118v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Caishuang Huang, Wanxu Zhao, Rui Zheng, Huijie Lv, Shihan Dou, Sixian Li, Xiao Wang, Enyu Zhou, Junjie Ye, Yuming Yang, Tao Gui, Qi Zhang, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the development of large language models (LLMs) rapidly advances, securing
these models effectively without compromising their utility has become a
pivotal area of research. However, current defense strategies against jailbreak
attacks (i.e., efforts to bypass security protocols) often suffer from limited
adaptability, restricted general capability, and high cost. To address these
challenges, we introduce SafeAligner, a methodology implemented at the decoding
stage to fortify defenses against jailbreak attacks. We begin by developing two
specialized models: the Sentinel Model, which is trained to foster safety, and
the Intruder Model, designed to generate riskier responses. SafeAligner
leverages the disparity in security levels between the responses from these
models to differentiate between harmful and beneficial tokens, effectively
guiding the safety alignment by altering the output token distribution of the
target model. Extensive experiments show that SafeAligner can increase the
likelihood of beneficial tokens, while reducing the occurrence of harmful ones,
thereby ensuring secure alignment with minimal loss to generality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with
  Flowcharts <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for visual question answering lack in visual grounding
and complexity, particularly in evaluating spatial reasoning skills. We
introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of
visual question-answering multimodal language models in reasoning with
flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and
human-verified flowchart images from three distinct content sources, along with
22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,
including information localization, decision-making, and logical progression.
We conduct a thorough baseline evaluation on a suite of both open-source and
proprietary multimodal language models using various strategies, followed by an
analysis of directional bias. The results underscore the benchmark's potential
as a vital tool for advancing the field of multimodal modeling, providing a
focused and challenging environment for enhancing model performance in visual
and logical reasoning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ACL 2024 (Findings), 21 pages, 7 figures, 9 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WellDunn: On the Robustness and Explainability of Language Models and
  Large Language Models in Identifying Wellness Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12058v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12058v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seyedali Mohammadi, Edward Raff, Jinendra Malekar, Vedant Palit, Francis Ferraro, Manas Gaur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language Models (LMs) are being proposed for mental health applications where
the heightened risk of adverse outcomes means predictive performance may not be
a sufficient litmus test of a model's utility in clinical practice. A model
that can be trusted for practice should have a correspondence between
explanation and clinical determination, yet no prior research has examined the
attention fidelity of these models and their effect on ground truth
explanations. We introduce an evaluation design that focuses on the robustness
and explainability of LMs in identifying Wellness Dimensions (WD). We focus on
two mental health and well-being datasets: (a) Multi-label Classification-based
MultiWD, and (b) WellXplain for evaluating attention mechanism veracity against
expert-labeled explanations. The labels are based on Halbert Dunn's theory of
wellness, which gives grounding to our evaluation. We reveal four surprising
results about LMs/LLMs: (1) Despite their human-like capabilities, GPT-3.5/4
lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM fails to deliver any
remarkable improvements in performance or explanations. (2) Re-examining LMs'
predictions based on a confidence-oriented loss function reveals a significant
performance drop. (3) Across all LMs/LLMs, the alignment between attention and
explanations remains low, with LLMs scoring a dismal 0.0. (4) Most mental
health-specific LMs/LLMs overlook domain-specific knowledge and undervalue
explanations, causing these discrepancies. This study highlights the need for
further research into their consistency and explanations in mental health and
well-being.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, including reference and appendix sections, 8 figures, and
  16 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical
  Interaction Simulator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09742v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09742v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Fan, Jialong Tang, Wei Chen, Siyuan Wang, Zhongyu Wei, Jun Xi, Fei Huang, Jingren Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence has significantly advanced healthcare, particularly
through large language models (LLMs) that excel in medical question answering
benchmarks. However, their real-world clinical application remains limited due
to the complexities of doctor-patient interactions. To address this, we
introduce \textbf{AI Hospital}, a multi-agent framework simulating dynamic
medical interactions between \emph{Doctor} as player and NPCs including
\emph{Patient}, \emph{Examiner}, \emph{Chief Physician}. This setup allows for
realistic assessments of LLMs in clinical scenarios. We develop the Multi-View
Medical Evaluation (MVME) benchmark, utilizing high-quality Chinese medical
records and NPCs to evaluate LLMs' performance in symptom collection,
examination recommendations, and diagnoses. Additionally, a dispute resolution
collaborative mechanism is proposed to enhance diagnostic accuracy through
iterative discussions. Despite improvements, current LLMs exhibit significant
performance gaps in multi-turn interactions compared to one-step approaches.
Our findings highlight the need for further research to bridge these gaps and
improve LLMs' clinical diagnostic capabilities. Our data, code, and
experimental results are all open-sourced at
\url{https://github.com/LibertFan/AI_Hospital}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/LibertFan/AI_Hospital</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Navigating LLM Ethics: Advancements, Challenges, and Future Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18841v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18841v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Jiao, Saleh Afroogh, Yiming Xu, Connor Phillips
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study addresses ethical issues surrounding Large Language Models (LLMs)
within the field of artificial intelligence. It explores the common ethical
challenges posed by both LLMs and other AI systems, such as privacy and
fairness, as well as ethical challenges uniquely arising from LLMs. It
highlights challenges such as hallucination, verifiable accountability, and
decoding censorship complexity, which are unique to LLMs and distinct from
those encountered in traditional AI systems. The study underscores the need to
tackle these complexities to ensure accountability, reduce biases, and enhance
transparency in the influential role that LLMs play in shaping information
dissemination. It proposes mitigation strategies and future directions for LLM
ethics, advocating for interdisciplinary collaboration. It recommends ethical
frameworks tailored to specific domains and dynamic auditing systems adapted to
diverse contexts. This roadmap aims to guide responsible development and
integration of LLMs, envisioning a future where ethical considerations govern
AI advancements in society.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The global landscape of academic guidelines for generative AI and Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18842v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18842v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Jiao, Saleh Afroogh, Kevin Chen, David Atkinson, Amit Dhurandhar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of Generative Artificial Intelligence (GAI) and Large
Language Models (LLMs) in academia has spurred a global discourse on their
potential pedagogical benefits and ethical considerations. Positive reactions
highlight some potential, such as collaborative creativity, increased access to
education, and empowerment of trainers and trainees. However, negative
reactions raise concerns about ethical complexities, balancing innovation and
academic integrity, unequal access, and misinformation risks. Through a
systematic survey and text-mining-based analysis of global and national
directives, insights from independent research, and eighty university-level
guidelines, this study provides a nuanced understanding of the opportunities
and challenges posed by GAI and LLMs in education. It emphasizes the importance
of balanced approaches that harness the benefits of these technologies while
addressing ethical considerations and ensuring equitable access and educational
outcomes. The paper concludes with recommendations for fostering responsible
innovation and ethical practices to guide the integration of GAI and LLMs in
academia.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and
  Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.02990v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.02990v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bosheng Ding, Chengwei Qin, Ruochen Zhao, Tianze Luo, Xinze Li, Guizhen Chen, Wenhan Xia, Junjie Hu, Anh Tuan Luu, Shafiq Joty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving field of large language models (LLMs), data
augmentation (DA) has emerged as a pivotal technique for enhancing model
performance by diversifying training examples without the need for additional
data collection. This survey explores the transformative impact of LLMs on DA,
particularly addressing the unique challenges and opportunities they present in
the context of natural language processing (NLP) and beyond. From both data and
learning perspectives, we examine various strategies that utilize LLMs for data
augmentation, including a novel exploration of learning paradigms where
LLM-generated data is used for diverse forms of further training. Additionally,
this paper highlights the primary open challenges faced in this domain, ranging
from controllable data augmentation to multi-modal data augmentation. This
survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve
as a comprehensive guide for researchers and practitioners.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIntRec2.0: A Large-scale Benchmark <span class="highlight-title">Dataset</span> for Multimodal Intent
  Recognition and Out-of-scope Detection in Conversations <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10943v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10943v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanlei Zhang, Xin Wang, Hua Xu, Qianrui Zhou, Kai Gao, Jianhua Su, jinyue Zhao, Wenrui Li, Yanting Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal intent recognition poses significant challenges, requiring the
incorporation of non-verbal modalities from real-world contexts to enhance the
comprehension of human intentions. Existing benchmark datasets are limited in
scale and suffer from difficulties in handling out-of-scope samples that arise
in multi-turn conversational interactions. We introduce MIntRec2.0, a
large-scale benchmark dataset for multimodal intent recognition in multi-party
conversations. It contains 1,245 dialogues with 15,040 samples, each annotated
within a new intent taxonomy of 30 fine-grained classes. Besides 9,304 in-scope
samples, it also includes 5,736 out-of-scope samples appearing in multi-turn
contexts, which naturally occur in real-world scenarios. Furthermore, we
provide comprehensive information on the speakers in each utterance, enriching
its utility for multi-party conversational research. We establish a general
framework supporting the organization of single-turn and multi-turn dialogue
data, modality feature extraction, multimodal fusion, as well as in-scope
classification and out-of-scope detection. Evaluation benchmarks are built
using classic multimodal fusion methods, ChatGPT, and human evaluators. While
existing methods incorporating nonverbal information yield improvements,
effectively leveraging context information and detecting out-of-scope samples
remains a substantial challenge. Notably, large language models exhibit a
significant performance gap compared to humans, highlighting the limitations of
machine learning methods in the cognitive intent understanding task. We believe
that MIntRec2.0 will serve as a valuable resource, providing a pioneering
foundation for research in human-machine conversational interactions, and
significantly facilitating related applications. The full dataset and codes are
available at https://github.com/thuiar/MIntRec2.0.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2024, Long Paper; The abstract is slightly modified
  due to the length limitation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>ing Explicit and Implicit Knowledge for Multi-hop Question
  Answering Based on Human Reading Process <span class="chip">COLING 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.19350v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.19350v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangming Huang, Yunfei Long, Cunjin Luo, Jiaxing Shen, Xia Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to
simulate human reasoning and inference processes, achieving proficient
performance in multi-hop QA. However, a gap persists between PLMs' reasoning
abilities and those of humans when tackling complex problems. Psychological
studies suggest a vital connection between explicit information in passages and
human prior knowledge during reading. Nevertheless, current research has given
insufficient attention to linking input passages and PLMs' pre-training-based
knowledge from the perspective of human cognition studies. In this study, we
introduce a Prompting Explicit and Implicit knowledge (PEI) framework, which
uses prompts to connect explicit and implicit knowledge, aligning with human
reading process for multi-hop QA. We consider the input passages as explicit
knowledge, employing them to elicit implicit knowledge through unified prompt
reasoning. Furthermore, our model incorporates type-specific reasoning via
prompts, a form of implicit knowledge. Experimental results show that PEI
performs comparably to the state-of-the-art on HotpotQA. Ablation studies
confirm the efficacy of our model in bridging and integrating explicit and
implicit knowledge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted at COLING 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">90</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Odd-One-Out: Anomaly Detection by Comparing with Neighbors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20099v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20099v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ankan Bhunia, Changjian Li, Hakan Bilen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel anomaly detection (AD) problem that focuses on
identifying `odd-looking' objects relative to the other instances within a
scene. Unlike the traditional AD benchmarks, in our setting, anomalies in this
context are scene-specific, defined by the regular instances that make up the
majority. Since object instances are often partly visible from a single
viewpoint, our setting provides multiple views of each scene as input. To
provide a testbed for future research in this task, we introduce two
benchmarks, ToysAD-8K and PartsAD-15K. We propose a novel method that generates
3D object-centric representations for each instance and detects the anomalous
ones through a cross-examination between the instances. We rigorously analyze
our method quantitatively and qualitatively in the presented benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Codes & Dataset at https://github.com/VICO-UoE/OddOneOutAD</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Web2Code: A Large-scale Webpage-to-Code <span class="highlight-title">Dataset</span> and Evaluation Framework
  for Multimodal LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20098v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20098v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sukmin Yun, Haokun Lin, Rusiru Thushara, Mohammad Qazim Bhat, Yongxin Wang, Zutao Jiang, Mingkai Deng, Jinhong Wang, Tianhua Tao, Junbo Li, Haonan Li, Preslav Nakov, Timothy Baldwin, Zhengzhong Liu, Eric P. Xing, Xiaodan Liang, Zhiqiang Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) have shown impressive success across
modalities such as image, video, and audio in a variety of understanding and
generation tasks. However, current MLLMs are surprisingly poor at understanding
webpage screenshots and generating their corresponding HTML code. To address
this problem, we propose Web2Code, a benchmark consisting of a new large-scale
webpage-to-code dataset for instruction tuning and an evaluation framework for
the webpage understanding and HTML code translation abilities of MLLMs. For
dataset construction, we leverage pretrained LLMs to enhance existing
webpage-to-code datasets as well as generate a diverse pool of new webpages
rendered into images. Specifically, the inputs are webpage images and
instructions, while the responses are the webpage's HTML code. We further
include diverse natural language QA pairs about the webpage content in the
responses to enable a more comprehensive understanding of the web content. To
evaluate model performance in these tasks, we develop an evaluation framework
for testing MLLMs' abilities in webpage understanding and web-to-code
generation. Extensive experiments show that our proposed dataset is beneficial
not only to our proposed tasks but also in the general visual domain, while
previous datasets result in worse performance. We hope our work will contribute
to the development of general MLLMs suitable for web-based content generation
and task automation. Our data and code will be available at
https://github.com/MBZUAI-LLM/web2code.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Website at https://mbzuai-llm.github.io/webpage2code/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLaRA: Supercharging Robot Learning Data for Vision-Language Policy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) equipped with extensive world knowledge and
strong reasoning skills can tackle diverse tasks across domains, often by
posing them as conversation-style instruction-response pairs. In this paper, we
propose LLaRA: Large Language and Robotics Assistant, a framework which
formulates robot action policy as conversations, and provides improved
responses when trained with auxiliary data that complements policy learning.
LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity
to process state information as visual-textual prompts and generate optimal
policy decisions in text. To train such action policy VLMs, we first introduce
an automated pipeline to generate diverse high-quality robotics instruction
data from existing behavior cloning data. A VLM finetuned with the resulting
collection of datasets based on a conversation-style formulation tailored for
robotics tasks, can generate meaningful robot action policy decisions. Our
experiments across multiple simulated and real-world environments demonstrate
the state-of-the-art performance of the proposed LLaRA framework. The code,
datasets, and pretrained models are available at
https://github.com/LostXine/LLaRA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLaVolta: Efficient Multi-modal Models via Stage-wise Visual Context
  Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20092v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20092v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jieneng Chen, Luoxin Ye, Ju He, Zhao-Yang Wang, Daniel Khashabi, Alan Yuille
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While significant advancements have been made in compressed representations
for text embeddings in large language models (LLMs), the compression of visual
tokens in large multi-modal models (LMMs) has remained a largely overlooked
area. In this work, we present the study on the analysis of redundancy
concerning visual tokens and efficient training within these models. Our
initial experiments show that eliminating up to 70% of visual tokens at the
testing stage by simply average pooling only leads to a minimal 3% reduction in
visual question answering accuracy on the GQA benchmark, indicating significant
redundancy in visual context. Addressing this, we introduce Visual Context
Compressor, which reduces the number of visual tokens during training to
enhance training efficiency without sacrificing performance. To minimize
information loss caused by the compression on visual tokens while maintaining
training efficiency, we develop LLaVolta as a lite training scheme. LLaVolta
incorporates stage-wise visual context compression to progressively compress
the visual tokens from heavily to lightly, and finally no compression at the
end of training, yielding no loss of information when testing. Extensive
experiments demonstrate that our approach enhances the performance of MLLMs in
both image-language and video-language understanding, while also significantly
cutting training costs. Code is available at
https://github.com/Beckschen/LLaVolta
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available at https://github.com/Beckschen/LLaVolta</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Auto Cherry-Picker: Learning from High-quality Generative Data Driven by
  Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20085v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20085v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yicheng Chen, Xiangtai Li, Yining Li, Yanhong Zeng, Jianzong Wu, Xiangyu Zhao, Kai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based models have shown great potential in generating high-quality
images with various layouts, which can benefit downstream perception tasks.
However, a fully automatic layout generation driven only by language and a
suitable metric for measuring multiple generated instances has not been well
explored. In this work, we present Auto Cherry-Picker (ACP), a novel framework
that generates high-quality multi-modal training examples to augment perception
and multi-modal training. Starting with a simple list of natural language
concepts, we prompt large language models (LLMs) to generate a detailed
description and design reasonable layouts. Next, we use an off-the-shelf
text-to-image model to generate multiple images. Then, the generated data are
refined using a comprehensively designed metric to ensure quality. In
particular, we present a new metric, Composite Layout and Image Score (CLIS),
to evaluate the generated images fairly. Our synthetic high-quality examples
boost performance in various scenarios by customizing the initial concept list,
especially in addressing challenges associated with long-tailed distribution
and imbalanced datasets. Experiment results on downstream tasks demonstrate
that Auto Cherry-Picker can significantly improve the performance of existing
models. In addition, we have thoroughly investigated the correlation between
CLIS and performance gains in downstream tasks, and we find that a better CLIS
score results in better performance. This finding shows the potential for
evaluation metrics as the role for various visual perception and MLLM tasks.
Code will be available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PoliFormer: Scaling On-Policy RL with <span class="highlight-title">Transformer</span>s Results in Masterful
  Navigators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20083v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20083v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuo-Hao Zeng, Zichen Zhang, Kiana Ehsani, Rose Hendrix, Jordi Salvador, Alvaro Herrasti, Ross Girshick, Aniruddha Kembhavi, Luca Weihs
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present PoliFormer (Policy Transformer), an RGB-only indoor navigation
agent trained end-to-end with reinforcement learning at scale that generalizes
to the real-world without adaptation despite being trained purely in
simulation. PoliFormer uses a foundational vision transformer encoder with a
causal transformer decoder enabling long-term memory and reasoning. It is
trained for hundreds of millions of interactions across diverse environments,
leveraging parallelized, multi-machine rollouts for efficient training with
high throughput. PoliFormer is a masterful navigator, producing
state-of-the-art results across two distinct embodiments, the LoCoBot and
Stretch RE-1 robots, and four navigation benchmarks. It breaks through the
plateaus of previous work, achieving an unprecedented 85.5% success rate in
object goal navigation on the CHORES-S benchmark, a 28.5% absolute improvement.
PoliFormer can also be trivially extended to a variety of downstream
applications such as object tracking, multi-object navigation, and
open-vocabulary navigation with no finetuning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Segment Anything without Supervision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20081v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20081v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        XuDong Wang, Jingfeng Yang, Trevor Darrell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Segmentation Anything Model (SAM) requires labor-intensive data labeling.
We present Unsupervised SAM (UnSAM) for promptable and automatic whole-image
segmentation that does not require human annotations. UnSAM utilizes a
divide-and-conquer strategy to "discover" the hierarchical structure of visual
scenes. We first leverage top-down clustering methods to partition an unlabeled
image into instance/semantic level segments. For all pixels within a segment, a
bottom-up clustering method is employed to iteratively merge them into larger
groups, thereby forming a hierarchical structure. These unsupervised
multi-granular masks are then utilized to supervise model training. Evaluated
across seven popular datasets, UnSAM achieves competitive results with the
supervised counterpart SAM, and surpasses the previous state-of-the-art in
unsupervised segmentation by 11% in terms of AR. Moreover, we show that
supervised SAM can also benefit from our self-supervised labels. By integrating
our unsupervised pseudo masks into SA-1B's ground-truth masks and training
UnSAM with only 1% of SA-1B, a lightly semi-supervised UnSAM can often segment
entities overlooked by supervised SAM, exceeding SAM's AR by over 6.7% and AP
by 3.9% on SA-1B.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/frank-xwang/UnSAM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GM-DF: Generalized Multi-Scenario Deepfake Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingxin Lai, Zitong Yu, Jing Yang, Bin Li, Xiangui Kang, Linlin Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing face forgery detection usually follows the paradigm of training
models in a single domain, which leads to limited generalization capacity when
unseen scenarios and unknown attacks occur. In this paper, we elaborately
investigate the generalization capacity of deepfake detection models when
jointly trained on multiple face forgery detection datasets. We first find a
rapid degradation of detection accuracy when models are directly trained on
combined datasets due to the discrepancy across collection scenarios and
generation methods. To address the above issue, a Generalized Multi-Scenario
Deepfake Detection framework (GM-DF) is proposed to serve multiple real-world
scenarios by a unified model. First, we propose a hybrid expert modeling
approach for domain-specific real/forgery feature extraction. Besides, as for
the commonality representation, we use CLIP to extract the common features for
better aligning visual and textual features across domains. Meanwhile, we
introduce a masked image reconstruction mechanism to force models to capture
rich forged details. Finally, we supervise the models via a domain-aware
meta-learning strategy to further enhance their generalization capacities.
Specifically, we design a novel domain alignment loss to strongly align the
distributions of the meta-test domains and meta-train domains. Thus, the
updated models are able to represent both specific and common real/forgery
features across multiple datasets. In consideration of the lack of study of
multi-dataset training, we establish a new benchmark leveraging multi-source
data to fairly evaluate the models' generalization capacity on unseen
scenarios. Both qualitative and quantitative experiments on five datasets
conducted on traditional protocols as well as the proposed benchmark
demonstrate the effectiveness of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20077v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20077v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hieu T. Nguyen, Yiwen Chen, Vikram Voleti, Varun Jampani, Huaizu Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce HouseCrafter, a novel approach that can lift a floorplan into a
complete large 3D indoor scene (e.g., a house). Our key insight is to adapt a
2D diffusion model, which is trained on web-scale images, to generate
consistent multi-view color (RGB) and depth (D) images across different
locations of the scene. Specifically, the RGB-D images are generated
autoregressively in a batch-wise manner along sampled locations based on the
floorplan, where previously generated images are used as condition to the
diffusion model to produce images at nearby locations. The global floorplan and
attention design in the diffusion model ensures the consistency of the
generated images, from which a 3D scene can be reconstructed. Through extensive
evaluation on the 3D-Front dataset, we demonstrate that HouseCraft can generate
high-quality house-scale 3D scenes. Ablation studies also validate the
effectiveness of different design choices. We will release our code and model
weights. Project page: https://neu-vi.github.io/houseCrafter/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EVF-SAM: Early Vision-Language Fusion for Text-<span class="highlight-title">Prompt</span>ed Segment Anything
  Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20076v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20076v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhang, Tianheng Cheng, Rui Hu, ei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, Xinggang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Segment Anything Model (SAM) has attracted widespread attention for its
superior interactive segmentation capabilities with visual prompts while
lacking further exploration of text prompts. In this paper, we empirically
investigate what text prompt encoders (e.g., CLIP or LLM) are good for adapting
SAM for referring expression segmentation and introduce the Early
Vision-language Fusion-based SAM (EVF-SAM). EVF-SAM is a simple yet effective
referring segmentation method which exploits multimodal prompts (i.e., image
and text) and comprises a pre-trained vision-language model to generate
referring prompts and a SAM model for segmentation. Surprisingly, we observe
that: (1) multimodal prompts and (2) vision-language models with early fusion
(e.g., BEIT-3) are beneficial for prompting SAM for accurate referring
segmentation. Our experiments show that the proposed EVF-SAM based on BEIT-3
can obtain state-of-the-art performance on RefCOCO/+/g for referring expression
segmentation and demonstrate the superiority of prompting SAM with early
vision-language fusion. In addition, the proposed EVF-SAM with 1.32B parameters
achieves remarkably higher performance while reducing nearly 82% of parameters
compared to previous SAM methods based on large multimodal models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ASSR-NeRF: Arbitrary-Scale Super-Resolution on Voxel Grid for
  High-Quality Radiance Fields Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20066v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20066v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ding-Jiun Huang, Zi-Ting Chou, Yu-Chiang Frank Wang, Cheng Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  NeRF-based methods reconstruct 3D scenes by building a radiance field with
implicit or explicit representations. While NeRF-based methods can perform
novel view synthesis (NVS) at arbitrary scale, the performance in
high-resolution novel view synthesis (HRNVS) with low-resolution (LR)
optimization often results in oversmoothing. On the other hand, single-image
super-resolution (SR) aims to enhance LR images to HR counterparts but lacks
multi-view consistency. To address these challenges, we propose Arbitrary-Scale
Super-Resolution NeRF (ASSR-NeRF), a novel framework for super-resolution novel
view synthesis (SRNVS). We propose an attention-based VoxelGridSR model to
directly perform 3D super-resolution (SR) on the optimized volume. Our model is
trained on diverse scenes to ensure generalizability. For unseen scenes trained
with LR views, we then can directly apply our VoxelGridSR to further refine the
volume and achieve multi-view consistent SR. We demonstrate quantitative and
qualitatively that the proposed method achieves significant performance in
SRNVS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20055v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20055v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Sabour, Lily Goli, George Kopanas, Mark Matthews, Dmitry Lagun, Leonidas Guibas, Alec Jacobson, David J. Fleet, Andrea Tagliasacchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Gaussian Splatting (3DGS) is a promising technique for 3D reconstruction,
offering efficient training and rendering speeds, making it suitable for
real-time applications.However, current methods require highly controlled
environments (no moving people or wind-blown elements, and consistent lighting)
to meet the inter-view consistency assumption of 3DGS. This makes
reconstruction of real-world captures problematic. We present SpotlessSplats,
an approach that leverages pre-trained and general-purpose features coupled
with robust optimization to effectively ignore transient distractors. Our
method achieves state-of-the-art reconstruction quality both visually and
quantitatively, on casual captures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HAITCH: A Framework for Distortion and Motion Correction in Fetal
  Multi-Shell Diffusion-Weighted MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20042v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20042v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haykel Snoussi, Davood Karimi, Onur Afacan, Mustafa Utkur, Ali Gholipour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion magnetic resonance imaging (dMRI) is pivotal for probing the
microstructure of the rapidly-developing fetal brain. However, fetal motion
during scans and its interaction with magnetic field inhomogeneities result in
artifacts and data scattering across spatial and angular domains. The effects
of those artifacts are more pronounced in high-angular resolution fetal dMRI,
where signal-to-noise ratio is very low. Those effects lead to biased estimates
and compromise the consistency and reliability of dMRI analysis. This work
presents HAITCH, the first and the only publicly available tool to correct and
reconstruct multi-shell high-angular resolution fetal dMRI data. HAITCH offers
several technical advances that include a blip-reversed dual-echo acquisition
for dynamic distortion correction, advanced motion correction for model-free
and robust reconstruction, optimized multi-shell design for enhanced
information capture and increased tolerance to motion, and outlier detection
for improved reconstruction fidelity. The framework is open-source, flexible,
and can be used to process any type of fetal dMRI data including single-echo or
single-shell acquisitions, but is most effective when used with multi-shell
multi-echo fetal dMRI data that cannot be processed with any of the existing
tools. Validation experiments on real fetal dMRI scans demonstrate significant
improvements and accurate correction across diverse fetal ages and motion
levels. HAITCH successfully removes artifacts and reconstructs high-fidelity
fetal dMRI data suitable for advanced diffusion modeling, including fiber
orientation distribution function estimation. These advancements pave the way
for more reliable analysis of the fetal brain microstructure and tractography
under challenging imaging conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ eMoE-Tracker: Environmental MoE-based <span class="highlight-title">Transformer</span> for Robust
  Event-guided Object Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20024v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20024v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucheng Chen, Lin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The unique complementarity of frame-based and event cameras for high frame
rate object tracking has recently inspired some research attempts to develop
multi-modal fusion approaches. However, these methods directly fuse both
modalities and thus ignore the environmental attributes, e.g., motion blur,
illumination variance, occlusion, scale variation, etc. Meanwhile, no
interaction between search and template features makes distinguishing target
objects and backgrounds difficult. As a result, performance degradation is
induced especially in challenging conditions. This paper proposes a novel and
effective Transformer-based event-guided tracking framework, called
eMoE-Tracker, which achieves new SOTA performance under various conditions. Our
key idea is to disentangle the environment into several learnable attributes to
dynamically learn the attribute-specific features for better interaction and
discriminability between the target information and background. To achieve the
goal, we first propose an environmental Mix-of-Experts (eMoE) module that is
built upon the environmental Attributes Disentanglement to learn
attribute-specific features and environmental Attributes Gating to assemble the
attribute-specific features by the learnable attribute scores dynamically. The
eMoE module is a subtle router that fine-tunes the transformer backbone more
efficiently. We then introduce a contrastive relation modeling (CRM) module to
improve interaction and discriminability between the target information and
background. Extensive experiments on diverse event-based benchmark datasets
showcase the superior performance of our eMoE-Tracker compared to the prior
arts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>RGB-event single object tracking</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Malaria Cell Detection Using Deep Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20005v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20005v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saurabh Sawant, Anurag Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Malaria remains one of the most pressing public health concerns globally,
causing significant morbidity and mortality, especially in sub-Saharan Africa.
Rapid and accurate diagnosis is crucial for effective treatment and disease
management. Traditional diagnostic methods, such as microscopic examination of
blood smears, are labor-intensive and require significant expertise, which may
not be readily available in resource-limited settings. This project aims to
automate the detection of malaria-infected cells using a deep learning
approach. We employed a convolutional neural network (CNN) based on the
ResNet50 architecture, leveraging transfer learning to enhance performance. The
Malaria Cell Images Dataset from Kaggle, containing 27,558 images categorized
into infected and uninfected cells, was used for training and evaluation. Our
model demonstrated high accuracy, precision, and recall, indicating its
potential as a reliable tool for assisting in malaria diagnosis. Additionally,
a web application was developed using Streamlit to allow users to upload cell
images and receive predictions about malaria infection, making the technology
accessible and user-friendly. This paper provides a comprehensive overview of
the methodology, experiments, and results, highlighting the effectiveness of
deep learning in medical image analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wavelets Are All You Need for Autoregressive Image Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wael Mattar, Idan Levy, Nir Sharon, Shai Dekel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we take a new approach to autoregressive image generation that
is based on two main ingredients. The first is wavelet image coding, which
allows to tokenize the visual details of an image from coarse to fine details
by ordering the information starting with the most significant bits of the most
significant wavelet coefficients. The second is a variant of a language
transformer whose architecture is re-designed and optimized for token sequences
in this 'wavelet language'. The transformer learns the significant statistical
correlations within a token sequence, which are the manifestations of
well-known correlations between the wavelet subbands at various resolutions. We
show experimental results with conditioning on the generation process.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STLLaVA-Med: Self-Training Large Language and Vision Assistant for
  Medical 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19973v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19973v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guohao Sun, Can Qin, Huazhu Fu, Linwei Wang, Zhiqiang Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) have shown significant potential in
assisting medical diagnosis by leveraging extensive biomedical datasets.
However, the advancement of medical image understanding and reasoning
critically depends on building high-quality visual instruction data, which is
costly and labor-intensive to obtain, particularly in the medical domain. To
mitigate this data-starving issue, we introduce Self-Training Large Language
and Vision Assistant for Medical (STLLaVA-Med). The proposed method is designed
to train a policy model (an LVLM) capable of auto-generating medical visual
instruction data to improve data efficiency, guided through Direct Preference
Optimization (DPO). Specifically, a more powerful and larger LVLM (e.g.,
GPT-4o) is involved as a biomedical expert to oversee the DPO fine-tuning
process on the auto-generated data, encouraging the policy model to align
efficiently with human preferences. We validate the efficacy and data
efficiency of STLLaVA-Med across three major medical Visual Question Answering
(VQA) benchmarks, demonstrating competitive zero-shot performance with the
utilization of only 9% of the medical data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Impact of Initialization on Intra-subject Pediatric Brain MR Image
  Registration: A Comparative Analysis between SyN ANTs and Deep Learning-Based
  Approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19943v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19943v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andjela Dimitrijevic, Vincent Noblet, Benjamin De Leener
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study evaluates the performance of conventional SyN ANTs and
learning-based registration methods in the context of pediatric neuroimaging,
specifically focusing on intrasubject deformable registration. The comparison
involves three approaches: without (NR), with rigid (RR), and with rigid and
affine (RAR) initializations. In addition to initialization, performances are
evaluated in terms of accuracy, speed, and the impact of age intervals and sex
per pair. Data consists of the publicly available MRI scans from the Calgary
Preschool dataset, which includes 63 children aged 2-7 years, allowing for 431
registration pairs. We implemented the unsupervised DL framework with a U-Net
architecture using DeepReg and it was 5-fold cross-validated. Evaluation
includes Dice scores for tissue segmentation from 18 smaller regions obtained
by SynthSeg, analysis of log Jacobian determinants, and registration pro-rated
training and inference times. Learning-based approaches, with or without linear
initializations, exhibit slight superiority over SyN ANTs in terms of Dice
scores. Indeed, DL-based implementations with RR and RAR initializations
significantly outperform SyN ANTs. Both SyN ANTs and DL-based registration
involve parameter optimization, but the choice between these methods depends on
the scale of registration: network-based for broader coverage or SyN ANTs for
specific structures. Both methods face challenges with larger age intervals due
to greater growth changes. The main takeaway is that while DL-based methods
show promise with faster and more accurate registrations, SyN ANTs remains
robust and generalizable without the need for extensive training, highlighting
the importance of method selection based on specific registration needs in the
pediatric context. Our code is available at
https://github.com/neuropoly/pediatric-DL-registration
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org/2024:013</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GRACE: Graph-Regularized Attentive Convolutional Entanglement with
  Laplacian Smoothing for Robust DeepFake Video Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19941v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19941v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chih-Chung Hsu, Shao-Ning Chen, Mei-Hsuan Wu, Yi-Fang Wang, Chia-Ming Lee, Yi-Shiuan Chou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As DeepFake video manipulation techniques escalate, posing profound threats,
the urgent need to develop efficient detection strategies is underscored.
However, one particular issue lies with facial images being mis-detected, often
originating from degraded videos or adversarial attacks, leading to unexpected
temporal artifacts that can undermine the efficacy of DeepFake video detection
techniques. This paper introduces a novel method for robust DeepFake video
detection, harnessing the power of the proposed Graph-Regularized Attentive
Convolutional Entanglement (GRACE) based on the graph convolutional network
with graph Laplacian to address the aforementioned challenges. First,
conventional Convolution Neural Networks are deployed to perform spatiotemporal
features for the entire video. Then, the spatial and temporal features are
mutually entangled by constructing a graph with sparse constraint, enforcing
essential features of valid face images in the noisy face sequences remaining,
thus augmenting stability and performance for DeepFake video detection.
Furthermore, the Graph Laplacian prior is proposed in the graph convolutional
network to remove the noise pattern in the feature space to further improve the
performance. Comprehensive experiments are conducted to illustrate that our
proposed method delivers state-of-the-art performance in DeepFake video
detection under noisy face sequences. The source code is available at
https://github.com/ming053l/GRACE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to TPAMI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parallax-tolerant Image Stitching via Segmentation-guided
  Multi-homography Warping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19922v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19922v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianli Liao, Ce Wang, Lei Li, Guangen Liu, Nan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large parallax between images is an intractable issue in image stitching.
Various warping-based methods are proposed to address it, yet the results are
unsatisfactory. In this paper, we propose a novel image stitching method using
multi-homography warping guided by image segmentation. Specifically, we
leverage the Segment Anything Model to segment the target image into numerous
contents and partition the feature points into multiple subsets via the
energy-based multi-homography fitting algorithm. The multiple subsets of
feature points are used to calculate the corresponding multiple homographies.
For each segmented content in the overlapping region, we select its
best-fitting homography with the lowest photometric error. For each segmented
content in the non-overlapping region, we calculate a weighted combination of
the linearized homographies. Finally, the target image is warped via the
best-fitting homographies to align with the reference image, and the final
panorama is generated via linear blending. Comprehensive experimental results
on the public datasets demonstrate that our method provides the best alignment
accuracy by a large margin, compared with the state-of-the-art methods. The
source code is available at https://github.com/tlliao/multi-homo-warp.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Solving Token Gradient Conflict in Mixture-of-Experts for Large
  Vision-Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19905v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19905v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longrong Yang, Dong Sheng, Chaoxiang Cai, Fan Yang, Size Li, Di Zhang, Xi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Mixture-of-Experts (MoE) has gained increasing attention in the study of
Large Vision-Language Models (LVLMs). It uses a sparse model to replace the
dense model, achieving comparable performance while activating fewer parameters
during inference, thus significantly reducing the inference cost. Existing MoE
methods in LVLMs encourage different experts to handle different tokens, and
thus they employ a router to predict the routing for each token. However, the
predictions are based solely on sample features and do not truly reveal the
optimization direction of tokens. This can lead to severe optimization
conflicts between different tokens within an expert. To address this problem,
this paper proposes a novel method based on token-level gradient analysis.
Specifically, we first use token-level gradients to identify conflicting tokens
in experts. Then, we add a specialized loss tailored to eliminate conflicts
among tokens within each expert. Our method can serve as a plug-in for diverse
Large Vision-Language Models, and extensive experimental results demonstrate
the effectiveness of our method. The code will be publicly available at
https://github.com/longrongyang/STGC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Value of PHH3 for Mitotic Figure Detection on H&E-stained Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19899v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19899v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Ganz, Christian Marzahl, Jonas Ammeling, Barbara Richter, Chloé Puget, Daniela Denk, Elena A. Demeter, Flaviu A. Tabaran, Gabriel Wasinger, Karoline Lipnik, Marco Tecilla, Matthew J. Valentine, Michael J. Dark, Niklas Abele, Pompei Bolfa, Ramona Erber, Robert Klopfleisch, Sophie Merz, Taryn A. Donovan, Samir Jabari, Christof A. Bertram, Katharina Breininger, Marc Aubreville
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The count of mitotic figures (MFs) observed in hematoxylin and eosin
(H&E)-stained slides is an important prognostic marker as it is a measure for
tumor cell proliferation. However, the identification of MFs has a known low
inter-rater agreement. Deep learning algorithms can standardize this task, but
they require large amounts of annotated data for training and validation.
Furthermore, label noise introduced during the annotation process may impede
the algorithm's performance. Unlike H&E, the mitosis-specific antibody
phospho-histone H3 (PHH3) specifically highlights MFs. Counting MFs on slides
stained against PHH3 leads to higher agreement among raters and has therefore
recently been used as a ground truth for the annotation of MFs in H&E. However,
as PHH3 facilitates the recognition of cells indistinguishable from H&E stain
alone, the use of this ground truth could potentially introduce noise into the
H&E-related dataset, impacting model performance. This study analyzes the
impact of PHH3-assisted MF annotation on inter-rater reliability and object
level agreement through an extensive multi-rater experiment. We found that the
annotators' object-level agreement increased when using PHH3-assisted labeling.
Subsequently, MF detectors were evaluated on the resulting datasets to
investigate the influence of PHH3-assisted labeling on the models' performance.
Additionally, a novel dual-stain MF detector was developed to investigate the
interpretation-shift of PHH3-assisted labels used in H&E, which clearly
outperformed single-stain detectors. However, the PHH3-assisted labels did not
have a positive effect on solely H&E-based models. The high performance of our
dual-input detector reveals an information mismatch between the H&E and
PHH3-stained images as the cause of this effect.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures, 1 Table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InfiniBench: A Comprehensive Benchmark for Large Multimodal Models in
  Very Long Video Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19875v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19875v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kirolos Ataallah, Chenhui Gou, Eslam Abdelrahman, Khushbu Pahwa, Jian Ding, Mohamed Elhoseiny
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding long videos, ranging from tens of minutes to several hours,
presents unique challenges in video comprehension. Despite the increasing
importance of long-form video content, existing benchmarks primarily focus on
shorter clips. To address this gap, we introduce InfiniBench a comprehensive
benchmark for very long video understanding which presents 1)The longest video
duration, averaging 76.34 minutes; 2) The largest number of question-answer
pairs, 108.2K; 3) Diversity in questions that examine nine different skills and
include both multiple-choice questions and open-ended questions; 4)
Humancentric, as the video sources come from movies and daily TV shows, with
specific human-level question designs such as Movie Spoiler Questions that
require critical thinking and comprehensive understanding. Using InfiniBench,
we comprehensively evaluate existing Large MultiModality Models (LMMs) on each
skill, including the commercial model Gemini 1.5 Flash and the open-source
models. The evaluation shows significant challenges in our benchmark.Our
results show that the best AI models such Gemini struggles to perform well with
42.72% average accuracy and 2.71 out of 5 average score. We hope this benchmark
will stimulate the LMMs community towards long video and human-level
understanding. Our benchmark can be accessed at
https://vision-cair.github.io/InfiniBench/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 page ,17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FootBots: A <span class="highlight-title">Transformer</span>-based Architecture for Motion Prediction in
  Soccer <span class="chip">ICIP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19852v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19852v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guillem Capellera, Luis Ferraz, Antonio Rubio, Antonio Agudo, Francesc Moreno-Noguer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion prediction in soccer involves capturing complex dynamics from player
and ball interactions. We present FootBots, an encoder-decoder
transformer-based architecture addressing motion prediction and conditioned
motion prediction through equivariance properties. FootBots captures temporal
and social dynamics using set attention blocks and multi-attention block
decoder. Our evaluation utilizes two datasets: a real soccer dataset and a
tailored synthetic one. Insights from the synthetic dataset highlight the
effectiveness of FootBots' social attention mechanism and the significance of
conditioned motion prediction. Empirical results on real soccer data
demonstrate that FootBots outperforms baselines in motion prediction and excels
in conditioned tasks, such as predicting the players based on the ball
position, predicting the offensive (defensive) team based on the ball and the
defensive (offensive) team, and predicting the ball position based on all
players. Our evaluation connects quantitative and qualitative findings.
https://youtu.be/9kaEkfzG3L8
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at IEEE ICIP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StreamMOTP: Streaming and Unified Framework for Joint 3D Multi-Object
  Tracking and Trajectory Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19844v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19844v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaheng Zhuang, Guoan Wang, Siyu Zhang, Xiyang Wang, Hangning Zhou, Ziyao Xu, Chi Zhang, Zhiheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D multi-object tracking and trajectory prediction are two crucial modules in
autonomous driving systems. Generally, the two tasks are handled separately in
traditional paradigms and a few methods have started to explore modeling these
two tasks in a joint manner recently. However, these approaches suffer from the
limitations of single-frame training and inconsistent coordinate
representations between tracking and prediction tasks. In this paper, we
propose a streaming and unified framework for joint 3D Multi-Object Tracking
and trajectory Prediction (StreamMOTP) to address the above challenges.
Firstly, we construct the model in a streaming manner and exploit a memory bank
to preserve and leverage the long-term latent features for tracked objects more
effectively. Secondly, a relative spatio-temporal positional encoding strategy
is introduced to bridge the gap of coordinate representations between the two
tasks and maintain the pose-invariance for trajectory prediction. Thirdly, we
further improve the quality and consistency of predicted trajectories with a
dual-stream predictor. We conduct extensive experiments on popular nuSences
dataset and the experimental results demonstrate the effectiveness and
superiority of StreamMOTP, which outperforms previous methods significantly on
both tasks. Furthermore, we also prove that the proposed framework has great
potential and advantages in actual applications of autonomous driving.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LightStereo: Channel Boost Is All Your Need for Efficient 2D Cost
  Aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19833v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19833v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xianda Guo, Chenming Zhang, Dujun Nie, Wenzhao Zheng, Youmin Zhang, Long Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present LightStereo, a cutting-edge stereo-matching network crafted to
accelerate the matching process. Departing from conventional methodologies that
rely on aggregating computationally intensive 4D costs, LightStereo adopts the
3D cost volume as a lightweight alternative. While similar approaches have been
explored previously, our breakthrough lies in enhancing performance through a
dedicated focus on the channel dimension of the 3D cost volume, where the
distribution of matching costs is encapsulated. Our exhaustive exploration has
yielded plenty of strategies to amplify the capacity of the pivotal dimension,
ensuring both precision and efficiency. We compare the proposed LightStereo
with existing state-of-the-art methods across various benchmarks, which
demonstrate its superior performance in speed, accuracy, and resource
utilization. LightStereo achieves a competitive EPE metric in the SceneFlow
datasets while demanding a minimum of only 22 GFLOPs, with an inference time of
just 17 ms. Our comprehensive analysis reveals the effect of 2D cost
aggregation for stereo matching, paving the way for real-world applications of
efficient stereo systems. Code will be available at
\url{https://github.com/XiandaGuo/OpenStereo}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code will be available at
  \url{https://github.com/XiandaGuo/OpenStereo}</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Emotion Loss Attacking: Adversarial Attack Perception for Skeleton based
  on Multi-dimensional Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19815v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19815v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feng Liu, Qing Xu, Qijian Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial attack on skeletal motion is a hot topic. However, existing
researches only consider part of dynamic features when measuring distance
between skeleton graph sequences, which results in poor imperceptibility. To
this end, we propose a novel adversarial attack method to attack action
recognizers for skeletal motions. Firstly, our method systematically proposes a
dynamic distance function to measure the difference between skeletal motions.
Meanwhile, we innovatively introduce emotional features for complementary
information. In addition, we use Alternating Direction Method of
Multipliers(ADMM) to solve the constrained optimization problem, which
generates adversarial samples with better imperceptibility to deceive the
classifiers. Experiments show that our method is effective on multiple action
classifiers and datasets. When the perturbation magnitude measured by l norms
is the same, the dynamic perturbations generated by our method are much lower
than that of other methods. What's more, we are the first to prove the
effectiveness of emotional features, and provide a new idea for measuring the
distance between skeletal motions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extract More from Less: Efficient Fine-Grained Visual Recognition in
  Low-Data Regimes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19814v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19814v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dmitry Demidov, Abduragim Shtanchaev, Mihail Mihaylov, Mohammad Almansoori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emerging task of fine-grained image classification in low-data regimes
assumes the presence of low inter-class variance and large intra-class
variation along with a highly limited amount of training samples per class.
However, traditional ways of separately dealing with fine-grained
categorisation and extremely scarce data may be inefficient under both these
harsh conditions presented together. In this paper, we present a novel
framework, called AD-Net, aiming to enhance deep neural network performance on
this challenge by leveraging the power of Augmentation and Distillation
techniques. Specifically, our approach is designed to refine learned features
through self-distillation on augmented samples, mitigating harmful overfitting.
We conduct comprehensive experiments on popular fine-grained image
classification benchmarks where our AD-Net demonstrates consistent improvement
over traditional fine-tuning and state-of-the-art low-data techniques.
Remarkably, with the smallest data available, our framework shows an
outstanding relative accuracy increase of up to 45 % compared to standard
ResNet-50 and up to 27 % compared to the closest SOTA runner-up. We emphasise
that our approach is practically architecture-independent and adds zero extra
cost at inference time. Additionally, we provide an extensive study on the
impact of every framework's component, highlighting the importance of each in
achieving optimal performance. Source code and trained models are publicly
available at github.com/demidovd98/fgic_lowd.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main paper and Appendices</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EgoGaussian: Dynamic Scene Understanding from Egocentric Video with 3D
  Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19811v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19811v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daiwei Zhang, Gengyan Li, Jiajie Li, Mickaël Bressieux, Otmar Hilliges, Marc Pollefeys, Luc Van Gool, Xi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human activities are inherently complex, and even simple household tasks
involve numerous object interactions. To better understand these activities and
behaviors, it is crucial to model their dynamic interactions with the
environment. The recent availability of affordable head-mounted cameras and
egocentric data offers a more accessible and efficient means to understand
dynamic human-object interactions in 3D environments. However, most existing
methods for human activity modeling either focus on reconstructing 3D models of
hand-object or human-scene interactions or on mapping 3D scenes, neglecting
dynamic interactions with objects. The few existing solutions often require
inputs from multiple sources, including multi-camera setups, depth-sensing
cameras, or kinesthetic sensors. To this end, we introduce EgoGaussian, the
first method capable of simultaneously reconstructing 3D scenes and dynamically
tracking 3D object motion from RGB egocentric input alone. We leverage the
uniquely discrete nature of Gaussian Splatting and segment dynamic interactions
from the background. Our approach employs a clip-level online learning pipeline
that leverages the dynamic nature of human activities, allowing us to
reconstruct the temporal evolution of the scene in chronological order and
track rigid object motion. Additionally, our method automatically segments
object and background Gaussians, providing 3D representations for both static
scenes and dynamic objects. EgoGaussian outperforms previous NeRF and Dynamic
Gaussian methods in challenging in-the-wild videos and we also qualitatively
demonstrate the high quality of the reconstructed models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comprehensive Generative Replay for Task-Incremental Segmentation with
  Concurrent Appearance and Semantic Forgetting <span class="chip">MICCAI24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Li, Jingyang Zhang, Pheng-Ann Heng, Lixu Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generalist segmentation models are increasingly favored for diverse tasks
involving various objects from different image sources. Task-Incremental
Learning (TIL) offers a privacy-preserving training paradigm using tasks
arriving sequentially, instead of gathering them due to strict data sharing
policies. However, the task evolution can span a wide scope that involves
shifts in both image appearance and segmentation semantics with intricate
correlation, causing concurrent appearance and semantic forgetting. To solve
this issue, we propose a Comprehensive Generative Replay (CGR) framework that
restores appearance and semantic knowledge by synthesizing image-mask pairs to
mimic past task data, which focuses on two aspects: modeling image-mask
correspondence and promoting scalability for diverse tasks. Specifically, we
introduce a novel Bayesian Joint Diffusion (BJD) model for high-quality
synthesis of image-mask pairs with their correspondence explicitly preserved by
conditional denoising. Furthermore, we develop a Task-Oriented Adapter (TOA)
that recalibrates prompt embeddings to modulate the diffusion model, making the
data synthesis compatible with different tasks. Experiments on incremental
tasks (cardiac, fundus and prostate segmentation) show its clear advantage for
alleviating concurrent appearance and semantic forgetting. Code is available at
https://github.com/jingyzhang/CGR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structure-aware World Model for Probe Guidance via Large-scale
  <span class="highlight-title">Self-supervised</span> <span class="highlight-title">Pre-train</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19756v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19756v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haojun Jiang, Meng Li, Zhenguo Sun, Ning Jia, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The complex structure of the heart leads to significant challenges in
echocardiography, especially in acquisition cardiac ultrasound images.
Successful echocardiography requires a thorough understanding of the structures
on the two-dimensional plane and the spatial relationships between planes in
three-dimensional space. In this paper, we innovatively propose a large-scale
self-supervised pre-training method to acquire a cardiac structure-aware world
model. The core innovation lies in constructing a self-supervised task that
requires structural inference by predicting masked structures on a 2D plane and
imagining another plane based on pose transformation in 3D space. To support
large-scale pre-training, we collected over 1.36 million echocardiograms from
ten standard views, along with their 3D spatial poses. In the downstream probe
guidance task, we demonstrate that our pre-trained model consistently reduces
guidance errors across the ten most common standard views on the test set with
0.29 million samples from 74 routine clinical scans, indicating that
structure-aware pre-training benefits the scanning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SPIRONet: Spatial-Frequency Learning and Topological Channel Interaction
  Network for Vessel Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19749v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19749v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        De-Xing Huang, Xiao-Hu Zhou, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Zhen-Qiu Feng, Mei-Jiang Gui, Hao Li, Tian-Yu Xiang, Bo-Xian Yao, Zeng-Guang Hou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic vessel segmentation is paramount for developing next-generation
interventional navigation systems. However, current approaches suffer from
suboptimal segmentation performances due to significant challenges in
intraoperative images (i.e., low signal-to-noise ratio, small or slender
vessels, and strong interference). In this paper, a novel spatial-frequency
learning and topological channel interaction network (SPIRONet) is proposed to
address the above issues. Specifically, dual encoders are utilized to
comprehensively capture local spatial and global frequency vessel features.
Then, a cross-attention fusion module is introduced to effectively fuse spatial
and frequency features, thereby enhancing feature discriminability.
Furthermore, a topological channel interaction module is designed to filter out
task-irrelevant responses based on graph neural networks. Extensive
experimental results on several challenging datasets (CADSA, CAXF, DCA1, and
XCAD) demonstrate state-of-the-art performances of our method. Moreover, the
inference speed of SPIRONet is 21 FPS with a 512x512 input size, surpassing
clinical real-time requirements (6~12FPS). These promising outcomes indicate
SPIRONet's potential for integration into vascular interventional navigation
systems. Code is available at https://github.com/Dxhuang-CASIA/SPIRONet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MM-Instruct: Generated Visual Instructions for Large Multimodal Model
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihao Liu, Xin Huang, Jinliang Zheng, Boxiao Liu, Jia Wang, Osamu Yoshie, Yu Liu, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces MM-Instruct, a large-scale dataset of diverse and
high-quality visual instruction data designed to enhance the
instruction-following capabilities of large multimodal models (LMMs). While
existing visual instruction datasets often focus on question-answering, they
struggle to generalize to broader application scenarios such as creative
writing, summarization, or image analysis. To address these limitations, we
propose a novel approach to constructing MM-Instruct that leverages the strong
instruction-following capabilities of existing LLMs to generate novel visual
instruction data from large-scale but conventional image captioning datasets.
MM-Instruct first leverages ChatGPT to automatically generate diverse
instructions from a small set of seed instructions through augmenting and
summarization. It then matches these instructions with images and uses an
open-sourced large language model (LLM) to generate coherent answers to the
instruction-image pairs. The LLM is grounded by the detailed text descriptions
of images in the whole answer generation process to guarantee the alignment of
the instruction data. Moreover, we introduce a benchmark based on the generated
instruction data to evaluate the instruction-following capabilities of existing
LMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5
model on the generated data, denoted as LLaVA-Instruct, which exhibits
significant improvements in instruction-following capabilities compared to
LLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models
are available at https://github.com/jihaonew/MM-Instruct.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset and models are available at
  https://github.com/jihaonew/MM-Instruct</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EPOCH: Jointly Estimating the 3D Pose of Cameras and Humans 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19726v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19726v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Garau, Giulia Martinelli, Niccolò Bisagno, Denis Tomè, Carsten Stoll
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monocular Human Pose Estimation (HPE) aims at determining the 3D positions of
human joints from a single 2D image captured by a camera. However, a single 2D
point in the image may correspond to multiple points in 3D space. Typically,
the uniqueness of the 2D-3D relationship is approximated using an orthographic
or weak-perspective camera model. In this study, instead of relying on
approximations, we advocate for utilizing the full perspective camera model.
This involves estimating camera parameters and establishing a precise,
unambiguous 2D-3D relationship. To do so, we introduce the EPOCH framework,
comprising two main components: the pose lifter network (LiftNet) and the pose
regressor network (RegNet). LiftNet utilizes the full perspective camera model
to precisely estimate the 3D pose in an unsupervised manner. It takes a 2D pose
and camera parameters as inputs and produces the corresponding 3D pose
estimation. These inputs are obtained from RegNet, which starts from a single
image and provides estimates for the 2D pose and camera parameters. RegNet
utilizes only 2D pose data as weak supervision. Internally, RegNet predicts a
3D pose, which is then projected to 2D using the estimated camera parameters.
This process enables RegNet to establish the unambiguous 2D-3D relationship.
Our experiments show that modeling the lifting as an unsupervised task with a
camera in-the-loop results in better generalization to unseen data. We obtain
state-of-the-art results for the 3D HPE on the Human3.6M and MPI-INF-3DHP
datasets. Our code is available at: [Github link upon acceptance, see
supplementary materials].
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vision <span class="highlight-title">Transformer</span> with Key-select Routing Attention for Single Image
  Dehazing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19703v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19703v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lihan Tong, Weijia Li, Qingxia Yang, Liyuan Chen, Peng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Ksformer, utilizing Multi-scale Key-select Routing Attention
(MKRA) for intelligent selection of key areas through multi-channel,
multi-scale windows with a top-k operator, and Lightweight Frequency Processing
Module (LFPM) to enhance high-frequency features, outperforming other dehazing
methods in tests.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages,4 figures,IEICE Trans. Information and Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19693v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19693v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinming Li, Yichen Zhu, Zhiyuan Xu, Jindong Gu, Minjie Zhu, Xin Liu, Ning Liu, Yaxin Peng, Feifei Feng, Jian Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is fundamentally challenging for robots to serve as useful assistants in
human environments because this requires addressing a spectrum of sub-problems
across robotics, including perception, language understanding, reasoning, and
planning. The recent advancements in Multimodal Large Language Models (MLLMs)
have demonstrated their exceptional abilities in solving complex mathematical
problems, mastering commonsense and abstract reasoning. This has led to the
recent utilization of MLLMs as the brain in robotic systems, enabling these
models to conduct high-level planning prior to triggering low-level control
actions for task execution. However, it remains uncertain whether existing
MLLMs are reliable in serving the brain role of robots. In this study, we
introduce the first benchmark for evaluating Multimodal LLM for Robotic (MMRo)
benchmark, which tests the capability of MLLMs for robot applications.
Specifically, we identify four essential capabilities perception, task
planning, visual reasoning, and safety measurement that MLLMs must possess to
qualify as the robot's central processing unit. We have developed several
scenarios for each capability, resulting in a total of 14 metrics for
evaluation. We present experimental results for various MLLMs, including both
commercial and open-source models, to assess the performance of existing
systems. Our findings indicate that no single model excels in all areas,
suggesting that current MLLMs are not yet trustworthy enough to serve as the
cognitive core for robots. Our data can be found in
https://mm-robobench.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Fusion Model for Brain Tumor Classification Using Fine-Grained
  Gradient Preservation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niful Islam, Mohaiminul Islam Bhuiyan, Jarin Tasnim Raya, Nur Shazwani Kamarudin, Khan Md Hasib, M. F. Mridha, Dewan Md. Farid
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Brain tumors are one of the most common diseases that lead to early death if
not diagnosed at an early stage. Traditional diagnostic approaches are
extremely time-consuming and prone to errors. In this context, computer
vision-based approaches have emerged as an effective tool for accurate brain
tumor classification. While some of the existing solutions demonstrate
noteworthy accuracy, the models become infeasible to deploy in areas where
computational resources are limited. This research addresses the need for
accurate and fast classification of brain tumors with a priority of deploying
the model in technologically underdeveloped regions. The research presents a
novel architecture for precise brain tumor classification fusing pretrained
ResNet152V2 and modified VGG16 models. The proposed architecture undergoes a
diligent fine-tuning process that ensures fine gradients are preserved in deep
neural networks, which are essential for effective brain tumor classification.
The proposed solution incorporates various image processing techniques to
improve image quality and achieves an astounding accuracy of 98.36% and 98.04%
in Figshare and Kaggle datasets respectively. This architecture stands out for
having a streamlined profile, with only 2.8 million trainable parameters. We
have leveraged 8-bit quantization to produce a model of size 73.881 MB,
significantly reducing it from the previous size of 289.45 MB, ensuring smooth
deployment in edge devices even in resource-constrained areas. Additionally,
the use of Grad-CAM improves the interpretability of the model, offering
insightful information regarding its decision-making process. Owing to its high
discriminative ability, this model can be a reliable option for accurate brain
tumor classification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Radiological Diagnosis: A Collaborative Approach Integrating
  AI and Human Expertise for Visual Miss Correction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19686v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19686v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akash Awasthi, Ngan Le, Zhigang Deng, Carol C. Wu, Hien Van Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human-AI collaboration to identify and correct perceptual errors in chest
radiographs has not been previously explored. This study aimed to develop a
collaborative AI system, CoRaX, which integrates eye gaze data and radiology
reports to enhance diagnostic accuracy in chest radiology by pinpointing
perceptual errors and refining the decision-making process. Using public
datasets REFLACX and EGD-CXR, the study retrospectively developed CoRaX,
employing a large multimodal model to analyze image embeddings, eye gaze data,
and radiology reports. The system's effectiveness was evaluated based on its
referral-making process, the quality of referrals, and performance in
collaborative diagnostic settings. CoRaX was tested on a simulated error
dataset of 271 samples with 28% (93 of 332) missed abnormalities. The system
corrected 21% (71 of 332) of these errors, leaving 7% (22 of 312) unresolved.
The Referral-Usefulness score, indicating the accuracy of predicted regions for
all true referrals, was 0.63 (95% CI 0.59, 0.68). The Total-Usefulness score,
reflecting the diagnostic accuracy of CoRaX's interactions with radiologists,
showed that 84% (237 of 280) of these interactions had a score above 0.40. In
conclusion, CoRaX efficiently collaborates with radiologists to address
perceptual errors across various abnormalities, with potential applications in
the education and training of novice radiologists.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review in Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MimicMotion: High-Quality Human Motion Video Generation with
  Confidence-aware Pose Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuang Zhang, Jiaxi Gu, Li-Wen Wang, Han Wang, Junqi Cheng, Yuefeng Zhu, Fangyuan Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, generative artificial intelligence has achieved significant
advancements in the field of image generation, spawning a variety of
applications. However, video generation still faces considerable challenges in
various aspects, such as controllability, video length, and richness of
details, which hinder the application and popularization of this technology. In
this work, we propose a controllable video generation framework, dubbed
MimicMotion, which can generate high-quality videos of arbitrary length
mimicking specific motion guidance. Compared with previous methods, our
approach has several highlights. Firstly, we introduce confidence-aware pose
guidance that ensures high frame quality and temporal smoothness. Secondly, we
introduce regional loss amplification based on pose confidence, which
significantly reduces image distortion. Lastly, for generating long and smooth
videos, we propose a progressive latent fusion strategy. By this means, we can
produce videos of arbitrary length with acceptable resource consumption. With
extensive experiments and user studies, MimicMotion demonstrates significant
improvements over previous approaches in various aspects. Detailed results and
comparisons are available on our project page:
https://tencent.github.io/MimicMotion .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning-based Depth Estimation Methods from Monocular Image and
  Videos: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Uchitha Rajapaksha, Ferdous Sohel, Hamid Laga, Dean Diepeveen, Mohammed Bennamoun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating depth from single RGB images and videos is of widespread interest
due to its applications in many areas, including autonomous driving, 3D
reconstruction, digital entertainment, and robotics. More than 500 deep
learning-based papers have been published in the past 10 years, which indicates
the growing interest in the task. This paper presents a comprehensive survey of
the existing deep learning-based methods, the challenges they address, and how
they have evolved in their architecture and supervision methods. It provides a
taxonomy for classifying the current work based on their input and output
modalities, network architectures, and learning methods. It also discusses the
major milestones in the history of monocular depth estimation, and different
pipelines, datasets, and evaluation metrics used in existing methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>46 pages, 10 figures, The paper has been accepted for publication in
  ACM Computing Surveys 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond First-Order: A Multi-Scale Approach to Finger Knuckle Print
  Biometrics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19672v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19672v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengrui Gao, Ziyuan Yang, Andrew Beng Jin Teoh, Min Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, finger knuckle prints (FKPs) have gained attention due to their
rich textural patterns, positioning them as a promising biometric for identity
recognition. Prior FKP recognition methods predominantly leverage first-order
feature descriptors, which capture intricate texture details but fail to
account for structural information. Emerging research, however, indicates that
second-order textures, which describe the curves and arcs of the textures,
encompass this overlooked structural information. This paper introduces a novel
FKP recognition approach, the Dual-Order Texture Competition Network (DOTCNet),
designed to capture texture information in FKP images comprehensively. DOTCNet
incorporates three dual-order texture competitive modules (DTCMs), each
targeting textures at different scales. Each DTCM employs a learnable texture
descriptor, specifically a learnable Gabor filter (LGF), to extract texture
features. By leveraging LGFs, the network extracts first and second order
textures to describe fine textures and structural features thoroughly.
Furthermore, an attention mechanism enhances relevant features in the
first-order features, thereby highlighting significant texture details. For
second-order features, a competitive mechanism emphasizes structural
information while reducing noise from higher-order features. Extensive
experimental results reveal that DOTCNet significantly outperforms several
standard algorithms on the publicly available PolyU-FKP dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PopAlign: Population-Level Alignment for Fair Text-to-Image Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19668v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19668v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shufan Li, Harkanwar Singh, Aditya Grover
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image (T2I) models achieve high-fidelity generation through extensive
training on large datasets. However, these models may unintentionally pick up
undesirable biases of their training data, such as over-representation of
particular identities in gender or ethnicity neutral prompts. Existing
alignment methods such as Reinforcement Learning from Human Feedback (RLHF) and
Direct Preference Optimization (DPO) fail to address this problem effectively
because they operate on pairwise preferences consisting of individual samples,
while the aforementioned biases can only be measured at a population level. For
example, a single sample for the prompt "doctor" could be male or female, but a
model generating predominantly male doctors even with repeated sampling
reflects a gender bias. To address this limitation, we introduce PopAlign, a
novel approach for population-level preference optimization, while standard
optimization would prefer entire sets of samples over others. We further derive
a stochastic lower bound that directly optimizes for individual samples from
preferred populations over others for scalable training. Using human evaluation
and standard image quality and bias metrics, we show that PopAlign
significantly mitigates the bias of pretrained T2I models while largely
preserving the generation quality. Code is available at
https://github.com/jacklishufan/PopAlignSDXL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CSAKD: Knowledge Distillation with Cross Self-Attention for
  Hyperspectral and Multispectral Image Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chih-Chung Hsu, Chih-Chien Ni, Chia-Ming Lee, Li-Wei Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hyperspectral imaging, capturing detailed spectral information for each
pixel, is pivotal in diverse scientific and industrial applications. Yet, the
acquisition of high-resolution (HR) hyperspectral images (HSIs) often needs to
be addressed due to the hardware limitations of existing imaging systems. A
prevalent workaround involves capturing both a high-resolution multispectral
image (HR-MSI) and a low-resolution (LR) HSI, subsequently fusing them to yield
the desired HR-HSI. Although deep learning-based methods have shown promising
in HR-MSI/LR-HSI fusion and LR-HSI super-resolution (SR), their substantial
model complexities hinder deployment on resource-constrained imaging devices.
This paper introduces a novel knowledge distillation (KD) framework for
HR-MSI/LR-HSI fusion to achieve SR of LR-HSI. Our KD framework integrates the
proposed Cross-Layer Residual Aggregation (CLRA) block to enhance efficiency
for constructing Dual Two-Streamed (DTS) network structure, designed to extract
joint and distinct features from LR-HSI and HR-MSI simultaneously. To fully
exploit the spatial and spectral feature representations of LR-HSI and HR-MSI,
we propose a novel Cross Self-Attention (CSA) fusion module to adaptively fuse
those features to improve the spatial and spectral quality of the reconstructed
HR-HSI. Finally, the proposed KD-based joint loss function is employed to
co-train the teacher and student networks. Our experimental results demonstrate
that the student model not only achieves comparable or superior LR-HSI SR
performance but also significantly reduces the model-size and computational
requirements. This marks a substantial advancement over existing
state-of-the-art methods. The source code is available at
https://github.com/ming053l/CSAKD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to TIP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PM-VIS+: High-Performance Video Instance Segmentation without Video
  Annotation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhangjing Yang, Dun Liu, Xin Wang, Zhe Li, Barathwaj Anandan, Yi Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video instance segmentation requires detecting, segmenting, and tracking
objects in videos, typically relying on costly video annotations. This paper
introduces a method that eliminates video annotations by utilizing image
datasets. The PM-VIS algorithm is adapted to handle both bounding box and
instance-level pixel annotations dynamically. We introduce ImageNet-bbox to
supplement missing categories in video datasets and propose the PM-VIS+
algorithm to adjust supervision based on annotation types. To enhance accuracy,
we use pseudo masks and semi-supervised optimization techniques on unannotated
video data. This method achieves high video instance segmentation performance
without manual video annotations, offering a cost-effective solution and new
perspectives for video instance segmentation applications. The code will be
available in https://github.com/ldknight/PM-VIS-plus
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MIPR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Basketball-SORT: An Association Method for Complex Multi-object
  Occlusion Problems in Basketball Multi-object Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingrui Hu, Atom Scott, Calvin Yeung, Keisuke Fujii
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent deep learning-based object detection approaches have led to
significant progress in multi-object tracking (MOT) algorithms. The current MOT
methods mainly focus on pedestrian or vehicle scenes, but basketball sports
scenes are usually accompanied by three or more object occlusion problems with
similar appearances and high-intensity complex motions, which we call complex
multi-object occlusion (CMOO). Here, we propose an online and robust MOT
approach, named Basketball-SORT, which focuses on the CMOO problems in
basketball videos. To overcome the CMOO problem, instead of using the
intersection-over-union-based (IoU-based) approach, we use the trajectories of
neighboring frames based on the projected positions of the players. Our method
designs the basketball game restriction (BGR) and reacquiring Long-Lost IDs
(RLLI) based on the characteristics of basketball scenes, and we also solve the
occlusion problem based on the player trajectories and appearance features.
Experimental results show that our method achieves a Higher Order Tracking
Accuracy (HOTA) score of 63.48$\%$ on the basketball fixed video dataset and
outperforms other recent popular approaches. Overall, our approach solved the
CMOO problem more effectively than recent MOT algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AstMatch: Adversarial Self-training Consistency Framework for
  Semi-Supervised Medical Image Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanghao Zhu, Jing Zhang, Juanxiu Liu, Xiaohui Du, Ruqian Hao, Yong Liu, Lin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semi-supervised learning (SSL) has shown considerable potential in medical
image segmentation, primarily leveraging consistency regularization and
pseudo-labeling. However, many SSL approaches only pay attention to low-level
consistency and overlook the significance of pseudo-label reliability.
Therefore, in this work, we propose an adversarial self-training consistency
framework (AstMatch). Firstly, we design an adversarial consistency
regularization (ACR) approach to enhance knowledge transfer and strengthen
prediction consistency under varying perturbation intensities. Second, we apply
a feature matching loss for adversarial training to incorporate high-level
consistency regularization. Additionally, we present the pyramid channel
attention (PCA) and efficient channel and spatial attention (ECSA) modules to
improve the discriminator's performance. Finally, we propose an adaptive
self-training (AST) approach to ensure the pseudo-labels' quality. The proposed
AstMatch has been extensively evaluated with cutting-edge SSL methods on three
public-available datasets. The experimental results under different labeled
ratios indicate that AstMatch outperforms other existing methods, achieving new
state-of-the-art performance. Our code will be available at
https://github.com/GuanghaoZhu663/AstMatch.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Event Stream Super-Resolution with Recursive Multi-Branch
  Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19640v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19640v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quanmin Liang, Zhilin Huang, Xiawu Zheng, Feidiao Yang, Jun Peng, Kai Huang, Yonghong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current Event Stream Super-Resolution (ESR) methods overlook the redundant
and complementary information present in positive and negative events within
the event stream, employing a direct mixing approach for super-resolution,
which may lead to detail loss and inefficiency. To address these issues, we
propose an efficient Recursive Multi-Branch Information Fusion Network (RMFNet)
that separates positive and negative events for complementary information
extraction, followed by mutual supplementation and refinement. Particularly, we
introduce Feature Fusion Modules (FFM) and Feature Exchange Modules (FEM). FFM
is designed for the fusion of contextual information within neighboring event
streams, leveraging the coupling relationship between positive and negative
events to alleviate the misleading of noises in the respective branches. FEM
efficiently promotes the fusion and exchange of information between positive
and negative branches, enabling superior local information enhancement and
global information complementation. Experimental results demonstrate that our
approach achieves over 17% and 31% improvement on synthetic and real datasets,
accompanied by a 2.3X acceleration. Furthermore, we evaluate our method on two
downstream event-driven applications, \emph{i.e.}, object recognition and video
reconstruction, achieving remarkable results that outperform existing methods.
Our code and Supplementary Material are available at
https://github.com/Lqm26/RMFNet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Precision matters: Precision-aware ensemble for weakly supervised
  semantic segmentation <span class="chip">AAAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junsung Park, Hyunjung Shim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly Supervised Semantic Segmentation (WSSS) employs weak supervision, such
as image-level labels, to train the segmentation model. Despite the impressive
achievement in recent WSSS methods, we identify that introducing weak labels
with high mean Intersection of Union (mIoU) does not guarantee high
segmentation performance. Existing studies have emphasized the importance of
prioritizing precision and reducing noise to improve overall performance. In
the same vein, we propose ORANDNet, an advanced ensemble approach tailored for
WSSS. ORANDNet combines Class Activation Maps (CAMs) from two different
classifiers to increase the precision of pseudo-masks (PMs). To further
mitigate small noise in the PMs, we incorporate curriculum learning. This
involves training the segmentation model initially with pairs of smaller-sized
images and corresponding PMs, gradually transitioning to the original-sized
pairs. By combining the original CAMs of ResNet-50 and ViT, we significantly
improve the segmentation performance over the single-best model and the naive
ensemble model, respectively. We further extend our ensemble method to CAMs
from AMN (ResNet-like) and MCTformer (ViT-like) models, achieving performance
benefits in advanced WSSS models. It highlights the potential of our ORANDNet
as a final add-on module for WSSS models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 5 figures, accepted in AAAI 2024 Edge Intelligence Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Model Predictive Simulation Using Structured Graphical Models and
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinghua Lou, Meet Dave, Shrinu Kushagra, Miguel Lazaro-Gredilla, Kevin Murphy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an approach to simulating trajectories of multiple interacting
agents (road users) based on transformers and probabilistic graphical models
(PGMs), and apply it to the Waymo SimAgents challenge. The transformer baseline
is based on the MTR model, which predicts multiple future trajectories
conditioned on the past trajectories and static road layout features. We then
improve upon these generated trajectories using a PGM, which contains factors
which encode prior knowledge, such as a preference for smooth trajectories, and
avoidance of collisions with static obstacles and other moving agents. We
perform (approximate) MAP inference in this PGM using the Gauss-Newton method.
Finally we sample $K=32$ trajectories for each of the $N \sim 100$ agents for
the next $T=8 \Delta$ time steps, where $\Delta=10$ is the sampling rate per
second. Following the Model Predictive Control (MPC) paradigm, we only return
the first element of our forecasted trajectories at each step, and then we
replan, so that the simulation can constantly adapt to its changing
environment. We therefore call our approach "Model Predictive Simulation" or
MPS. We show that MPS improves upon the MTR baseline, especially in safety
critical metrics such as collision rate. Furthermore, our approach is
compatible with any underlying forecasting model, and does not require extra
training, so we believe it is a valuable contribution to the community.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Special Mention at the Waymo Sim Agents Challenge 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PPTFormer: Pseudo Multi-Perspective <span class="highlight-title">Transformer</span> for UAV Segmentation <span class="chip">IJCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deyi Ji, Wenwei Jin, Hongtao Lu, Feng Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ascension of Unmanned Aerial Vehicles (UAVs) in various fields
necessitates effective UAV image segmentation, which faces challenges due to
the dynamic perspectives of UAV-captured images. Traditional segmentation
algorithms falter as they cannot accurately mimic the complexity of UAV
perspectives, and the cost of obtaining multi-perspective labeled datasets is
prohibitive. To address these issues, we introduce the PPTFormer, a novel
\textbf{P}seudo Multi-\textbf{P}erspective \textbf{T}rans\textbf{former}
network that revolutionizes UAV image segmentation. Our approach circumvents
the need for actual multi-perspective data by creating pseudo perspectives for
enhanced multi-perspective learning. The PPTFormer network boasts Perspective
Decomposition, novel Perspective Prototypes, and a specialized encoder and
decoder that together achieve superior segmentation results through Pseudo
Multi-Perspective Attention (PMP Attention) and fusion. Our experiments
demonstrate that PPTFormer achieves state-of-the-art performance across five
UAV segmentation datasets, confirming its capability to effectively simulate
UAV flight perspectives and significantly advance segmentation precision. This
work presents a pioneering leap in UAV scene understanding and sets a new
benchmark for future developments in semantic segmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IJCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Video Compression using Pixel Shift Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19630v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19630v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hitesh Saai Mananchery Panneerselvam, Smit Anand
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Video comprises approximately ~85\% of all internet traffic, but video
encoding/compression is being historically done with hard coded rules, which
has worked well but only to a certain limit. We have seen a surge in video
compression algorithms using ML-based models in the last few years and many of
them have outperformed several legacy codecs. The models range from encoding
video end to end using an ML approach or replacing some intermediate steps in
legacy codecs using ML models to increase the efficiency of those steps.
  Optimizing video storage is an essential aspect of video processing, so we
are proposing one of the possible approaches to achieve it is by avoiding
redundant data at each frame. In this paper, we want to introduce the approach
of redundancies removal in subsequent frames for a given video as a main
approach for video compression. We call this method Redundancy Removal using
Shift (R\textsuperscript2S). This method can be utilized across various Machine
Learning model algorithms, and make the compression more accessible and
adaptable. In this study, we have utilized a computer vision-based pixel point
tracking method to identify redundant pixels to encode video for optimal
storage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Deep Clustering: From the Prior Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19602v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19602v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiding Lu, Haobin Li, Yunfan Li, Yijie Lin, Xi Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Facilitated by the powerful feature extraction ability of neural networks,
deep clustering has achieved great success in analyzing high-dimensional and
complex real-world data. The performance of deep clustering methods is affected
by various factors such as network structures and learning objectives. However,
as pointed out in this survey, the essence of deep clustering lies in the
incorporation and utilization of prior knowledge, which is largely ignored by
existing works. From pioneering deep clustering methods based on data structure
assumptions to recent contrastive clustering methods based on data augmentation
invariances, the development of deep clustering intrinsically corresponds to
the evolution of prior knowledge. In this survey, we provide a comprehensive
review of deep clustering methods by categorizing them into six types of prior
knowledge. We find that in general the prior innovation follows two trends,
namely, i) from mining to constructing, and ii) from internal to external.
Besides, we provide a benchmark on five widely-used datasets and analyze the
performance of methods with diverse priors. By providing a novel prior
knowledge perspective, we hope this survey could provide some novel insights
and inspire future research in the deep clustering community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SK-VQA: Synthetic Knowledge Generation at Scale for Training
  Context-Augmented Multimodal LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19593v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19593v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Su, Man Luo, Kris W Pan, Tien Pei Chou, Vasudev Lal, Phillip Howard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data generation has gained significant attention recently for its
utility in training large vision and language models. However, the application
of synthetic data to the training of multimodal context-augmented generation
systems has been relatively unexplored. This gap in existing work is important
because existing vision and language models (VLMs) are not trained specifically
for context-augmented generation. Resources for adapting such models are
therefore crucial for enabling their use in retrieval-augmented generation
(RAG) settings, where a retriever is used to gather relevant information that
is then subsequently provided to a generative model via context augmentation.
To address this challenging problem, we generate SK-VQA: a large synthetic
multimodal dataset containing over 2 million question-answer pairs which
require external knowledge to determine the final answer. Our dataset is both
larger and significantly more diverse than existing resources of its kind,
possessing over 11x more unique questions and containing images from a greater
variety of sources than previously-proposed datasets. Through extensive
experiments, we demonstrate that our synthetic dataset can not only serve as a
challenging benchmark, but is also highly effective for adapting existing
generative multimodal models for context-augmented generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploiting Diffusion Prior for Real-World Image Super-Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.07015v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.07015v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianyi Wang, Zongsheng Yue, Shangchen Zhou, Kelvin C. K. Chan, Chen Change Loy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to leverage prior knowledge encapsulated in
pre-trained text-to-image diffusion models for blind super-resolution (SR).
Specifically, by employing our time-aware encoder, we can achieve promising
restoration results without altering the pre-trained synthesis model, thereby
preserving the generative prior and minimizing training cost. To remedy the
loss of fidelity caused by the inherent stochasticity of diffusion models, we
employ a controllable feature wrapping module that allows users to balance
quality and fidelity by simply adjusting a scalar value during the inference
process. Moreover, we develop a progressive aggregation sampling strategy to
overcome the fixed-size constraints of pre-trained diffusion models, enabling
adaptation to resolutions of any size. A comprehensive evaluation of our method
using both synthetic and real-world benchmarks demonstrates its superiority
over current state-of-the-art approaches. Code and models are available at
https://github.com/IceClear/StableSR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IJCV'2024. Some Figs are compressed due to size limits.
  Uncompressed ver.:
  https://github.com/IceClear/StableSR/releases/download/UncompressedPDF/StableSR_IJCV_Uncompressed.pdf.
  Project page: https://iceclear.github.io/projects/stablesr/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EnSolver: Uncertainty-Aware Ensemble CAPTCHA Solvers with Theoretical
  Guarantees <span class="chip">UAI 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.15180v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.15180v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duc C. Hoang, Behzad Ousat, Amin Kharraz, Cuong V. Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The popularity of text-based CAPTCHA as a security mechanism to protect
websites from automated bots has prompted researches in CAPTCHA solvers, with
the aim of understanding its failure cases and subsequently making CAPTCHAs
more secure. Recently proposed solvers, built on advances in deep learning, are
able to crack even the very challenging CAPTCHAs with high accuracy. However,
these solvers often perform poorly on out-of-distribution samples that contain
visual features different from those in the training set. Furthermore, they
lack the ability to detect and avoid such samples, making them susceptible to
being locked out by defense systems after a certain number of failed attempts.
In this paper, we propose EnSolver, a family of CAPTCHA solvers that use deep
ensemble uncertainty to detect and skip out-of-distribution CAPTCHAs, making it
harder to be detected. We prove novel theoretical bounds on the effectiveness
of our solvers and demonstrate their use with state-of-the-art CAPTCHA solvers.
Our experiments show that the proposed approaches perform well when cracking
CAPTCHA datasets that contain both in-distribution and out-of-distribution
samples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A previous version of this paper was presented at the Epistemic
  Uncertainty - E-pi UAI 2023 Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robustness Assessment of a Runway Object Classifier for Safe Aircraft
  Taxiing <span class="chip">SC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00035v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00035v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhak Elboher, Raya Elsaleh, Omri Isac, Mélanie Ducoffe, Audrey Galametz, Guillaume Povéda, Ryma Boumazouza, Noémie Cohen, Guy Katz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As deep neural networks (DNNs) are becoming the prominent solution for many
computational problems, the aviation industry seeks to explore their potential
in alleviating pilot workload and in improving operational safety. However, the
use of DNNs in this type of safety-critical applications requires a thorough
certification process. This need can be addressed through formal verification,
which provides rigorous assurances -- e.g.,~by proving the absence of certain
mispredictions. In this case-study paper, we demonstrate this process using an
image-classifier DNN currently under development at Airbus and intended for use
during the aircraft taxiing phase. We use formal methods to assess this DNN's
robustness to three common image perturbation types: noise, brightness and
contrast, and some of their combinations. This process entails multiple
invocations of the underlying verifier, which might be computationally
expensive; and we therefore propose a method that leverages the monotonicity of
these robustness properties, as well as the results of past verification
queries, in order to reduce the overall number of verification queries required
by nearly 60%. Our results provide an indication of the level of robustness
achieved by the DNN classifier under study, and indicate that it is
considerably more vulnerable to noise than to brightness or contrast
perturbations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a preprint version of the paper in the proceedings of 43rd
  Digital Avionics Systems Conference (DASC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning to utilize image second-order derivative information for crisp
  edge detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05779v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05779v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changsong Liu, Wei Zhang, Yanyan Liu, Yimeng Fan, Mingyang Li, Wenlin Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Edge detection is a fundamental task in computer vision. It has made great
progress under the development of deep convolutional neural networks (DCNNs),
some of which have achieved a beyond human-level performance. However, recent
top-performing edge detection methods tend to generate thick and noisy edge
lines. In this work, we solve this problem from two aspects: (1) the lack of
prior knowledge regarding image edges, and (2) the issue of imbalanced pixel
distribution. We propose a second-order derivative-based multi-scale contextual
enhancement module (SDMCM) to help the model locate true edge pixels accurately
by introducing the edge prior knowledge. We also construct a hybrid focal loss
function (HFL) to alleviate the imbalanced distribution issue. In addition, we
employ the conditionally parameterized convolution (CondConv) to develop a
novel boundary refinement module (BRM), which can further refine the final
output edge maps. In the end, we propose a U-shape network named LUS-Net which
is based on the SDMCM and BRM for crisp edge detection. We perform extensive
experiments on three standard benchmarks, and the experiment results illustrate
that our method can predict crisp and clean edge maps and achieves
state-of-the-art performance on the BSDS500 dataset (ODS=0.829), NYUD-V2
dataset (ODS=0.768), and BIPED dataset (ODS=0.903).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DWARF: Disease-weighted network for attention map refinement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17032v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17032v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhe Luo, Aurélie Pahud de Mortanges, Oana Inel, Abraham Bernstein, Mauricio Reyes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The interpretability of deep learning is crucial for evaluating the
reliability of medical imaging models and reducing the risks of inaccurate
patient recommendations. This study addresses the "human out of the loop" and
"trustworthiness" issues in medical image analysis by integrating medical
professionals into the interpretability process. We propose a disease-weighted
attention map refinement network (DWARF) that leverages expert feedback to
enhance model relevance and accuracy. Our method employs cyclic training to
iteratively improve diagnostic performance, generating precise and
interpretable feature maps. Experimental results demonstrate significant
improvements in interpretability and diagnostic accuracy across multiple
medical imaging datasets. This approach fosters effective collaboration between
AI systems and healthcare professionals, ultimately aiming to improve patient
outcomes
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modeling State Shifting via Local-Global Distillation for Event-Frame
  Gaze Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00548v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00548v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiading Li, Zhiyu Zhu, Jinhui Hou, Junhui Hou, Jinjian Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper tackles the problem of passive gaze estimation using both event
and frame data. Considering the inherently different physiological structures,
it is intractable to accurately estimate gaze purely based on a given state.
Thus, we reformulate gaze estimation as the quantification of the state
shifting from the current state to several prior registered anchor states.
Specifically, we propose a two-stage learning-based gaze estimation framework
that divides the whole gaze estimation process into a coarse-to-fine approach
involving anchor state selection and final gaze location. Moreover, to improve
the generalization ability, instead of learning a large gaze estimation network
directly, we align a group of local experts with a student network, where a
novel denoising distillation algorithm is introduced to utilize denoising
diffusion techniques to iteratively remove inherent noise in event data.
Extensive experiments demonstrate the effectiveness of the proposed method,
which surpasses state-of-the-art methods by a large margin of 15$\%$. The code
will be publicly available at
https://github.com/jdjdli/Denoise_distill_EF_gazetracker.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tracking Object Positions in Reinforcement Learning: A Metric for
  Keypoint Detection (extended version) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emma Cramer, Jonas Reiher, Sebastian Trimpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) for robot control typically requires a detailed
representation of the environment state, including information about
task-relevant objects not directly measurable. Keypoint detectors, such as
spatial autoencoders (SAEs), are a common approach to extracting a
low-dimensional representation from high-dimensional image data. SAEs aim at
spatial features such as object positions, which are often useful
representations in robotic RL. However, whether an SAE is actually able to
track objects in the scene and thus yields a spatial state representation well
suited for RL tasks has rarely been examined due to a lack of established
metrics. In this paper, we propose to assess the performance of an SAE instance
by measuring how well keypoints track ground truth objects in images. We
present a computationally lightweight metric and use it to evaluate common
baseline SAE architectures on image data from a simulated robot task. We find
that common SAEs differ substantially in their spatial extraction capability.
Furthermore, we validate that SAEs that perform well in our metric achieve
superior performance when used in downstream RL. Thus, our metric is an
effective and lightweight indicator of RL performance before executing
expensive RL training. Building on these insights, we identify three key
modifications of SAE architectures to improve tracking performance. We make our
code available at anonymous.4open.science/r/sae-rl.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LatentExplainer: Explaining Latent Representations in Deep Generative
  Models with Multi-modal Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14862v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14862v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models like VAEs and diffusion models have advanced various
generation tasks by leveraging latent variables to learn data distributions and
generate high-quality samples. Despite the field of explainable AI making
strides in interpreting machine learning models, understanding latent variables
in generative models remains challenging. This paper introduces
LatentExplainer, a framework for automatically generating semantically
meaningful explanations of latent variables in deep generative models.
LatentExplainer tackles three main challenges: inferring the meaning of latent
variables, aligning explanations with inductive biases, and handling varying
degrees of explainability. By perturbing latent variables and interpreting
changes in generated data, the framework provides a systematic approach to
understanding and controlling the data generation process, enhancing the
transparency and interpretability of deep generative models. We evaluate our
proposed method on several real-world and synthetic datasets, and the results
demonstrate superior performance in generating high-quality explanations of
latent variables.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mining Open Semantics from CLIP: A Relation Transition Perspective for
  Few-Shot Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11252v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11252v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cilin Yan, Haochen Wang, Xiaolong Jiang, Yao Hu, Xu Tang, Guoliang Kang, Efstratios Gavves
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive Vision-Language Pre-training(CLIP) demonstrates impressive
zero-shot capability. The key to improve the adaptation of CLIP to downstream
task with few exemplars lies in how to effectively model and transfer the
useful knowledge embedded in CLIP. Previous work mines the knowledge typically
based on the limited visual samples and close-set semantics (i.e., within
target category set of downstream task). However, the aligned CLIP image/text
encoders contain abundant relationships between visual features and almost
infinite open semantics, which may benefit the few-shot learning but remains
unexplored. In this paper, we propose to mine open semantics as anchors to
perform a relation transition from image-anchor relationship to image-target
relationship to make predictions. Specifically, we adopt a transformer module
which takes the visual feature as "Query", the text features of the anchors as
"Key" and the similarity matrix between the text features of anchor and target
classes as "Value". In this way, the output of such a transformer module
represents the relationship between the image and target categories, i.e., the
classification predictions. To avoid manually selecting the open semantics, we
make the [CLASS] token of input text embedding learnable. We conduct extensive
experiments on eleven representative classification datasets. The results show
that our method performs favorably against previous state-of-the-arts
considering few-shot classification settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Kandinsky 3.0 Technical Report 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03511v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03511v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vladimir Arkhipkin, Andrei Filatov, Viacheslav Vasilev, Anastasia Maltseva, Said Azizov, Igor Pavlov, Julia Agafonova, Andrey Kuznetsov, Denis Dimitrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Kandinsky 3.0, a large-scale text-to-image generation model based
on latent diffusion, continuing the series of text-to-image Kandinsky models
and reflecting our progress to achieve higher quality and realism of image
generation. In this report we describe the architecture of the model, the data
collection procedure, the training technique, and the production system for
user interaction. We focus on the key components that, as we have identified as
a result of a large number of experiments, had the most significant impact on
improving the quality of our model compared to the others. We also describe
extensions and applications of our model, including super resolution,
inpainting, image editing, image-to-video generation, and a distilled version
of Kandinsky 3.0 - Kandinsky 3.1, which does inference in 4 steps of the
reverse process and 20 times faster without visual quality decrease. By
side-by-side human preferences comparison, Kandinsky becomes better in text
understanding and works better on specific domains. The code is available at
https://github.com/ai-forever/Kandinsky-3
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://ai-forever.github.io/Kandinsky-3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deformable MRI Sequence Registration for AI-based Prostate Cancer
  Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.09666v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.09666v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessa Hering, Sarah de Boer, Anindo Saha, Jasper J. Twilt, Mattias P. Heinrich, Derya Yakar, Maarten de Rooij, Henkjan Huisman, Joeran S. Bosma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The PI-CAI (Prostate Imaging: Cancer AI) challenge led to expert-level
diagnostic algorithms for clinically significant prostate cancer detection. The
algorithms receive biparametric MRI scans as input, which consist of
T2-weighted and diffusion-weighted scans. These scans can be misaligned due to
multiple factors in the scanning process. Image registration can alleviate this
issue by predicting the deformation between the sequences. We investigate the
effect of image registration on the diagnostic performance of AI-based prostate
cancer diagnosis. First, the image registration algorithm, developed in
MeVisLab, is analyzed using a dataset with paired lesion annotations. Second,
the effect on diagnosis is evaluated by comparing case-level cancer diagnosis
performance between using the original dataset, rigidly aligned
diffusion-weighted scans, or deformably aligned diffusion-weighted scans. Rigid
registration showed no improvement. Deformable registration demonstrated a
substantial improvement in lesion overlap (+10% median Dice score) and a
positive yet non-significant improvement in diagnostic performance (+0.3%
AUROC, p=0.18). Our investigation shows that a substantial improvement in
lesion alignment does not directly lead to a significant improvement in
diagnostic performance. Qualitative analysis indicated that jointly developing
image registration methods and diagnostic AI algorithms could enhance
diagnostic accuracy and patient outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatic Data Curation for <span class="highlight-title">Self-Supervised</span> Learning: A Clustering-Based
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15613v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15613v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huy V. Vo, Vasil Khalidov, Timothée Darcet, Théo Moutakanni, Nikita Smetanin, Marc Szafraniec, Hugo Touvron, Camille Couprie, Maxime Oquab, Armand Joulin, Hervé Jégou, Patrick Labatut, Piotr Bojanowski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised features are the cornerstone of modern machine learning
systems. They are typically pre-trained on data collections whose construction
and curation typically require extensive human effort. This manual process has
some limitations similar to those encountered in supervised learning, e.g., the
crowd-sourced selection of data is costly and time-consuming, preventing
scaling the dataset size. In this work, we consider the problem of automatic
curation of high-quality datasets for self-supervised pre-training. We posit
that such datasets should be large, diverse and balanced, and propose a
clustering-based approach for building ones satisfying all these criteria. Our
method involves successive and hierarchical applications of $k$-means on a
large and diverse data repository to obtain clusters that distribute uniformly
among data concepts, followed by a hierarchical, balanced sampling step from
these clusters. Extensive experiments on three different data domains including
web-based images, satellite images and text show that features trained on our
automatically curated datasets outperform those trained on uncurated data while
being on par or better than ones trained on manually curated data. Code is
available at https://github.com/facebookresearch/ssl-data-curation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LiverUSRecon: Automatic 3D Reconstruction and Volumetry of the Liver
  with a Few Partial Ultrasound Scans <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19336v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19336v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaushalya Sivayogaraj, Sahan T. Guruge, Udari Liyanage, Jeevani Udupihille, Saroj Jayasinghe, Gerard Fernando, Ranga Rodrigo, M. Rukshani Liyanaarachchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D reconstruction of the liver for volumetry is important for qualitative
analysis and disease diagnosis. Liver volumetry using ultrasound (US) scans,
although advantageous due to less acquisition time and safety, is challenging
due to the inherent noisiness in US scans, blurry boundaries, and partial liver
visibility. We address these challenges by using the segmentation masks of a
few incomplete sagittal-plane US scans of the liver in conjunction with a
statistical shape model (SSM) built using a set of CT scans of the liver. We
compute the shape parameters needed to warp this canonical SSM to fit the US
scans through a parametric regression network. The resulting 3D liver
reconstruction is accurate and leads to automatic liver volume calculation. We
evaluate the accuracy of the estimated liver volumes with respect to CT
segmentation volumes using RMSE. Our volume computation is statistically much
closer to the volume estimated using CT scans than the volume computed using
Childs' method by radiologists: p-value of 0.094 (>0.05) says that there is no
significant difference between CT segmentation volumes and ours in contrast to
Childs' method. We validate our method using investigations (ablation studies)
on the US image resolution, the number of CT scans used for SSM, the number of
principal components, and the number of input US scans. To the best of our
knowledge, this is the first automatic liver volumetry system using a few
incomplete US scans given a set of CT scans of livers for SSM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, Accepted to MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-domain Denoising for Low-dose Multi-frame Spiral Computed
  Tomography 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.10839v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.10839v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucheng Lu, Zhixin Xu, Moon Hyung Choi, Jimin Kim, Seung-Won Jung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computed tomography (CT) has been used worldwide as a non-invasive test to
assist in diagnosis. However, the ionizing nature of X-ray exposure raises
concerns about potential health risks such as cancer. The desire for lower
radiation doses has driven researchers to improve reconstruction quality.
Although previous studies on low-dose computed tomography (LDCT) denoising have
demonstrated the effectiveness of learning-based methods, most were developed
on the simulated data. However, the real-world scenario differs significantly
from the simulation domain, especially when using the multi-slice spiral
scanner geometry. This paper proposes a two-stage method for the commercially
available multi-slice spiral CT scanners that better exploits the complete
reconstruction pipeline for LDCT denoising across different domains. Our
approach makes good use of the high redundancy of multi-slice projections and
the volumetric reconstructions while leveraging the over-smoothing problem in
conventional cascaded frameworks caused by aggressive denoising. The dedicated
design also provides a more explicit interpretation of the data flow. Extensive
experiments on various datasets showed that the proposed method could remove up
to 70\% of noise without compromised spatial resolution, and subjective
evaluations by two experienced radiologists further supported its superior
performance against state-of-the-art methods in clinical practice.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Defect Detection in Synthetic Fibre Ropes using Detectron2 Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.01469v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.01469v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anju Rani, Daniel O. Arroyo, Petar Durdevic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fibre ropes with the latest technology have emerged as an appealing
alternative to steel ropes for offshore industries due to their lightweight and
high tensile strength. At the same time, frequent inspection of these ropes is
essential to ensure the proper functioning and safety of the entire system. The
development of deep learning (DL) models in condition monitoring (CM)
applications offers a simpler and more effective approach for defect detection
in synthetic fibre ropes (SFRs). The present paper investigates the performance
of Detectron2, a state-of-the-art library for defect detection and instance
segmentation. Detectron2 with Mask R-CNN architecture is used for segmenting
defects in SFRs. Mask R-CNN with various backbone configurations has been
trained and tested on an experimentally obtained dataset comprising 1,803
high-dimensional images containing seven damage classes (placking high,
placking medium, placking low, compression, core out, chafing, and normal
respectively) for SFRs. By leveraging the capabilities of Detectron2, this
study aims to develop an automated and efficient method for detecting defects
in SFRs, enhancing the inspection process, and ensuring the safety of the fibre
ropes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assessment of Sentinel-2 spatial and temporal coverage based on the
  scene classification layer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18584v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18584v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cristhian Sanchez, Francisco Mena, Marcela Charfuelan, Marlon Nuske, Andreas Dengel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since the launch of the Sentinel-2 (S2) satellites, many ML models have used
the data for diverse applications. The scene classification layer (SCL) inside
the S2 product provides rich information for training, such as filtering images
with high cloud coverage. However, there is more potential in this. We propose
a technique to assess the clean optical coverage of a region, expressed by a
SITS and calculated with the S2-based SCL data. With a manual threshold and
specific labels in the SCL, the proposed technique assigns a percentage of
spatial and temporal coverage across the time series and a high/low assessment.
By evaluating the AI4EO challenge for Enhanced Agriculture, we show that the
assessment is correlated to the predictive results of ML models. The
classification results in a region with low spatial and temporal coverage is
worse than in a region with high coverage. Finally, we applied the technique
across all continents of the global dataset LandCoverNet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IEEE International Geoscience and Remote Sensing
  Symposium 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Logical Closed Loop: Uncovering Object Hallucinations in Large
  Vision-Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11622v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11622v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfei Wu, Qiang Liu, Ding Wang, Jinghao Zhang, Shu Wu, Liang Wang, Tieniu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object hallucination has been an Achilles' heel which hinders the broader
applications of large vision-language models (LVLMs). Object hallucination
refers to the phenomenon that the LVLMs claim non-existent objects in the
image. To mitigate the object hallucinations, instruction tuning and external
model-based detection methods have been proposed, which either require
large-scare computational resources or depend on the detection result of
external models. However, there remains an under-explored field to utilize the
LVLM itself to alleviate object hallucinations. In this work, we adopt the
intuition that the LVLM tends to respond logically consistently for existent
objects but inconsistently for hallucinated objects. Therefore, we propose a
Logical Closed Loop-based framework for Object Hallucination Detection and
Mitigation, namely LogicCheckGPT. In specific, we devise logical consistency
probing to raise questions with logical correlations, inquiring about
attributes from objects and vice versa. Whether their responses can form a
logical closed loop serves as an indicator of object hallucination. As a
plug-and-play method, it can be seamlessly applied to all existing LVLMs.
Comprehensive experiments conducted on three benchmarks across four LVLMs have
demonstrated significant improvements brought by our method, indicating its
effectiveness and generality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Viewport Prediction for Volumetric Video Streaming by Exploring Video
  Saliency and Trajectory Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16462v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16462v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Li, Zhixin Li, Zhi Liu, Pengyuan Zhou, Richang Hong, Qiyue Li, Han Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Volumetric video, also known as hologram video, is a novel medium that
portrays natural content in Virtual Reality (VR), Augmented Reality (AR), and
Mixed Reality (MR). It is expected to be the next-gen video technology and a
prevalent use case for 5G and beyond wireless communication. Considering that
each user typically only watches a section of the volumetric video, known as
the viewport, it is essential to have precise viewport prediction for optimal
performance. However, research on this topic is still in its infancy. In the
end, this paper presents and proposes a novel approach, named Saliency and
Trajectory Viewport Prediction (STVP), which aims to improve the precision of
viewport prediction in volumetric video streaming. The STVP extensively
utilizes video saliency information and viewport trajectory. To our knowledge,
this is the first comprehensive study of viewport prediction in volumetric
video streaming. In particular, we introduce a novel sampling method, Uniform
Random Sampling (URS), to reduce computational complexity while still
preserving video features in an efficient manner. Then we present a saliency
detection technique that incorporates both spatial and temporal information for
detecting static, dynamic geometric, and color salient regions. Finally, we
intelligently fuse saliency and trajectory information to achieve more accurate
viewport prediction. We conduct extensive simulations to evaluate the
effectiveness of our proposed viewport prediction methods using
state-of-the-art volumetric video sequences. The experimental results show the
superiority of the proposed method over existing schemes. The dataset and
source code will be publicly accessible after acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FAGhead: Fully Animate Gaussian Head from Monocular Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19070v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19070v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Xuan, Xinyang Li, Gongxin Yao, Shiwei Zhou, Donghui Sun, Xiaoxin Chen, Yu Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-fidelity reconstruction of 3D human avatars has a wild application in
visual reality. In this paper, we introduce FAGhead, a method that enables
fully controllable human portraits from monocular videos. We explicit the
traditional 3D morphable meshes (3DMM) and optimize the neutral 3D Gaussians to
reconstruct with complex expressions. Furthermore, we employ a novel
Point-based Learnable Representation Field (PLRF) with learnable Gaussian point
positions to enhance reconstruction performance. Meanwhile, to effectively
manage the edges of avatars, we introduced the alpha rendering to supervise the
alpha value of each pixel. Extensive experimental results on the open-source
datasets and our capturing datasets demonstrate that our approach is able to
generate high-fidelity 3D head avatars and fully control the expression and
pose of the virtual avatars, which is outperforming than existing works.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Refer-and-Ground Multimodal Large Language Model for Biomedicine <span class="chip">MICCAI2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18146v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18146v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoshuang Huang, Haifeng Huang, Lingdong Shen, Yehui Yang, Fangxin Shang, Junwei Liu, Jia Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of multimodal large language models (MLLMs),
especially their capabilities in visual chat through refer and ground
functionalities, their significance is increasingly recognized. However, the
biomedical field currently exhibits a substantial gap in this area, primarily
due to the absence of a dedicated refer and ground dataset for biomedical
images. To address this challenge, we devised the Med-GRIT-270k dataset. It
comprises 270k question-and-answer pairs and spans eight distinct medical
imaging modalities. Most importantly, it is the first dedicated to the
biomedical domain and integrating refer and ground conversations. The key idea
is to sample large-scale biomedical image-mask pairs from medical segmentation
datasets and generate instruction datasets from text using chatGPT.
Additionally, we introduce a Refer-and-Ground Multimodal Large Language Model
for Biomedicine (BiRD) by using this dataset and multi-task instruction
learning. Extensive experiments have corroborated the efficacy of the
Med-GRIT-270k dataset and the multi-modal, fine-grained interactive
capabilities of the BiRD model. This holds significant reference value for the
exploration and development of intelligent biomedical assistants.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ProbRadarM3F: mmWave Radar based Human Skeletal Pose Estimation with
  Probability Map Guided Multi-Format Feature Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.05164v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.05164v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bing Zhu, Zixin He, Weiyi Xiong, Guanhua Ding, Jianan Liu, Tao Huang, Wei Chen, Wei Xiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Millimeter wave (mmWave) radar is a non-intrusive privacy and relatively
convenient and inexpensive device, which has been demonstrated to be applicable
in place of RGB cameras in human indoor pose estimation tasks. However, mmWave
radar relies on the collection of reflected signals from the target, and the
radar signals containing information is difficult to be fully applied. This has
been a long-standing hindrance to the improvement of pose estimation accuracy.
To address this major challenge, this paper introduces a probability map guided
multi-format feature fusion model, ProbRadarM3F. This is a novel radar feature
extraction framework using a traditional FFT method in parallel with a
probability map based positional encoding method. ProbRadarM3F fuses the
traditional heatmap features and the positional features, then effectively
achieves the estimation of 14 keypoints of the human body. Experimental
evaluation on the HuPR dataset proves the effectiveness of the model proposed
in this paper, outperforming other methods experimented on this dataset with an
AP of 69.9 %. The emphasis of our study is focusing on the position information
that is not exploited before in radar singal. This provides direction to
investigate other potential non-redundant information from mmWave rader.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text
  Cues <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19364v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19364v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Xie, Tao Zhou, Yi Zhou, Geng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly-supervised medical image segmentation is a challenging task that aims
to reduce the annotation cost while keep the segmentation performance. In this
paper, we present a novel framework, SimTxtSeg, that leverages simple text cues
to generate high-quality pseudo-labels and study the cross-modal fusion in
training segmentation models, simultaneously. Our contribution consists of two
key components: an effective Textual-to-Visual Cue Converter that produces
visual prompts from text prompts on medical images, and a text-guided
segmentation model with Text-Vision Hybrid Attention that fuses text and image
features. We evaluate our framework on two medical image segmentation tasks:
colonic polyp segmentation and MRI brain tumor segmentation, and achieve
consistent state-of-the-art performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging Knowledge Distillation for Lightweight Skin Cancer
  Classification: Balancing Accuracy and Computational Efficiency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17051v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17051v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niful Islam, Khan Md Hasib, Fahmida Akter Joti, Asif Karim, Sami Azam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Skin cancer is a major concern to public health, accounting for one-third of
the reported cancers. If not detected early, the cancer has the potential for
severe consequences. Recognizing the critical need for effective skin cancer
classification, we address the limitations of existing models, which are often
too large to deploy in areas with limited computational resources. In response,
we present a knowledge distillation based approach for creating a lightweight
yet high-performing classifier. The proposed solution involves fusing three
models, namely ResNet152V2, ConvNeXtBase, and ViT Base, to create an effective
teacher model. The teacher model is then employed to guide a lightweight
student model of size 2.03 MB. This student model is further compressed to
469.77 KB using 16-bit quantization, enabling smooth incorporation into edge
devices. With six-stage image preprocessing, data augmentation, and a rigorous
ablation study, the model achieves an impressive accuracy of 98.75% on the
HAM10000 dataset and 98.94% on the Kaggle dataset in classifying benign and
malignant skin cancers. With its high accuracy and compact size, our model
appears to be a potential choice for accurate skin cancer classification,
particularly in resource-constrained settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with
  Flowcharts <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for visual question answering lack in visual grounding
and complexity, particularly in evaluating spatial reasoning skills. We
introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of
visual question-answering multimodal language models in reasoning with
flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and
human-verified flowchart images from three distinct content sources, along with
22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,
including information localization, decision-making, and logical progression.
We conduct a thorough baseline evaluation on a suite of both open-source and
proprietary multimodal language models using various strategies, followed by an
analysis of directional bias. The results underscore the benchmark's potential
as a vital tool for advancing the field of multimodal modeling, providing a
focused and challenging environment for enhancing model performance in visual
and logical reasoning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ACL 2024 (Findings), 21 pages, 7 figures, 9 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CSI4Free: GAN-Augmented mmWave CSI for Improved Pose Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18684v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18684v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nabeel Nisar Bhat, Rafael Berkvens, Jeroen Famaey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Joint Communication and Sensing (JC&S), has demonstrated
significant success, particularly in utilizing sub-6 GHz frequencies with
commercial-off-the-shelf (COTS) Wi-Fi devices for applications such as
localization, gesture recognition, and pose classification. Deep learning and
the existence of large public datasets has been pivotal in achieving such
results. However, at mmWave frequencies (30-300 GHz), which has shown potential
for more accurate sensing performance, there is a noticeable lack of research
in the domain of COTS Wi-Fi sensing. Challenges such as limited research
hardware, the absence of large datasets, limited functionality in COTS
hardware, and the complexities of data collection present obstacles to a
comprehensive exploration of this field. In this work, we aim to address these
challenges by developing a method that can generate synthetic mmWave channel
state information (CSI) samples. In particular, we use a generative adversarial
network (GAN) on an existing dataset, to generate 30,000 additional CSI
samples. The augmented samples exhibit a remarkable degree of consistency with
the original data, as indicated by the notably high GAN-train and GAN-test
scores. Furthermore, we integrate the augmented samples in training a pose
classification model. We observe that the augmented samples complement the real
data and improve the generalization of the classification model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ All-In-One Medical Image Restoration via Task-Adaptive Routing <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19769v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19769v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiwen Yang, Haowei Chen, Ziniu Qian, Yang Yi, Hui Zhang, Dan Zhao, Bingzheng Wei, Yan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although single-task medical image restoration (MedIR) has witnessed
remarkable success, the limited generalizability of these methods poses a
substantial obstacle to wider application. In this paper, we focus on the task
of all-in-one medical image restoration, aiming to address multiple distinct
MedIR tasks with a single universal model. Nonetheless, due to significant
differences between different MedIR tasks, training a universal model often
encounters task interference issues, where different tasks with shared
parameters may conflict with each other in the gradient update direction. This
task interference leads to deviation of the model update direction from the
optimal path, thereby affecting the model's performance. To tackle this issue,
we propose a task-adaptive routing strategy, allowing conflicting tasks to
select different network paths in spatial and channel dimensions, thereby
mitigating task interference. Experimental results demonstrate that our
proposed \textbf{A}ll-in-one \textbf{M}edical \textbf{I}mage
\textbf{R}estoration (\textbf{AMIR}) network achieves state-of-the-art
performance in three MedIR tasks: MRI super-resolution, CT denoising, and PET
synthesis, both in single-task and all-in-one settings. The code and data will
be available at
\href{https://github.com/Yaziwel/All-In-One-Medical-Image-Restoration-via-Task-Adaptive-Routing.git}{https://github.com/Yaziwel/AMIR}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This article has been early accepted by MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revisiting Backdoor Attacks against Large Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18844v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18844v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Liang, Jiawei Liang, Tianyu Pang, Chao Du, Aishan Liu, Ee-Chien Chang, Xiaochun Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction tuning enhances large vision-language models (LVLMs) but raises
security risks through potential backdoor attacks due to their openness.
Previous backdoor studies focus on enclosed scenarios with consistent training
and testing instructions, neglecting the practical domain gaps that could
affect attack effectiveness. This paper empirically examines the
generalizability of backdoor attacks during the instruction tuning of LVLMs for
the first time, revealing certain limitations of most backdoor strategies in
practical scenarios. We quantitatively evaluate the generalizability of six
typical backdoor attacks on image caption benchmarks across multiple LVLMs,
considering both visual and textual domain offsets. Our findings indicate that
attack generalizability is positively correlated with the backdoor trigger's
irrelevance to specific images/models and the preferential correlation of the
trigger pattern. Additionally, we modify existing backdoor attacks based on the
above key observations, demonstrating significant improvements in cross-domain
scenario generalizability (+86% attack success rate). Notably, even without
access to the instruction datasets, a multimodal instruction set can be
successfully poisoned with a very low poisoning rate (0.2%), achieving an
attack success rate of over 97%. This paper underscores that even simple
traditional backdoor strategies pose a serious threat to LVLMs, necessitating
more attention and in-depth research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative Autoencoding of Dropout Patterns 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.01712v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.01712v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shunta Maeda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a generative model termed Deciphering Autoencoders. In this model,
we assign a unique random dropout pattern to each data point in the training
dataset and then train an autoencoder to reconstruct the corresponding data
point using this pattern as information to be encoded. Even if a completely
random dropout pattern is assigned to each data point regardless of their
similarities, a sufficiently large encoder can smoothly map them to a
low-dimensional latent space to reconstruct individual training data points.
During inference, using a dropout pattern different from those used during
training allows the model to function as a generator. Since the training of
Deciphering Autoencoders relies solely on reconstruction error, it offers more
stable training compared to other generative models. Despite their simplicity,
Deciphering Autoencoders show sampling quality comparable to DCGAN on the
CIFAR-10 dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EgoVideo: Exploring Egocentric Foundation Model and Downstream
  Adaptation <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18070v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18070v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baoqi Pei, Guo Chen, Jilan Xu, Yuping He, Yicheng Liu, Kanghua Pan, Yifei Huang, Yali Wang, Tong Lu, Limin Wang, Yu Qiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this report, we present our solutions to the EgoVis Challenges in CVPR
2024, including five tracks in the Ego4D challenge and three tracks in the
EPIC-Kitchens challenge. Building upon the video-language two-tower model and
leveraging our meticulously organized egocentric video data, we introduce a
novel foundation model called EgoVideo. This model is specifically designed to
cater to the unique characteristics of egocentric videos and provides strong
support for our competition submissions. In the Ego4D challenges, we tackle
various tasks including Natural Language Queries, Step Grounding, Moment
Queries, Short-term Object Interaction Anticipation, and Long-term Action
Anticipation. In addition, we also participate in the EPIC-Kitchens challenge,
where we engage in the Action Recognition, Multiple Instance Retrieval, and
Domain Adaptation for Action Recognition tracks. By adapting EgoVideo to these
diverse tasks, we showcase its versatility and effectiveness in different
egocentric video analysis scenarios, demonstrating the powerful representation
ability of EgoVideo as an egocentric foundation model. Our codebase and
pretrained models are publicly available at
https://github.com/OpenGVLab/EgoVideo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Champion solutions in the EgoVis CVPR 2024 workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AlignIT: Enhancing <span class="highlight-title">Prompt</span> Alignment in Customization of Text-to-Image
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18893v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18893v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aishwarya Agarwal, Srikrishna Karanam, Balaji Vasan Srinivasan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of customizing text-to-image diffusion models with
user-supplied reference images. Given new prompts, the existing methods can
capture the key concept from the reference images but fail to align the
generated image with the prompt. In this work, we seek to address this key
issue by proposing new methods that can easily be used in conjunction with
existing customization methods that optimize the embeddings/weights at various
intermediate stages of the text encoding process.
  The first contribution of this paper is a dissection of the various stages of
the text encoding process leading up to the conditioning vector for
text-to-image models. We take a holistic view of existing customization methods
and notice that key and value outputs from this process differs substantially
from their corresponding baseline (non-customized) models (e.g., baseline
stable diffusion). While this difference does not impact the concept being
customized, it leads to other parts of the generated image not being aligned
with the prompt. Further, we also observe that these keys and values allow
independent control various aspects of the final generation, enabling semantic
manipulation of the output. Taken together, the features spanning these keys
and values, serve as the basis for our next contribution where we fix the
aforementioned issues with existing methods. We propose a new post-processing
algorithm, AlignIT, that infuses the keys and values for the concept of
interest while ensuring the keys and values for all other tokens in the input
prompt are unchanged.
  Our proposed method can be plugged in directly to existing customization
methods, leading to a substantial performance improvement in the alignment of
the final result with the input prompt while retaining the customization
quality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Character-Adapter: <span class="highlight-title">Prompt</span>-Guided Region Control for High-Fidelity
  Character Customization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16537v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16537v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhang Ma, Wenting Xu, Jiji Tang, Qinfeng Jin, Rongsheng Zhang, Zeng Zhao, Changjie Fan, Zhipeng Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Customized image generation, which seeks to synthesize images with consistent
characters, holds significant relevance for applications such as storytelling,
portrait generation, and character design. However, previous approaches have
encountered challenges in preserving characters with high-fidelity consistency
due to inadequate feature extraction and concept confusion of reference
characters. Therefore, we propose Character-Adapter, a plug-and-play framework
designed to generate images that preserve the details of reference characters,
ensuring high-fidelity consistency. Character-Adapter employs prompt-guided
segmentation to ensure fine-grained regional features of reference characters
and dynamic region-level adapters to mitigate concept confusion. Extensive
experiments are conducted to validate the effectiveness of Character-Adapter.
Both quantitative and qualitative results demonstrate that Character-Adapter
achieves the state-of-the-art performance of consistent character generation,
with an improvement of 24.8% compared with other methods. Our code will be
released at https://github.com/Character-Adapter/Character-Adapte
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MolX: Enhancing Large Language Models for Molecular Learning with A
  Multi-Modal Extension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06777v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06777v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khiem Le, Zhichun Guo, Kaiwen Dong, Xiaobao Huang, Bozhao Nan, Roshni Iyer, Xiangliang Zhang, Olaf Wiest, Wei Wang, Nitesh V. Chawla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Large Language Models (LLMs) with their strong task-handling
capabilities have shown remarkable advancements across a spectrum of fields,
moving beyond natural language understanding. However, their proficiency within
the chemistry domain remains restricted, especially in solving professional
molecule-related tasks. This challenge is attributed to their inherent
limitations in comprehending molecules using only common textual
representations, i.e., SMILES strings. In this study, we seek to enhance the
ability of LLMs to comprehend molecules by designing and equipping them with a
multi-modal external module, namely MolX. In particular, instead of directly
using a SMILES string to represent a molecule, we utilize specific encoders to
extract fine-grained features from both SMILES string and 2D molecular graph
representations for feeding into an LLM. Moreover, a human-defined molecular
fingerprint is incorporated to leverage its embedded domain knowledge. Then, to
establish an alignment between MolX and the LLM's textual input space, the
whole model in which the LLM is frozen, is pre-trained with a versatile
strategy including a diverse set of tasks. Extensive experimental evaluations
demonstrate that our proposed method only introduces a small number of
trainable parameters while outperforming baselines on various downstream
molecule-related tasks ranging from molecule-to-text translation to
retrosynthesis, with and without fine-tuning the LLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AnyControl: Create Your Artwork with Versatile Control on Text-to-Image
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18958v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18958v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanan Sun, Yanchen Liu, Yinhao Tang, Wenjie Pei, Kai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of text-to-image (T2I) generation has made significant progress in
recent years, largely driven by advancements in diffusion models. Linguistic
control enables effective content creation, but struggles with fine-grained
control over image generation. This challenge has been explored, to a great
extent, by incorporating additional user-supplied spatial conditions, such as
depth maps and edge maps, into pre-trained T2I models through extra encoding.
However, multi-control image synthesis still faces several challenges.
Specifically, current approaches are limited in handling free combinations of
diverse input control signals, overlook the complex relationships among
multiple spatial conditions, and often fail to maintain semantic alignment with
provided textual prompts. This can lead to suboptimal user experiences. To
address these challenges, we propose AnyControl, a multi-control image
synthesis framework that supports arbitrary combinations of diverse control
signals. AnyControl develops a novel Multi-Control Encoder that extracts a
unified multi-modal embedding to guide the generation process. This approach
enables a holistic understanding of user inputs, and produces high-quality,
faithful results under versatile control signals, as demonstrated by extensive
quantitative and qualitative evaluations. Our project page is available in
https://any-control.github.io.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Manipulate-Anything: Automating Real-World Robots using Vision-Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18915v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18915v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiafei Duan, Wentao Yuan, Wilbert Pumacay, Yi Ru Wang, Kiana Ehsani, Dieter Fox, Ranjay Krishna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large-scale endeavors like RT-1 and widespread community efforts such as
Open-X-Embodiment have contributed to growing the scale of robot demonstration
data. However, there is still an opportunity to improve the quality, quantity,
and diversity of robot demonstration data. Although vision-language models have
been shown to automatically generate demonstration data, their utility has been
limited to environments with privileged state information, they require
hand-designed skills, and are limited to interactions with few object
instances. We propose Manipulate-Anything, a scalable automated generation
method for real-world robotic manipulation. Unlike prior work, our method can
operate in real-world environments without any privileged state information,
hand-designed skills, and can manipulate any static object. We evaluate our
method using two setups. First, Manipulate-Anything successfully generates
trajectories for all 5 real-world and 12 simulation tasks, significantly
outperforming existing methods like VoxPoser. Second, Manipulate-Anything's
demonstrations can train more robust behavior cloning policies than training
with human demonstrations, or from data generated by VoxPoser and
Code-As-Policies. We believe Manipulate-Anything can be the scalable method for
both generating data for robotics and solving novel tasks in a zero-shot
setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://robot-ma.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Epicardium <span class="highlight-title">Prompt</span>-guided Real-time Cardiac Ultrasound Frame-to-volume
  Registration <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14534v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14534v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Long Lei, Jun Zhou, Jialun Pei, Baoliang Zhao, Yueming Jin, Yuen-Chun Jeremy Teoh, Jing Qin, Pheng-Ann Heng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A comprehensive guidance view for cardiac interventional surgery can be
provided by the real-time fusion of the intraoperative 2D images and
preoperative 3D volume based on the ultrasound frame-to-volume registration.
However, cardiac ultrasound images are characterized by a low signal-to-noise
ratio and small differences between adjacent frames, coupled with significant
dimension variations between 2D frames and 3D volumes to be registered,
resulting in real-time and accurate cardiac ultrasound frame-to-volume
registration being a very challenging task. This paper introduces a lightweight
end-to-end Cardiac Ultrasound frame-to-volume Registration network, termed
CU-Reg. Specifically, the proposed model leverages epicardium prompt-guided
anatomical clues to reinforce the interaction of 2D sparse and 3D dense
features, followed by a voxel-wise local-global aggregation of enhanced
features, thereby boosting the cross-dimensional matching effectiveness of
low-quality ultrasound modalities. We further embed an inter-frame
discriminative regularization term within the hybrid supervised learning to
increase the distinction between adjacent slices in the same ultrasound volume
to ensure registration stability. Experimental results on the reprocessed CAMUS
dataset demonstrate that our CU-Reg surpasses existing methods in terms of
registration accuracy and efficiency, meeting the guidance requirements of
clinical cardiac interventional surgery.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Solving the Inverse Problem of Electrocardiography for Cardiac Digital
  Twins: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11445v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11445v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Li, Julia Camps, Blanca Rodriguez, Vicente Grau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cardiac digital twins are personalized virtual representations used to
understand complex heart mechanisms. Solving the ECG inverse problem is crucial
for accurate virtual heart modelling, enabling the derivation of internal
electrical activity information from recorded surface potentials. Despite
challenges from cardiac complexity, noisy ECG data, and computational
efficiency, recent advancements hold significant promise for enhancing virtual
heart modelling, ultimately advancing precision medicine in cardiology. This
paper aims to provide a comprehensive review of the methods of solving ECG
inverse problem, the validation strategies, the clinical applications, and
future perspectives. For the computing methodologies, we broadly classify
state-of-the-art approaches into two categories: deterministic and
probabilistic methods, including conventional and deep learning-based
techniques. Integrating physics laws with deep learning models holds promise,
but challenges such as capturing dynamic electrophysiology accurately,
accessing accurate domain knowledge, and quantifying prediction uncertainty
persist. Integrating models into clinical workflows while ensuring
interpretability and usability for healthcare professionals is essential.
Overcoming these challenges will drive further research in cardiac digital
twins.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04940v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04940v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wentao Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image person re-identification (ReID) retrieves pedestrian images
according to textual descriptions. Manually annotating textual descriptions is
time-consuming, restricting the scale of existing datasets and therefore the
generalization ability of ReID models. As a result, we study the transferable
text-to-image ReID problem, where we train a model on our proposed large-scale
database and directly deploy it to various datasets for evaluation. We obtain
substantial training data via Multi-modal Large Language Models (MLLMs).
Moreover, we identify and address two key challenges in utilizing the obtained
textual descriptions. First, an MLLM tends to generate descriptions with
similar structures, causing the model to overfit specific sentence patterns.
Thus, we propose a novel method that uses MLLMs to caption images according to
various templates. These templates are obtained using a multi-turn dialogue
with a Large Language Model (LLM). Therefore, we can build a large-scale
dataset with diverse textual descriptions. Second, an MLLM may produce
incorrect descriptions. Hence, we introduce a novel method that automatically
identifies words in a description that do not correspond with the image. This
method is based on the similarity between one text and all patch token
embeddings in the image. Then, we mask these words with a larger probability in
the subsequent training epoch, alleviating the impact of noisy textual
descriptions. The experimental results demonstrate that our methods
significantly boost the direct transfer text-to-image ReID performance.
Benefiting from the pre-trained model weights, we also achieve state-of-the-art
performance in the traditional evaluation settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">9</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactive Topic Models with Optimal Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Garima Dhanania, Sheshera Mysore, Chau Minh Pham, Mohit Iyyer, Hamed Zamani, Andrew McCallum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic models are widely used to analyze document collections. While they are
valuable for discovering latent topics in a corpus when analysts are unfamiliar
with the corpus, analysts also commonly start with an understanding of the
content present in a corpus. This may be through categories obtained from an
initial pass over the corpus or a desire to analyze the corpus through a
predefined set of categories derived from a high level theoretical framework
(e.g. political ideology). In these scenarios analysts desire a topic modeling
approach which incorporates their understanding of the corpus while supporting
various forms of interaction with the model. In this work, we present EdTM, as
an approach for label name supervised topic modeling. EdTM models topic
modeling as an assignment problem while leveraging LM/LLM based document-topic
affinities and using optimal transport for making globally coherent
topic-assignments. In experiments, we show the efficacy of our framework
compared to few-shot LLM classifiers, and topic models based on clustering and
LDA. Further, we show EdTM's ability to incorporate various forms of analyst
feedback and while remaining robust to noisy analyst inputs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print; Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rateless Stochastic Coding for Delay-constrained Semantic Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19804v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19804v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng Peng, Rulong Wang, Yong Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of joint source-channel coding with distortion and
perception constraints from a rateless perspective, the purpose of which is to
settle the balance between reliability (distortion/perception) and
effectiveness (rate) of transmission over uncertain channels. We find a new
finite-blocklength bound for the achievable joint source-channel code rate with
the above two constraints. To achieve a superior rateless characteristic of
JSCC coding, we perform multi-level optimization on various finite-blocklength
codes. Based on these two, we then propose a new JSCC coding scheme called
rateless stochastic coding (RSC). We experimentally demonstrate that the
proposed RSC can achieve variable rates of transmission maintaining an
excellent trade-off between distortion and perception.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case
  Reformulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19760v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19760v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenlong Deng, Kelong Mao, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal case retrieval for sourcing similar cases is critical in upholding
judicial fairness. Different from general web search, legal case retrieval
involves processing lengthy, complex, and highly specialized legal documents.
Existing methods in this domain often overlook the incorporation of legal
expert knowledge, which is crucial for accurately understanding and modeling
legal cases, leading to unsatisfactory retrieval performance. This paper
introduces KELLER, a legal knowledge-guided case reformulation approach based
on large language models (LLMs) for effective and interpretable legal case
retrieval. By incorporating professional legal knowledge about crimes and law
articles, we enable large language models to accurately reformulate the
original legal case into concise sub-facts of crimes, which contain the
essential information of the case. Extensive experiments on two legal case
retrieval benchmarks demonstrate superior retrieval performance and robustness
on complex legal case queries of KELLER over existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Doc2Token: Bridging Vocabulary Gap by Predicting Missing Tokens for
  E-commerce Search <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19647v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19647v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaihao Li, Juexin Lin, Tony Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Addressing the "vocabulary mismatch" issue in information retrieval is a
central challenge for e-commerce search engines, because product pages often
miss important keywords that customers search for. Doc2Query[1] is a popular
document-expansion technique that predicts search queries for a document and
includes the predicted queries with the document for retrieval. However, this
approach can be inefficient for e-commerce search, because the predicted query
tokens are often already present in the document. In this paper, we propose
Doc2Token, a technique that predicts relevant tokens (instead of queries) that
are missing from the document and includes these tokens in the document for
retrieval. For the task of predicting missing tokens, we introduce a new
metric, "novel ROUGE score". Doc2Token is demonstrated to be superior to
Doc2Query in terms of novel ROUGE score and diversity of predictions. Doc2Token
also exhibits efficiency gains by reducing both training and inference times.
We deployed the feature to production and observed significant revenue gain in
an online A/B test, and launched the feature to full traffic on Walmart.com.
  [1] R. Nogueira, W. Yang, J. Lin, K. Cho, Document expansion by query
prediction, arXiv preprint arXiv:1904.08375 (2019)
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 1 figure, SIGIR 2024 Workshop on eCommerce</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GEO: Generative Engine Optimization <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09735v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09735v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranjal Aggarwal, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan, Ameet Deshpande
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of large language models (LLMs) has ushered in a new paradigm of
search engines that use generative models to gather and summarize information
to answer user queries. This emerging technology, which we formalize under the
unified framework of generative engines (GEs), can generate accurate and
personalized responses, rapidly replacing traditional search engines like
Google and Bing. Generative Engines typically satisfy queries by synthesizing
information from multiple sources and summarizing them using LLMs. While this
shift significantly improves $\textit{user}$ utility and $\textit{generative
search engine}$ traffic, it poses a huge challenge for the third stakeholder --
website and content creators. Given the black-box and fast-moving nature of
generative engines, content creators have little to no control over
$\textit{when}$ and $\textit{how}$ their content is displayed. With generative
engines here to stay, we must ensure the creator economy is not disadvantaged.
To address this, we introduce Generative Engine Optimization (GEO), the first
novel paradigm to aid content creators in improving their content visibility in
generative engine responses through a flexible black-box optimization framework
for optimizing and defining visibility metrics. We facilitate systematic
evaluation by introducing GEO-bench, a large-scale benchmark of diverse user
queries across multiple domains, along with relevant web sources to answer
these queries. Through rigorous evaluation, we demonstrate that GEO can boost
visibility by up to $40\%$ in generative engine responses. Moreover, we show
the efficacy of these strategies varies across domains, underscoring the need
for domain-specific optimization methods. Our work opens a new frontier in
information discovery systems, with profound implications for both developers
of generative engines and content creators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning
  and Professional Question Answering Capability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17887v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17887v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junda Wang, Zhichao Yang, Zonghai Yao, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated a remarkable potential in
medical knowledge acquisition and question-answering. However, LLMs can
potentially hallucinate and yield factually incorrect outcomes, even with
domain-specific pretraining. Previously, retrieval augmented generation (RAG)
has limited success in addressing hallucinations. Unlike previous methods in
RAG where the retrieval model was trained separately from the LLM, we introduce
JMLR (for Jointly trains LLM and information Retrieval) during the fine-tuning
phase. The synchronized training mechanism enhances JMLR's ability to retrieve
clinical guidelines and leverage medical knowledge to reason and answer
questions and reduces the demand for computational resources. We evaluated JMLR
on the important medical question-answering application. Our experimental
results demonstrate that JMLR-13B (70.5%) outperforms a previous
state-of-the-art open-source model using conventional pre-training and
fine-tuning Meditron-70B (68.9%) and Llama2-13B with RAG (67.7%) on a medical
question-answering dataset. Comprehensive evaluations reveal JMLR-13B enhances
reasoning quality and reduces hallucinations better than Claude3-Opus.
Additionally, JMLR-13B (148 GPU hours) also trains much faster than
Meditron-70B (42630 GPU hours). Through this work, we provide a new and
efficient knowledge enhancement method for healthcare, demonstrating the
potential of integrating retrieval and LLM training for medical
question-answering systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transparency, Privacy, and Fairness in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11323v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11323v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominik Kowald
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems have become a pervasive part of our daily online
experience, and are one of the most widely used applications of artificial
intelligence and machine learning. Therefore, regulations and requirements for
trustworthy artificial intelligence, for example, the European AI Act, which
includes notions such as transparency, privacy, and fairness are also highly
relevant for the design of recommender systems in practice. This habilitation
elaborates on aspects related to these three notions in the light of
recommender systems, namely: (i) transparency and cognitive models, (ii)
privacy and limited preference information, and (iii) fairness and popularity
bias in recommender systems. Specifically, with respect to aspect (i), we
highlight the usefulness of incorporating psychological theories for a
transparent design process of recommender systems. We term this type of systems
psychology-informed recommender systems. In aspect (ii), we study and address
the trade-off between accuracy and privacy in differentially-private
recommendations. We design a novel recommendation approach for collaborative
filtering based on an efficient neighborhood reuse concept, which reduces the
number of users that need to be protected with differential privacy.
Furthermore, we address the related issue of limited availability of user
preference information, e.g., click data, in the settings of session-based and
cold-start recommendations. With respect to aspect (iii), we analyze popularity
bias in recommender systems. We find that the recommendation frequency of an
item is positively correlated with this item's popularity. This also leads to
the unfair treatment of users with little interest in popular content. Finally,
we study long-term fairness dynamics in algorithmic decision support in the
labor market using agent-based modeling techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Habilitation (post-doctoral thesis) at Graz University of Technology
  for the scientific subject "Applied Computer Science" (accepted in June 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with
  Flowcharts <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for visual question answering lack in visual grounding
and complexity, particularly in evaluating spatial reasoning skills. We
introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of
visual question-answering multimodal language models in reasoning with
flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and
human-verified flowchart images from three distinct content sources, along with
22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,
including information localization, decision-making, and logical progression.
We conduct a thorough baseline evaluation on a suite of both open-source and
proprietary multimodal language models using various strategies, followed by an
analysis of directional bias. The results underscore the benchmark's potential
as a vital tool for advancing the field of multimodal modeling, providing a
focused and challenging environment for enhancing model performance in visual
and logical reasoning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ACL 2024 (Findings), 21 pages, 7 figures, 9 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language
  Models for Adaptable Conversational Task Assistants <span class="chip">KDD</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07647v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07647v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sophie Fischer, Carlos Gemmell, Niklas Tecklenburg, Iain Mackie, Federico Rossetto, Jeffrey Dalton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We tackle the challenge of building real-world multimodal assistants for
complex real-world tasks. We describe the practicalities and challenges of
developing and deploying GRILLBot, a leading (first and second prize winning in
2022 and 2023) system deployed in the Alexa Prize TaskBot Challenge. Building
on our Open Assistant Toolkit (OAT) framework, we propose a hybrid architecture
that leverages Large Language Models (LLMs) and specialised models tuned for
specific subtasks requiring very low latency. OAT allows us to define when, how
and which LLMs should be used in a structured and deployable manner. For
knowledge-grounded question answering and live task adaptations, we show that
LLM reasoning abilities over task context and world knowledge outweigh latency
concerns. For dialogue state management, we implement a code generation
approach and show that specialised smaller models have 84% effectiveness with
100x lower latency. Overall, we provide insights and discuss tradeoffs for
deploying both traditional models and LLMs to users in complex real-world
multimodal environments in the Alexa TaskBot challenge. These experiences will
continue to evolve as LLMs become more capable and efficient -- fundamentally
reshaping OAT and future assistant architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, KDD Preprint</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">132</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLaRA: Supercharging Robot Learning Data for Vision-Language Policy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20095v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20095v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) equipped with extensive world knowledge and
strong reasoning skills can tackle diverse tasks across domains, often by
posing them as conversation-style instruction-response pairs. In this paper, we
propose LLaRA: Large Language and Robotics Assistant, a framework which
formulates robot action policy as conversations, and provides improved
responses when trained with auxiliary data that complements policy learning.
LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity
to process state information as visual-textual prompts and generate optimal
policy decisions in text. To train such action policy VLMs, we first introduce
an automated pipeline to generate diverse high-quality robotics instruction
data from existing behavior cloning data. A VLM finetuned with the resulting
collection of datasets based on a conversation-style formulation tailored for
robotics tasks, can generate meaningful robot action policy decisions. Our
experiments across multiple simulated and real-world environments demonstrate
the state-of-the-art performance of the proposed LLaRA framework. The code,
datasets, and pretrained models are available at
https://github.com/LostXine/LLaRA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Synthetic Data Creation with 1,000,000,000 Personas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20094v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20094v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel persona-driven data synthesis methodology that leverages
various perspectives within a large language model (LLM) to create diverse
synthetic data. To fully exploit this methodology at scale, we introduce
Persona Hub -- a collection of 1 billion diverse personas automatically curated
from web data. These 1 billion personas (~13% of the world's total population),
acting as distributed carriers of world knowledge, can tap into almost every
perspective encapsulated within the LLM, thereby facilitating the creation of
diverse synthetic data at scale for various scenarios. By showcasing Persona
Hub's use cases in synthesizing high-quality mathematical and logical reasoning
problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs
and tools (functions) at scale, we demonstrate persona-driven data synthesis is
versatile, scalable, flexible, and easy to use, potentially driving a paradigm
shift in synthetic data creation and applications in practice, which may have a
profound impact on LLM research and development.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProgressGym: Alignment with a Millennium of Moral Progress 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20087v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20087v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Qiu, Yang Zhang, Xuchuan Huang, Jasmine Xinze Li, Jiaming Ji, Yaodong Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Frontier AI systems, including large language models (LLMs), hold increasing
influence over the epistemology of human users. Such influence can reinforce
prevailing societal values, potentially contributing to the lock-in of
misguided moral beliefs and, consequently, the perpetuation of problematic
moral practices on a broad scale. We introduce progress alignment as a
technical solution to mitigate this imminent risk. Progress alignment
algorithms learn to emulate the mechanics of human moral progress, thereby
addressing the susceptibility of existing alignment methods to contemporary
moral blindspots. To empower research in progress alignment, we introduce
ProgressGym, an experimental framework allowing the learning of moral progress
mechanics from history, in order to facilitate future progress in real-world
moral decisions. Leveraging 9 centuries of historical text and 18 historical
LLMs, ProgressGym enables codification of real-world progress alignment
challenges into concrete benchmarks. Specifically, we introduce three core
challenges: tracking evolving values (PG-Follow), preemptively anticipating
moral progress (PG-Predict), and regulating the feedback loop between human and
AI value shifts (PG-Coevolve). Alignment methods without a temporal dimension
are inapplicable to these tasks. In response, we present lifelong and
extrapolative algorithms as baseline methods of progress alignment, and build
an open leaderboard soliciting novel algorithms and challenges. The framework
and the leaderboard are available at
https://github.com/PKU-Alignment/ProgressGym and
https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20086v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20086v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheridan Feucht, David Atkinson, Byron Wallace, David Bau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs process text as sequences of tokens that roughly correspond to words,
where less common words are represented by multiple tokens. However, individual
tokens are often semantically unrelated to the meanings of the words/concepts
they comprise. For example, Llama-2-7b's tokenizer splits the word
"northeastern" into the tokens ['_n', 'ort', 'he', 'astern'], none of which
correspond to semantically meaningful units like "north" or "east." Similarly,
the overall meanings of named entities like "Neil Young" and multi-word
expressions like "break a leg" cannot be directly inferred from their
constituent tokens. Mechanistically, how do LLMs convert such arbitrary groups
of tokens into useful higher-level representations? In this work, we find that
last token representations of named entities and multi-token words exhibit a
pronounced "erasure" effect, where information about previous and current
tokens is rapidly forgotten in early layers. Using this observation, we propose
a method to "read out" the implicit vocabulary of an autoregressive LLM by
examining differences in token representations across layers, and present
results of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is
the first attempt to probe the implicit vocabulary of an LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 14 figures. Code and data at
  https://footprints.baulab.info/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Segment Anything without Supervision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20081v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20081v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        XuDong Wang, Jingfeng Yang, Trevor Darrell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Segmentation Anything Model (SAM) requires labor-intensive data labeling.
We present Unsupervised SAM (UnSAM) for promptable and automatic whole-image
segmentation that does not require human annotations. UnSAM utilizes a
divide-and-conquer strategy to "discover" the hierarchical structure of visual
scenes. We first leverage top-down clustering methods to partition an unlabeled
image into instance/semantic level segments. For all pixels within a segment, a
bottom-up clustering method is employed to iteratively merge them into larger
groups, thereby forming a hierarchical structure. These unsupervised
multi-granular masks are then utilized to supervise model training. Evaluated
across seven popular datasets, UnSAM achieves competitive results with the
supervised counterpart SAM, and surpasses the previous state-of-the-art in
unsupervised segmentation by 11% in terms of AR. Moreover, we show that
supervised SAM can also benefit from our self-supervised labels. By integrating
our unsupervised pseudo masks into SA-1B's ground-truth masks and training
UnSAM with only 1% of SA-1B, a lightly semi-supervised UnSAM can often segment
entities overlooked by supervised SAM, exceeding SAM's AR by over 6.7% and AP
by 3.9% on SA-1B.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/frank-xwang/UnSAM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cost-aware Bayesian optimization via the Pandora's Box Gittins index 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20062v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20062v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qian Xie, Raul Astudillo, Peter Frazier, Ziv Scully, Alexander Terenin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian optimization is a technique for efficiently optimizing unknown
functions in a black-box manner. To handle practical settings where gathering
data requires use of finite resources, it is desirable to explicitly
incorporate function evaluation costs into Bayesian optimization policies. To
understand how to do so, we develop a previously-unexplored connection between
cost-aware Bayesian optimization and the Pandora's Box problem, a decision
problem from economics. The Pandora's Box problem admits a Bayesian-optimal
solution based on an expression called the Gittins index, which can be
reinterpreted as an acquisition function. We study the use of this acquisition
function for cost-aware Bayesian optimization, and demonstrate empirically that
it performs well, particularly in medium-high dimensions. We further show that
this performance carries over to classical Bayesian optimization without
explicit evaluation costs. Our work constitutes a first step towards
integrating techniques from Gittins index theory into Bayesian optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20055v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20055v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Sabour, Lily Goli, George Kopanas, Mark Matthews, Dmitry Lagun, Leonidas Guibas, Alec Jacobson, David J. Fleet, Andrea Tagliasacchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Gaussian Splatting (3DGS) is a promising technique for 3D reconstruction,
offering efficient training and rendering speeds, making it suitable for
real-time applications.However, current methods require highly controlled
environments (no moving people or wind-blown elements, and consistent lighting)
to meet the inter-view consistency assumption of 3DGS. This makes
reconstruction of real-world captures problematic. We present SpotlessSplats,
an approach that leverages pre-trained and general-purpose features coupled
with robust optimization to effectively ignore transient distractors. Our
method achieves state-of-the-art reconstruction quality both visually and
quantitatively, on casual captures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20053v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20053v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danny Halawi, Alexander Wei, Eric Wallace, Tony T. Wang, Nika Haghtalab, Jacob Steinhardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Black-box finetuning is an emerging interface for adapting state-of-the-art
language models to user needs. However, such access may also let malicious
actors undermine model safety. To demonstrate the challenge of defending
finetuning interfaces, we introduce covert malicious finetuning, a method to
compromise model safety via finetuning while evading detection. Our method
constructs a malicious dataset where every individual datapoint appears
innocuous, but finetuning on the dataset teaches the model to respond to
encoded harmful requests with encoded harmful responses. Applied to GPT-4, our
method produces a finetuned model that acts on harmful instructions 99% of the
time and avoids detection by defense mechanisms such as dataset inspection,
safety evaluations, and input/output classifiers. Our findings question whether
black-box finetuning access can be secured against sophisticated adversaries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of autonomous systems under data distribution shifts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20046v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20046v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Sikar, Artur Garcez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We posit that data can only be safe to use up to a certain threshold of the
data distribution shift, after which control must be relinquished by the
autonomous system and operation halted or handed to a human operator. With the
use of a computer vision toy example we demonstrate that network predictive
accuracy is impacted by data distribution shifts and propose distance metrics
between training and testing data to define safe operation limits within said
shifts. We conclude that beyond an empirically obtained threshold of the data
distribution shift, it is unreasonable to expect network predictive accuracy
not to degrade
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 10 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explore as a Storm, Exploit as a Raindrop: On the Benefit of Fine-Tuning
  Kernel Schedulers with Coordinate Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Canesche, Gaurav Verma, Fernando Magno Quintao Pereira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine-learning models consist of kernels, which are algorithms applying
operations on tensors -- data indexed by a linear combination of natural
numbers. Examples of kernels include convolutions, transpositions, and
vectorial products. There are many ways to implement a kernel. These
implementations form the kernel's optimization space. Kernel scheduling is the
problem of finding the best implementation, given an objective function --
typically execution speed. Kernel optimizers such as Ansor, Halide, and AutoTVM
solve this problem via search heuristics, which combine two phases: exploration
and exploitation. The first step evaluates many different kernel optimization
spaces. The latter tries to improve the best implementations by investigating a
kernel within the same space. For example, Ansor combines kernel generation
through sketches for exploration and leverages an evolutionary algorithm to
exploit the best sketches. In this work, we demonstrate the potential to reduce
Ansor's search time while enhancing kernel quality by incorporating Droplet
Search, an AutoTVM algorithm, into Ansor's exploration phase. The approach
involves limiting the number of samples explored by Ansor, selecting the best,
and exploiting it with a coordinate descent algorithm. By applying this
approach to the first 300 kernels that Ansor generates, we usually obtain
better kernels in less time than if we let Ansor analyze 10,000 kernels. This
result has been replicated in 20 well-known deep-learning models (AlexNet,
ResNet, VGG, DenseNet, etc.) running on four architectures: an AMD Ryzen 7
(x86), an NVIDIA A100 tensor core, an NVIDIA RTX 3080 GPU, and an ARM A64FX. A
patch with this combined approach was approved in Ansor in February 2024. As
evidence of the generality of this search methodology, a similar patch,
achieving equally good results, was submitted to TVM's MetaSchedule in June
2024.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 19 figures, original work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pairwise Difference Learning for Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20031v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20031v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Karim Belaid, Maximilian Rabus, Eyke Hüllermeier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pairwise difference learning (PDL) has recently been introduced as a new
meta-learning technique for regression. Instead of learning a mapping from
instances to outcomes in the standard way, the key idea is to learn a function
that takes two instances as input and predicts the difference between the
respective outcomes. Given a function of this kind, predictions for a query
instance are derived from every training example and then averaged. This paper
extends PDL toward the task of classification and proposes a meta-learning
technique for inducing a PDL classifier by solving a suitably defined (binary)
classification problem on a paired version of the original training data. We
analyze the performance of the PDL classifier in a large-scale empirical study
and find that it outperforms state-of-the-art methods in terms of prediction
performance. Last but not least, we provide an easy-to-use and publicly
available implementation of PDL in a Python package.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Trade-off between Flatness and Optimization in Distributed
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20006v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20006v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ying Cao, Zhaoxian Wu, Kun Yuan, Ali H. Sayed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a theoretical framework to evaluate and compare the
performance of gradient-descent algorithms for distributed learning in relation
to their behavior around local minima in nonconvex environments. Previous works
have noticed that convergence toward flat local minima tend to enhance the
generalization ability of learning algorithms. This work discovers two
interesting results. First, it shows that decentralized learning strategies are
able to escape faster away from local minimizers and favor convergence toward
flatter minima relative to the centralized solution in the large-batch training
regime. Second, and importantly, the ultimate classification accuracy is not
solely dependent on the flatness of the local minimizer but also on how well a
learning algorithm can approach that minimum. In other words, the
classification accuracy is a function of both flatness and optimization
performance. The paper examines the interplay between the two measures of
flatness and optimization error closely. One important conclusion is that
decentralized strategies of the diffusion type deliver enhanced classification
accuracy because it strikes a more favorable balance between flatness and
optimization performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wavelets Are All You Need for Autoregressive Image Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wael Mattar, Idan Levy, Nir Sharon, Shai Dekel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we take a new approach to autoregressive image generation that
is based on two main ingredients. The first is wavelet image coding, which
allows to tokenize the visual details of an image from coarse to fine details
by ordering the information starting with the most significant bits of the most
significant wavelet coefficients. The second is a variant of a language
transformer whose architecture is re-designed and optimized for token sequences
in this 'wavelet language'. The transformer learns the significant statistical
correlations within a token sequence, which are the manifestations of
well-known correlations between the wavelet subbands at various resolutions. We
show experimental results with conditioning on the generation process.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Single Parent Family: A Spectrum of Family Members from a Single
  <span class="highlight-title">Pre-Train</span>ed Foundation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19995v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19995v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Habib Hajimolahoseini, Mohammad Hassanpour, Foozhan Ataiefard, Boxing Chen, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel method of Progressive Low Rank Decomposition
(PLRD) tailored for the compression of large language models. Our approach
leverages a pre-trained model, which is then incrementally decompressed to
smaller sizes using progressively lower ranks. This method allows for
significant reductions in computational overhead and energy consumption, as
subsequent models are derived from the original without the need for retraining
from scratch. We detail the implementation of PLRD, which strategically
decreases the tensor ranks, thus optimizing the trade-off between model
performance and resource usage. The efficacy of PLRD is demonstrated through
extensive experiments showing that models trained with PLRD method on only 1B
tokens maintain comparable performance with traditionally trained models while
using 0.1% of the tokens. The versatility of PLRD is highlighted by its ability
to generate multiple model sizes from a single foundational model, adapting
fluidly to varying computational and memory budgets. Our findings suggest that
PLRD could set a new standard for the efficient scaling of LLMs, making
advanced AI more feasible on diverse platforms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Machine Learning Predictors for Min-Entropy Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19983v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19983v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Javier Blanco-Romero, Vicente Lorenzo, Florina Almenares Mendoza, Daniel Díaz-Sánchez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study investigates the application of machine learning predictors for
min-entropy estimation in Random Number Generators (RNGs), a key component in
cryptographic applications where accurate entropy assessment is essential for
cybersecurity. Our research indicates that these predictors, and indeed any
predictor that leverages sequence correlations, primarily estimate average
min-entropy, a metric not extensively studied in this context. We explore the
relationship between average min-entropy and the traditional min-entropy,
focusing on their dependence on the number of target bits being predicted.
Utilizing data from Generalized Binary Autoregressive Models, a subset of
Markov processes, we demonstrate that machine learning models (including a
hybrid of convolutional and recurrent Long Short-Term Memory layers and the
transformer-based GPT-2 model) outperform traditional NIST SP 800-90B
predictors in certain scenarios. Our findings underscore the importance of
considering the number of target bits in min-entropy assessment for RNGs and
highlight the potential of machine learning approaches in enhancing entropy
estimation techniques for improved cryptographic security.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparative Analysis of LSTM Neural Networks and Traditional Machine
  Learning Models for Predicting Diabetes Patient Readmission 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19980v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19980v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abolfazl Zarghani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diabetes mellitus is a chronic metabolic disorder that has emerged as one of
the major health problems worldwide due to its high prevalence and serious
complications, which are pricey to manage. Effective management requires good
glycemic control and regular follow-up in the clinic; however, non-adherence to
scheduled follow-ups is very common. This study uses the Diabetes 130-US
Hospitals dataset for analysis and prediction of readmission patients by
various traditional machine learning models, such as XGBoost, LightGBM,
CatBoost, Decision Tree, and Random Forest, and also uses an in-house LSTM
neural network for comparison. The quality of the data was assured by
preprocessing it, and the performance evaluation for all these models was based
on accuracy, precision, recall, and F1-score. LightGBM turned out to be the
best traditional model, while XGBoost was the runner-up. The LSTM model
suffered from overfitting despite high training accuracy. A major strength of
LSTM is capturing temporal dependencies among the patient data. Further, SHAP
values were used, which improved model interpretability, whereby key factors
among them number of lab procedures and discharge disposition were identified
as critical in the prediction of readmissions. This study demonstrates that
model selection, validation, and interpretability are key steps in predictive
healthcare modeling. This will help health providers design interventions for
improved follow-up adherence and better management of diabetes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19976v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19976v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Pan, Jipeng Zhang, Xingyuan Pan, Renjie Pi, Xiaoyu Wang, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bilevel optimization has shown its utility across various machine learning
settings, yet most algorithms in practice require second-order information,
making it challenging to scale them up. Only recently, a paradigm of
first-order algorithms emerged, capable of effectively addressing bilevel
optimization problems. Nevertheless, the practical efficiency of this paradigm
remains unverified, particularly in the context of large language models
(LLMs). This paper introduces the first scalable instantiation of this paradigm
called ScaleBiO, focusing on bilevel optimization for large-scale LLM data
reweighting. By combining with a recently proposed memory-efficient training
technique called LISA, our novel algorithm allows the paradigm to scale to
34-billion-parameter LLMs on eight A40 GPUs, marking the first successful
application of bilevel optimization under practical scenarios for large-sized
LLMs. Empirically, extensive experiments on data reweighting verify the
effectiveness of ScaleBiO for different-scaled models, including GPT-2,
LLaMA-3-8B, GPT-NeoX-20B, and Yi-34B, where bilevel optimization succeeds in
filtering irrelevant data samples and selecting informative samples.
Theoretically, ScaleBiO ensures the optimality of the learned data weights,
along with a convergence guarantee matching the conventional first-order
bilevel optimization paradigm on smooth and strongly convex objectives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STLLaVA-Med: Self-Training Large Language and Vision Assistant for
  Medical 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19973v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19973v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guohao Sun, Can Qin, Huazhu Fu, Linwei Wang, Zhiqiang Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) have shown significant potential in
assisting medical diagnosis by leveraging extensive biomedical datasets.
However, the advancement of medical image understanding and reasoning
critically depends on building high-quality visual instruction data, which is
costly and labor-intensive to obtain, particularly in the medical domain. To
mitigate this data-starving issue, we introduce Self-Training Large Language
and Vision Assistant for Medical (STLLaVA-Med). The proposed method is designed
to train a policy model (an LVLM) capable of auto-generating medical visual
instruction data to improve data efficiency, guided through Direct Preference
Optimization (DPO). Specifically, a more powerful and larger LVLM (e.g.,
GPT-4o) is involved as a biomedical expert to oversee the DPO fine-tuning
process on the auto-generated data, encouraging the policy model to align
efficiently with human preferences. We validate the efficacy and data
efficiency of STLLaVA-Med across three major medical Visual Question Answering
(VQA) benchmarks, demonstrating competitive zero-shot performance with the
utilization of only 9% of the medical data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Text2Robot: Evolutionary Robot Design from Text Descriptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19963v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19963v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan P. Ringel, Zachary S. Charlick, Jiaxun Liu, Boxi Xia, Boyuan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robot design has traditionally been costly and labor-intensive. Despite
advancements in automated processes, it remains challenging to navigate a vast
design space while producing physically manufacturable robots. We introduce
Text2Robot, a framework that converts user text specifications and performance
preferences into physical quadrupedal robots. Within minutes, Text2Robot can
use text-to-3D models to provide strong initializations of diverse
morphologies. Within a day, our geometric processing algorithms and
body-control co-optimization produce a walking robot by explicitly considering
real-world electronics and manufacturability. Text2Robot enables rapid
prototyping and opens new opportunities for robot design with generative
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our project website is at: https://generalroboticslab.com/Text2Robot</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Computational Curse of Big Data for Bayesian Additive Regression
  Trees: A Hitting Time Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19958v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19958v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Shuo Tan, Omer Ronen, Theo Saarinen, Bin Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian Additive Regression Trees (BART) is a popular Bayesian
non-parametric regression model that is commonly used in causal inference and
beyond. Its strong predictive performance is supported by theoretical
guarantees that its posterior distribution concentrates around the true
regression function at optimal rates under various data generative settings and
for appropriate prior choices. In this paper, we show that the BART sampler
often converges slowly, confirming empirical observations by other researchers.
Assuming discrete covariates, we show that, while the BART posterior
concentrates on a set comprising all optimal tree structures (smallest bias and
complexity), the Markov chain's hitting time for this set increases with $n$
(training sample size), under several common data generative settings. As $n$
increases, the approximate BART posterior thus becomes increasingly different
from the exact posterior (for the same number of MCMC samples), contrasting
with earlier concentration results on the exact posterior. This contrast is
highlighted by our simulations showing worsening frequentist undercoverage for
approximate posterior intervals and a growing ratio between the MSE of the
approximate posterior and that obtainable by artificially improving convergence
via averaging multiple sampler chains. Finally, based on our theoretical
insights, possibilities are discussed to improve the BART sampler convergence
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kolmogorov-Smirnov GAN 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19948v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19948v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maciej Falkiewicz, Naoya Takeishi, Alexandros Kalousis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel deep generative model, the Kolmogorov-Smirnov Generative
Adversarial Network (KSGAN). Unlike existing approaches, KSGAN formulates the
learning process as a minimization of the Kolmogorov-Smirnov (KS) distance,
generalized to handle multivariate distributions. This distance is calculated
using the quantile function, which acts as the critic in the adversarial
training process. We formally demonstrate that minimizing the KS distance leads
to the trained approximate distribution aligning with the target distribution.
We propose an efficient implementation and evaluate its effectiveness through
experiments. The results show that KSGAN performs on par with existing
adversarial methods, exhibiting stability during training, resistance to mode
dropping and collapse, and tolerance to variations in hyperparameter settings.
Additionally, we review the literature on the Generalized KS test and discuss
the connections between KSGAN and existing adversarial generative models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code available at https://github.com/DMML-Geneva/ksgan</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decoupling General and Personalized Knowledge in Federated Learning via
  Additive and Low-Rank Decomposition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19931v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19931v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinghao Wu, Xuefeng Liu, Jianwei Niu, Haolin Wang, Shaojie Tang, Guogang Zhu, Hao Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To address data heterogeneity, the key strategy of Personalized Federated
Learning (PFL) is to decouple general knowledge (shared among clients) and
client-specific knowledge, as the latter can have a negative impact on
collaboration if not removed. Existing PFL methods primarily adopt a parameter
partitioning approach, where the parameters of a model are designated as one of
two types: parameters shared with other clients to extract general knowledge
and parameters retained locally to learn client-specific knowledge. However, as
these two types of parameters are put together like a jigsaw puzzle into a
single model during the training process, each parameter may simultaneously
absorb both general and client-specific knowledge, thus struggling to separate
the two types of knowledge effectively. In this paper, we introduce FedDecomp,
a simple but effective PFL paradigm that employs parameter additive
decomposition to address this issue. Instead of assigning each parameter of a
model as either a shared or personalized one, FedDecomp decomposes each
parameter into the sum of two parameters: a shared one and a personalized one,
thus achieving a more thorough decoupling of shared and personalized knowledge
compared to the parameter partitioning method. In addition, as we find that
retaining local knowledge of specific clients requires much lower model
capacity compared with general knowledge across all clients, we let the matrix
containing personalized parameters be low rank during the training process.
Moreover, a new alternating training strategy is proposed to further improve
the performance. Experimental results across multiple datasets and varying
degrees of data heterogeneity demonstrate that FedDecomp outperforms
state-of-the-art methods up to 4.9\%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ `Just One More Sensor is Enough' -- Iterative Water Leak Localization
  with Physical Simulation and a Small Number of Pressure Sensors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19900v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19900v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michał Cholewa, Michał Romaszewski, Przemysław Głomb, Katarzyna Kołodziej, Michał Gorawski, Jakub Koral, Wojciech Koral, Andrzej Madej, Kryspin Musioł
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this article, we propose an approach to leak localisation in a complex
water delivery grid with the use of data from physical simulation (e.g. EPANET
software). This task is usually achieved by a network of multiple water
pressure sensors and analysis of the so-called sensitivity matrix of pressure
differences between the network's simulated data and actual data of the network
affected by the leak. However, most algorithms using this approach require a
significant number of pressure sensors -- a condition that is not easy to
fulfil in the case of many less equipped networks. Therefore, we answer the
question of whether leak localisation is possible by utilising very few sensors
but having the ability to relocate one of them. Our algorithm is based on
physical simulations (EPANET software) and an iterative scheme for mobile
sensor relocation. The experiments show that the proposed system can equalise
the low number of sensors with adjustments made for their positioning, giving a
very good approximation of leak's position both in simulated cases and
real-life example taken from BattLeDIM competition L-Town data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FI-CBL: A Probabilistic Method for Concept-Based Learning with Expert
  Rules 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19897v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19897v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lev V. Utkin, Andrei V. Konstantinov, Stanislav R. Kirpichenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A method for solving concept-based learning (CBL) problem is proposed. The
main idea behind the method is to divide each concept-annotated image into
patches, to transform the patches into embeddings by using an autoencoder, and
to cluster the embeddings assuming that each cluster will mainly contain
embeddings of patches with certain concepts. To find concepts of a new image,
the method implements the frequentist inference by computing prior and
posterior probabilities of concepts based on rates of patches from images with
certain values of the concepts. Therefore, the proposed method is called the
Frequentist Inference CBL (FI-CBL). FI-CBL allows us to incorporate the expert
rules in the form of logic functions into the inference procedure. An idea
behind the incorporation is to update prior and conditional probabilities of
concepts to satisfy the rules. The method is transparent because it has an
explicit sequence of probabilistic calculations and a clear frequency
interpretation. Numerical experiments show that FI-CBL outperforms the concept
bottleneck model in cases when the number of training data is small. The code
of proposed algorithms is publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention Meets UAVs: A Comprehensive Evaluation of DDoS Detection in
  Low-Cost UAVs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19881v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19881v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashish Sharma, SVSLN Surya Suhas Vaddhiparthy, Sai Usha Goparaju, Deepak Gangadharan, Harikumar Kandath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the critical issue of enhancing cybersecurity measures
for low-cost, Wi-Fi-based Unmanned Aerial Vehicles (UAVs) against Distributed
Denial of Service (DDoS) attacks. In the current work, we have explored three
variants of DDoS attacks, namely Transmission Control Protocol (TCP), Internet
Control Message Protocol (ICMP), and TCP + ICMP flooding attacks, and developed
a detection mechanism that runs on the companion computer of the UAV system. As
a part of the detection mechanism, we have evaluated various machine learning,
and deep learning algorithms, such as XGBoost, Isolation Forest, Long
Short-Term Memory (LSTM), Bidirectional-LSTM (Bi-LSTM), LSTM with attention,
Bi-LSTM with attention, and Time Series Transformer (TST) in terms of various
classification metrics. Our evaluation reveals that algorithms with attention
mechanisms outperform their counterparts in general, and TST stands out as the
most efficient model with a run time of 0.1 seconds. TST has demonstrated an F1
score of 0.999, 0.997, and 0.943 for TCP, ICMP, and TCP + ICMP flooding attacks
respectively. In this work, we present the necessary steps required to build an
on-board DDoS detection mechanism. Further, we also present the ablation study
to identify the best TST hyperparameters for DDoS detection, and we have also
underscored the advantage of adapting learnable positional embeddings in TST
for DDoS detection with an improvement in F1 score from 0.94 to 0.99.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Koopman based trajectory model and computation offloading for high
  mobility paradigm in ISAC enabled IoT system 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19871v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19871v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minh-Tuan Tran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User experience on mobile devices is constrained by limited battery capacity
and processing power, but 6G technology advancements are diving rapidly into
mobile technical evolution. Mobile edge computing (MEC) offers a solution,
offloading computationally intensive tasks to edge cloud servers, reducing
battery drain compared to local processing. The upcoming integrated sensing and
communication in mobile communication may improve the trajectory prediction and
processing delays. This study proposes a greedy resource allocation
optimization strategy for multi-user networks to minimize aggregate energy
usage. Numerical results show potential improvement at 33\% for every 1000
iteration. Addressing prediction model division and velocity accuracy issues is
crucial for better results. A plan for further improvement and achieving
objectives is outlined for the upcoming work phase.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Operator World Models for Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19861v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19861v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pietro Novelli, Marco Pratticò, Massimiliano Pontil, Carlo Ciliberto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Policy Mirror Descent (PMD) is a powerful and theoretically sound methodology
for sequential decision-making. However, it is not directly applicable to
Reinforcement Learning (RL) due to the inaccessibility of explicit action-value
functions. We address this challenge by introducing a novel approach based on
learning a world model of the environment using conditional mean embeddings. We
then leverage the operatorial formulation of RL to express the action-value
function in terms of this quantity in closed form via matrix operations.
Combining these estimators with PMD leads to POWR, a new RL algorithm for which
we prove convergence rates to the global optimum. Preliminary experiments in
finite and infinite state settings support the effectiveness of our method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MuGSI: Distilling GNNs with Multi-Granularity Structural Information for
  Graph Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19832v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19832v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianjun Yao, Jiaqi Sun, Defu Cao, Kun Zhang, Guangyi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent works have introduced GNN-to-MLP knowledge distillation (KD)
frameworks to combine both GNN's superior performance and MLP's fast inference
speed. However, existing KD frameworks are primarily designed for node
classification within single graphs, leaving their applicability to graph
classification largely unexplored. Two main challenges arise when extending KD
for node classification to graph classification: (1) The inherent sparsity of
learning signals due to soft labels being generated at the graph level; (2) The
limited expressiveness of student MLPs, especially in datasets with limited
input feature spaces. To overcome these challenges, we introduce MuGSI, a novel
KD framework that employs Multi-granularity Structural Information for graph
classification. Specifically, we propose multi-granularity distillation loss in
MuGSI to tackle the first challenge. This loss function is composed of three
distinct components: graph-level distillation, subgraph-level distillation, and
node-level distillation. Each component targets a specific granularity of the
graph structure, ensuring a comprehensive transfer of structural knowledge from
the teacher model to the student model. To tackle the second challenge, MuGSI
proposes to incorporate a node feature augmentation component, thereby
enhancing the expressiveness of the student MLPs and making them more capable
learners. We perform extensive experiments across a variety of datasets and
different teacher/student model architectures. The experiment results
demonstrate the effectiveness, efficiency, and robustness of MuGSI. Codes are
publicly available at: \textbf{\url{https://github.com/tianyao-aka/MuGSI}.}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures. Accepted by TheWebConf2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Stable and Storage-efficient <span class="highlight-title">Dataset</span> Distillation: Matching
  Convexified Trajectory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19827v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19827v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenliang Zhong, Haoyu Tang, Qinghai Zheng, Mingzhu Xu, Yupeng Hu, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid evolution of deep learning and large language models has led to an
exponential growth in the demand for training data, prompting the development
of Dataset Distillation methods to address the challenges of managing large
datasets. Among these, Matching Training Trajectories (MTT) has been a
prominent approach, which replicates the training trajectory of an expert
network on real data with a synthetic dataset. However, our investigation found
that this method suffers from three significant limitations: 1. Instability of
expert trajectory generated by Stochastic Gradient Descent (SGD); 2. Low
convergence speed of the distillation process; 3. High storage consumption of
the expert trajectory. To address these issues, we offer a new perspective on
understanding the essence of Dataset Distillation and MTT through a simple
transformation of the objective function, and introduce a novel method called
Matching Convexified Trajectory (MCT), which aims to provide better guidance
for the student trajectory. MCT leverages insights from the linearized dynamics
of Neural Tangent Kernel methods to create a convex combination of expert
trajectories, guiding the student network to converge rapidly and stably. This
trajectory is not only easier to store, but also enables a continuous sampling
strategy during distillation, ensuring thorough learning and fitting of the
entire expert trajectory. Comprehensive experiments across three public
datasets validate the superiority of MCT over traditional MTT methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reinforcement Learning for Efficient Design and Control Co-optimisation
  of Energy Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marine Cauz, Adrien Bolland, Nicolas Wyrsch, Christophe Ballif
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ongoing energy transition drives the development of decentralised
renewable energy sources, which are heterogeneous and weather-dependent,
complicating their integration into energy systems. This study tackles this
issue by introducing a novel reinforcement learning (RL) framework tailored for
the co-optimisation of design and control in energy systems. Traditionally, the
integration of renewable sources in the energy sector has relied on complex
mathematical modelling and sequential processes. By leveraging RL's model-free
capabilities, the framework eliminates the need for explicit system modelling.
By optimising both control and design policies jointly, the framework enhances
the integration of renewable sources and improves system efficiency. This
contribution paves the way for advanced RL applications in energy management,
leading to more efficient and effective use of renewable energy sources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deceptive Diffusion: Generating Synthetic Adversarial Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19807v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19807v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Beerens, Catherine F. Higham, Desmond J. Higham
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the concept of deceptive diffusion -- training a generative AI
model to produce adversarial images. Whereas a traditional adversarial attack
algorithm aims to perturb an existing image to induce a misclassificaton, the
deceptive diffusion model can create an arbitrary number of new, misclassified
images that are not directly associated with training or test images. Deceptive
diffusion offers the possibility of strengthening defence algorithms by
providing adversarial training data at scale, including types of
misclassification that are otherwise difficult to find. In our experiments, we
also investigate the effect of training on a partially attacked data set. This
highlights a new type of vulnerability for generative diffusion models: if an
attacker is able to stealthily poison a portion of the training data, then the
resulting diffusion model will generate a similar proportion of misleading
outputs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MulTi-Wise Sampling: Trading Uniform T-Wise Feature Interaction Coverage
  for Smaller Samples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19801v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19801v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Pett, Sebastian Krieter, Thomas Thüm, Ina Schaefer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the functional safety of highly configurable systems often requires
testing representative subsets of all possible configurations to reduce testing
effort and save resources. The ratio of covered t-wise feature interactions
(i.e., T-Wise Feature Interaction Coverage) is a common criterion for
determining whether a subset of configurations is representative and capable of
finding faults. Existing t-wise sampling algorithms uniformly cover t-wise
feature interactions for all features, resulting in lengthy execution times and
large sample sizes, particularly when large t-wise feature interactions are
considered (i.e., high values of t). In this paper, we introduce a novel
approach to t-wise feature interaction sampling, questioning the necessity of
uniform coverage across all t-wise feature interactions, called
\emph{\mulTiWise{}}. Our approach prioritizes between subsets of critical and
non-critical features, considering higher t-values for subsets of critical
features when generating a t-wise feature interaction sample. We evaluate our
approach using subject systems from real-world applications, including
\busybox{}, \soletta{}, \fiasco{}, and \uclibc{}. Our results show that
sacrificing uniform t-wise feature interaction coverage between all features
reduces the time needed to generate a sample and the resulting sample size.
Hence, \mulTiWise{} Sampling offers an alternative to existing approaches if
knowledge about feature criticality is available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling the Real World with High-Density Visual Particle Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19800v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19800v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William F. Whitney, Jacob Varley, Deepali Jain, Krzysztof Choromanski, Sumeet Singh, Vikas Sindhwani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present High-Density Visual Particle Dynamics (HD-VPD), a learned world
model that can emulate the physical dynamics of real scenes by processing
massive latent point clouds containing 100K+ particles. To enable efficiency at
this scale, we introduce a novel family of Point Cloud Transformers (PCTs)
called Interlacers leveraging intertwined linear-attention Performer layers and
graph-based neighbour attention layers. We demonstrate the capabilities of
HD-VPD by modeling the dynamics of high degree-of-freedom bi-manual robots with
two RGB-D cameras. Compared to the previous graph neural network approach, our
Interlacer dynamics is twice as fast with the same prediction quality, and can
achieve higher quality using 4x as many particles. We illustrate how HD-VPD can
evaluate motion plan quality with robotic box pushing and can grasping tasks.
See videos and particle dynamics rendered by HD-VPD at
https://sites.google.com/view/hd-vpd.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Performance Prediction of Electrolyte Formulations with
  <span class="highlight-title">Transformer</span>-based Molecular Representation Model <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19792v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19792v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Indra Priyadarsini, Vidushi Sharma, Seiji Takeda, Akihiro Kishimoto, Lisa Hamada, Hajime Shinohara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Development of efficient and high-performing electrolytes is crucial for
advancing energy storage technologies, particularly in batteries. Predicting
the performance of battery electrolytes rely on complex interactions between
the individual constituents. Consequently, a strategy that adeptly captures
these relationships and forms a robust representation of the formulation is
essential for integrating with machine learning models to predict properties
accurately. In this paper, we introduce a novel approach leveraging a
transformer-based molecular representation model to effectively and efficiently
capture the representation of electrolyte formulations. The performance of the
proposed approach is evaluated on two battery property prediction tasks and the
results show superior performance compared to the state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ML4LMS Workshop at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Self-Supervised</span> Spatial-Temporal Normality Learning for Time Series
  Anomaly Detection <span class="chip">ECML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19770v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19770v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutong Chen, Hongzuo Xu, Guansong Pang, Hezhe Qiao, Yuan Zhou, Mingsheng Shang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time Series Anomaly Detection (TSAD) finds widespread applications across
various domains such as financial markets, industrial production, and
healthcare. Its primary objective is to learn the normal patterns of time
series data, thereby identifying deviations in test samples. Most existing TSAD
methods focus on modeling data from the temporal dimension, while ignoring the
semantic information in the spatial dimension. To address this issue, we
introduce a novel approach, called Spatial-Temporal Normality learning (STEN).
STEN is composed of a sequence Order prediction-based Temporal Normality
learning (OTN) module that captures the temporal correlations within sequences,
and a Distance prediction-based Spatial Normality learning (DSN) module that
learns the relative spatial relations between sequences in a feature space. By
synthesizing these two modules, STEN learns expressive spatial-temporal
representations for the normal patterns hidden in the time series data.
Extensive experiments on five popular TSAD benchmarks show that STEN
substantially outperforms state-of-the-art competing methods. Our code is
available at https://github.com/mala-lab/STEN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 4 figures, accepted in ECML PKDD2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contextualized Hybrid Ensemble Q-learning: Learning Fast with Control
  Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19768v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19768v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emma Cramer, Bernd Frauenknecht, Ramil Sabirov, Sebastian Trimpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Combining Reinforcement Learning (RL) with a prior controller can yield the
best out of two worlds: RL can solve complex nonlinear problems, while the
control prior ensures safer exploration and speeds up training. Prior work
largely blends both components with a fixed weight, neglecting that the RL
agent's performance varies with the training progress and across regions in the
state space. Therefore, we advocate for an adaptive strategy that dynamically
adjusts the weighting based on the RL agent's current capabilities. We propose
a new adaptive hybrid RL algorithm, Contextualized Hybrid Ensemble Q-learning
(CHEQ). CHEQ combines three key ingredients: (i) a time-invariant formulation
of the adaptive hybrid RL problem treating the adaptive weight as a context
variable, (ii) a weight adaption mechanism based on the parametric uncertainty
of a critic ensemble, and (iii) ensemble-based acceleration for data-efficient
RL. Evaluating CHEQ on a car racing task reveals substantially stronger data
efficiency, exploration safety, and transferability to unknown scenarios than
state-of-the-art adaptive hybrid RL methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Systematic Literature <span class="highlight-title">Review</span> on Application of Learning-based Approaches
  in Continuous Integration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19765v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19765v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Kazemi Arani, Triet Huynh Minh Le, Mansooreh Zahedi, M. Ali Babar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Context: Machine learning (ML) and deep learning (DL) analyze raw data to
extract valuable insights in specific phases. The rise of continuous practices
in software projects emphasizes automating Continuous Integration (CI) with
these learning-based methods, while the growing adoption of such approaches
underscores the need for systematizing knowledge. Objective: Our objective is
to comprehensively review and analyze existing literature concerning
learning-based methods within the CI domain. We endeavour to identify and
analyse various techniques documented in the literature, emphasizing the
fundamental attributes of training phases within learning-based solutions in
the context of CI. Method: We conducted a Systematic Literature Review (SLR)
involving 52 primary studies. Through statistical and thematic analyses, we
explored the correlations between CI tasks and the training phases of
learning-based methodologies across the selected studies, encompassing a
spectrum from data engineering techniques to evaluation metrics. Results: This
paper presents an analysis of the automation of CI tasks utilizing
learning-based methods. We identify and analyze nine types of data sources,
four steps in data preparation, four feature types, nine subsets of data
features, five approaches for hyperparameter selection and tuning, and fifteen
evaluation metrics. Furthermore, we discuss the latest techniques employed,
existing gaps in CI task automation, and the characteristics of the utilized
learning-based techniques. Conclusion: This study provides a comprehensive
overview of learning-based methods in CI, offering valuable insights for
researchers and practitioners developing CI task automation. It also highlights
the need for further research to advance these methods in CI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted to be published in IEEE Access</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Backdoor Attack in <span class="highlight-title">Prompt</span>-Based Continual Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19753v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19753v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trang Nguyen, Anh Tran, Nhat Ho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt-based approaches offer a cutting-edge solution to data privacy issues
in continual learning, particularly in scenarios involving multiple data
suppliers where long-term storage of private user data is prohibited. Despite
delivering state-of-the-art performance, its impressive remembering capability
can become a double-edged sword, raising security concerns as it might
inadvertently retain poisoned knowledge injected during learning from private
user data. Following this insight, in this paper, we expose continual learning
to a potential threat: backdoor attack, which drives the model to follow a
desired adversarial target whenever a specific trigger is present while still
performing normally on clean samples. We highlight three critical challenges in
executing backdoor attacks on incremental learners and propose corresponding
solutions: (1) \emph{Transferability}: We employ a surrogate dataset and
manipulate prompt selection to transfer backdoor knowledge to data from other
suppliers; (2) \emph{Resiliency}: We simulate static and dynamic states of the
victim to ensure the backdoor trigger remains robust during intense incremental
learning processes; and (3) \emph{Authenticity}: We apply binary cross-entropy
loss as an anti-cheating factor to prevent the backdoor trigger from devolving
into adversarial noise. Extensive experiments across various benchmark datasets
and continual learners validate our continual backdoor framework, achieving up
to $100\%$ attack success rate, with further ablation studies confirming our
contributions' effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Classical Bandit Algorithms for Entanglement Detection in Parameterized
  Qubit States 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19738v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19738v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bharati. K, Vikesh Siddhu, Krishna Jagannathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entanglement is a key resource for a wide range of tasks in quantum
information and computing. Thus, verifying availability of this quantum
resource is essential. Extensive research on entanglement detection has led to
no-go theorems (Lu et al. [Phys. Rev. Lett., 116, 230501 (2016)]) that
highlight the need for full state tomography (FST) in the absence of adaptive
or joint measurements. Recent advancements, as proposed by Zhu, Teo, and
Englert [Phys. Rev. A, 81, 052339, 2010], introduce a single-parameter family
of entanglement witness measurements which are capable of conclusively
detecting certain entangled states and only resort to FST when all witness
measurements are inconclusive. We find a variety of realistic noisy two-qubit
quantum states $\mathcal{F}$ that yield conclusive results under this witness
family. We solve the problem of detecting entanglement among $K$ quantum states
in $\mathcal{F}$, of which $m$ states are entangled, with $m$ potentially
unknown. We recognize a structural connection of this problem to the Bad Arm
Identification problem in stochastic Multi-Armed Bandits (MAB). In contrast to
existing quantum bandit frameworks, we establish a new correspondence tailored
for entanglement detection and term it the $(m,K)$-quantum Multi-Armed Bandit.
We implement two well-known MAB policies for arbitrary states derived from
$\mathcal{F}$, present theoretical guarantees on the measurement/sample
complexity and demonstrate the practicality of the policies through numerical
simulations. More broadly, this paper highlights the potential for employing
classical machine learning techniques for quantum entanglement detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MM-Instruct: Generated Visual Instructions for Large Multimodal Model
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihao Liu, Xin Huang, Jinliang Zheng, Boxiao Liu, Jia Wang, Osamu Yoshie, Yu Liu, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces MM-Instruct, a large-scale dataset of diverse and
high-quality visual instruction data designed to enhance the
instruction-following capabilities of large multimodal models (LMMs). While
existing visual instruction datasets often focus on question-answering, they
struggle to generalize to broader application scenarios such as creative
writing, summarization, or image analysis. To address these limitations, we
propose a novel approach to constructing MM-Instruct that leverages the strong
instruction-following capabilities of existing LLMs to generate novel visual
instruction data from large-scale but conventional image captioning datasets.
MM-Instruct first leverages ChatGPT to automatically generate diverse
instructions from a small set of seed instructions through augmenting and
summarization. It then matches these instructions with images and uses an
open-sourced large language model (LLM) to generate coherent answers to the
instruction-image pairs. The LLM is grounded by the detailed text descriptions
of images in the whole answer generation process to guarantee the alignment of
the instruction data. Moreover, we introduce a benchmark based on the generated
instruction data to evaluate the instruction-following capabilities of existing
LMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5
model on the generated data, denoted as LLaVA-Instruct, which exhibits
significant improvements in instruction-following capabilities compared to
LLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models
are available at https://github.com/jihaonew/MM-Instruct.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset and models are available at
  https://github.com/jihaonew/MM-Instruct</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EPOCH: Jointly Estimating the 3D Pose of Cameras and Humans 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19726v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19726v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Garau, Giulia Martinelli, Niccolò Bisagno, Denis Tomè, Carsten Stoll
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monocular Human Pose Estimation (HPE) aims at determining the 3D positions of
human joints from a single 2D image captured by a camera. However, a single 2D
point in the image may correspond to multiple points in 3D space. Typically,
the uniqueness of the 2D-3D relationship is approximated using an orthographic
or weak-perspective camera model. In this study, instead of relying on
approximations, we advocate for utilizing the full perspective camera model.
This involves estimating camera parameters and establishing a precise,
unambiguous 2D-3D relationship. To do so, we introduce the EPOCH framework,
comprising two main components: the pose lifter network (LiftNet) and the pose
regressor network (RegNet). LiftNet utilizes the full perspective camera model
to precisely estimate the 3D pose in an unsupervised manner. It takes a 2D pose
and camera parameters as inputs and produces the corresponding 3D pose
estimation. These inputs are obtained from RegNet, which starts from a single
image and provides estimates for the 2D pose and camera parameters. RegNet
utilizes only 2D pose data as weak supervision. Internally, RegNet predicts a
3D pose, which is then projected to 2D using the estimated camera parameters.
This process enables RegNet to establish the unambiguous 2D-3D relationship.
Our experiments show that modeling the lifting as an unsupervised task with a
camera in-the-loop results in better generalization to unseen data. We obtain
state-of-the-art results for the 3D HPE on the Human3.6M and MPI-INF-3DHP
datasets. Our code is available at: [Github link upon acceptance, see
supplementary materials].
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ State Matching and Multiple References in Adaptive Active Automata
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19714v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19714v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loes Kruger, Sebastian Junges, Jurriaan Rot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Active automata learning (AAL) is a method to infer state machines by
interacting with black-box systems. Adaptive AAL aims to reduce the sample
complexity of AAL by incorporating domain specific knowledge in the form of
(similar) reference models. Such reference models appear naturally when
learning multiple versions or variants of a software system. In this paper, we
present state matching, which allows flexible use of the structure of these
reference models by the learner. State matching is the main ingredient of
adaptive L#, a novel framework for adaptive learning, built on top of L#. Our
empirical evaluation shows that adaptive L# improves the state of the art by up
to two orders of magnitude.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended paper for FM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CHASE: A Causal Heterogeneous Graph based Framework for Root Cause
  Analysis in Multimodal Microservice Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19711v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19711v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziming Zhao, Tiehua Zhang, Zhishu Shen, Hai Dong, Xingjun Ma, Xianhui Liu, Yun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the widespread adoption of distributed microservice
architectures within the industry has significantly increased the demand for
enhanced system availability and robustness. Due to the complex service
invocation paths and dependencies at enterprise-level microservice systems, it
is challenging to locate the anomalies promptly during service invocations,
thus causing intractable issues for normal system operations and maintenance.
In this paper, we propose a Causal Heterogeneous grAph baSed framEwork for root
cause analysis, namely CHASE, for microservice systems with multimodal data,
including traces, logs, and system monitoring metrics. Specifically, related
information is encoded into representative embeddings and further modeled by a
multimodal invocation graph. Following that, anomaly detection is performed on
each instance node with attentive heterogeneous message passing from its
adjacent metric and log nodes. Finally, CHASE learns from the constructed
hypergraph with hyperedges representing the flow of causality and performs root
cause localization. We evaluate the proposed framework on two public
microservice datasets with distinct attributes and compare with the
state-of-the-art methods. The results show that CHASE achieves the average
performance gain up to 36.2%(A@1) and 29.4%(Percentage@1), respectively to its
best counterpart.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InfiniGen: Efficient Generative Inference of Large Language Models with
  Dynamic KV Cache Management <span class="chip">OSDI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonbeom Lee, Jungi Lee, Junghwan Seo, Jaewoong Sim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based large language models (LLMs) demonstrate impressive
performance across various natural language processing tasks. Serving LLM
inference for generating long contents, however, poses a challenge due to the
enormous memory footprint of the transient state, known as the key-value (KV)
cache, which scales with the sequence length and batch size. In this paper, we
present InfiniGen, a novel KV cache management framework tailored for long-text
generation, which synergistically works with modern offloading-based inference
systems. InfiniGen leverages the key insight that a few important tokens that
are essential for computing the subsequent attention layer in the Transformer
can be speculated by performing a minimal rehearsal with the inputs of the
current layer and part of the query weight and key cache of the subsequent
layer. This allows us to prefetch only the essential KV cache entries (without
fetching them all), thereby mitigating the fetch overhead from the host memory
in offloading-based LLM serving systems. Our evaluation on several
representative LLMs shows that InfiniGen improves the overall performance of a
modern offloading-based system by up to 3.00x compared to prior KV cache
management methods while offering substantially better model accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>OSDI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Less is More: Accurate Speech Recognition & Translation without
  Web-Scale Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krishna C. Puvvada, Piotr Żelasko, He Huang, Oleksii Hrinchuk, Nithin Rao Koluguri, Kunal Dhawan, Somshubra Majumdar, Elena Rastorgueva, Zhehuai Chen, Vitaly Lavrukhin, Jagadeesh Balam, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in speech recognition and translation rely on hundreds of
thousands of hours of Internet speech data. We argue that state-of-the art
accuracy can be reached without relying on web-scale data. Canary -
multilingual ASR and speech translation model, outperforms current
state-of-the-art models - Whisper, OWSM, and Seamless-M4T on English, French,
Spanish, and German languages, while being trained on an order of magnitude
less data than these models. Three key factors enables such data-efficient
model: (1) a FastConformer-based attention encoder-decoder architecture (2)
training on synthetic data generated with machine translation and (3) advanced
training techniques: data-balancing, dynamic data blending, dynamic bucketing
and noise-robust fine-tuning. The model, weights, and training code will be
open-sourced.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Interspeech-2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Function+Data Flow: A Framework to Specify Machine Learning Pipelines
  for Digital Twinning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19670v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19670v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduardo de Conto, Blaise Genest, Arvind Easwaran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of digital twins (DTs) for physical systems increasingly
leverages artificial intelligence (AI), particularly for combining data from
different sources or for creating computationally efficient, reduced-dimension
models. Indeed, even in very different application domains, twinning employs
common techniques such as model order reduction and modelization with hybrid
data (that is, data sourced from both physics-based models and sensors).
Despite this apparent generality, current development practices are ad-hoc,
making the design of AI pipelines for digital twinning complex and
time-consuming. Here we propose Function+Data Flow (FDF), a domain-specific
language (DSL) to describe AI pipelines within DTs. FDF aims to facilitate the
design and validation of digital twins. Specifically, FDF treats functions as
first-class citizens, enabling effective manipulation of models learned with
AI. We illustrate the benefits of FDF on two concrete use cases from different
domains: predicting the plastic strain of a structure and modeling the
electromagnetic behavior of a bearing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures, to be published in AIware'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finite basis Kolmogorov-Arnold networks: domain decomposition for
  data-driven and physics-informed problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19662v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19662v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amanda A. Howard, Bruno Jacob, Sarah H. Murphy, Alexander Heinlein, Panos Stinis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kolmogorov-Arnold networks (KANs) have attracted attention recently as an
alternative to multilayer perceptrons (MLPs) for scientific machine learning.
However, KANs can be expensive to train, even for relatively small networks.
Inspired by finite basis physics-informed neural networks (FBPINNs), in this
work, we develop a domain decomposition method for KANs that allows for several
small KANs to be trained in parallel to give accurate solutions for multiscale
problems. We show that finite basis KANs (FBKANs) can provide accurate results
with noisy data and for physics-informed training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMEasyQuant -- An Easy to Use Toolkit for LLM Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong Liu, Meng Jiang, Kaiser Pister
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Currently, there are many quantization methods appeared for LLM quantization,
yet few are user-friendly and easy to be deployed locally. Packages like
TensorRT and Quantohave many underlying structures and self-invoking internal
functions, which are not conducive to developers' personalized development and
learning for deployment. Therefore, we develop LLMEasyQuant, it is a package
aiming to for easy quantization deployment which is user-friendly and suitable
for beginners' learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ACES: Automatic Cohort Extraction System for Event-Stream <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19653v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19653v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Justin Xu, Jack Gallifant, Alistair E. W. Johnson, Matthew B. A. McDermott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reproducibility remains a significant challenge in machine learning (ML) for
healthcare. In this field, datasets, model pipelines, and even task/cohort
definitions are often private, leading to a significant barrier in sharing,
iterating, and understanding ML results on electronic health record (EHR)
datasets. In this paper, we address a significant part of this problem by
introducing the Automatic Cohort Extraction System for Event-Stream Datasets
(ACES). This tool is designed to simultaneously simplify the development of
task/cohorts for ML in healthcare and enable the reproduction of these cohorts,
both at an exact level for single datasets and at a conceptual level across
datasets. To accomplish this, ACES provides (1) a highly intuitive and
expressive configuration language for defining both dataset-specific concepts
and dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to
automatically extract patient records that meet these defined criteria from
real-world data. ACES can be automatically applied to any dataset in either the
Medical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to
*any* dataset for which the necessary task-specific predicates can be extracted
in an event-stream form. ACES has the potential to significantly lower the
barrier to entry for defining ML tasks, redefine the way researchers interact
with EHR datasets, and significantly improve the state of reproducibility for
ML studies in this modality. ACES is available at
https://github.com/justin13601/aces.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>For ACES Online Documentation, see
  https://eventstreamaces.readthedocs.io/en/latest/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IDT: Dual-Task Adversarial Attacks for Privacy Protection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedro Faustini, Shakila Mahjabin Tonni, Annabelle McIver, Qiongkai Xu, Mark Dras
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural language processing (NLP) models may leak private information in
different ways, including membership inference, reconstruction or attribute
inference attacks. Sensitive information may not be explicit in the text, but
hidden in underlying writing characteristics. Methods to protect privacy can
involve using representations inside models that are demonstrated not to detect
sensitive attributes or -- for instance, in cases where users might not trust a
model, the sort of scenario of interest here -- changing the raw text before
models can have access to it. The goal is to rewrite text to prevent someone
from inferring a sensitive attribute (e.g. the gender of the author, or their
location by the writing style) whilst keeping the text useful for its original
intention (e.g. the sentiment of a product review). The few works tackling this
have focused on generative techniques. However, these often create extensively
different texts from the original ones or face problems such as mode collapse.
This paper explores a novel adaptation of adversarial attack techniques to
manipulate a text to deceive a classifier w.r.t one task (privacy) whilst
keeping the predictions of another classifier trained for another task
(utility) unchanged. We propose IDT, a method that analyses predictions made by
auxiliary and interpretable models to identify which tokens are important to
change for the privacy task, and which ones should be kept for the utility
task. We evaluate different datasets for NLP suitable for different tasks.
Automatic and human evaluations show that IDT retains the utility of text,
while also outperforming existing methods when deceiving a classifier w.r.t
privacy task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enforcing Equity in Neural Climate Emulators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Yik, Sam J. Silva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural network emulators have become an invaluable tool for a wide variety of
climate and weather prediction tasks. While showing incredibly promising
results, these networks do not have an inherent ability to produce equitable
predictions. That is, they are not guaranteed to provide a uniform quality of
prediction along any particular class or group of people. This potential for
inequitable predictions motivates the need for explicit representations of
fairness in these neural networks. To that end, we draw on methods for
enforcing analytical physical constraints in neural networks to bias networks
towards more equitable predictions. We demonstrate the promise of this
methodology using the task of climate model emulation. Specifically, we propose
a custom loss function which punishes emulators with unequal quality of
predictions across any prespecified regions or category, here defined using
human development index (HDI). This loss function weighs a standard loss metric
such as mean squared error against another metric which captures inequity along
the equity category (HDI), allowing us to adjust the priority of each term
before training. Importantly, the loss function does not specify a particular
definition of equity to bias the neural network towards, opening the door for
custom fairness metrics. Our results show that neural climate emulators trained
with our loss function provide more equitable predictions and that the equity
metric improves with greater weighting in the loss function. We empirically
demonstrate that while there is a tradeoff between accuracy and equity when
prioritizing the latter during training, an appropriate selection of the equity
priority hyperparameter can minimize loss of performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Model Predictive Simulation Using Structured Graphical Models and
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinghua Lou, Meet Dave, Shrinu Kushagra, Miguel Lazaro-Gredilla, Kevin Murphy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an approach to simulating trajectories of multiple interacting
agents (road users) based on transformers and probabilistic graphical models
(PGMs), and apply it to the Waymo SimAgents challenge. The transformer baseline
is based on the MTR model, which predicts multiple future trajectories
conditioned on the past trajectories and static road layout features. We then
improve upon these generated trajectories using a PGM, which contains factors
which encode prior knowledge, such as a preference for smooth trajectories, and
avoidance of collisions with static obstacles and other moving agents. We
perform (approximate) MAP inference in this PGM using the Gauss-Newton method.
Finally we sample $K=32$ trajectories for each of the $N \sim 100$ agents for
the next $T=8 \Delta$ time steps, where $\Delta=10$ is the sampling rate per
second. Following the Model Predictive Control (MPC) paradigm, we only return
the first element of our forecasted trajectories at each step, and then we
replan, so that the simulation can constantly adapt to its changing
environment. We therefore call our approach "Model Predictive Simulation" or
MPS. We show that MPS improves upon the MTR baseline, especially in safety
critical metrics such as collision rate. Furthermore, our approach is
compatible with any underlying forecasting model, and does not require extra
training, so we believe it is a valuable contribution to the community.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Special Mention at the Waymo Sim Agents Challenge 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Interpretation on Federated Learning: A Virtual Concepts
  approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Yan, Guodong Long, Jing Jiang, Michael Blumenstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tackling non-IID data is an open challenge in federated learning research.
Existing FL methods, including robust FL and personalized FL, are designed to
improve model performance without consideration of interpreting non-IID across
clients. This paper aims to design a novel FL method to robust and interpret
the non-IID data across clients. Specifically, we interpret each client's
dataset as a mixture of conceptual vectors that each one represents an
interpretable concept to end-users. These conceptual vectors could be
pre-defined or refined in a human-in-the-loop process or be learnt via the
optimization procedure of the federated learning system. In addition to the
interpretability, the clarity of client-specific personalization could also be
applied to enhance the robustness of the training process on FL system. The
effectiveness of the proposed method have been validated on benchmark datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Lipschitz Continuity: A Cost-Effective Approach to Improve
  Adversarial Robustness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erh-Chung Chen, Pin-Yu Chen, I-Hsin Chung, Che-Rung Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The security and robustness of deep neural networks (DNNs) have become
increasingly concerning. This paper aims to provide both a theoretical
foundation and a practical solution to ensure the reliability of DNNs. We
explore the concept of Lipschitz continuity to certify the robustness of DNNs
against adversarial attacks, which aim to mislead the network with adding
imperceptible perturbations into inputs. We propose a novel algorithm that
remaps the input domain into a constrained range, reducing the Lipschitz
constant and potentially enhancing robustness. Unlike existing adversarially
trained models, where robustness is enhanced by introducing additional examples
from other datasets or generative models, our method is almost cost-free as it
can be integrated with existing models without requiring re-training.
Experimental results demonstrate the generalizability of our method, as it can
be combined with various models and achieve enhancements in robustness.
Furthermore, our method achieves the best robust accuracy for CIFAR10,
CIFAR100, and ImageNet datasets on the RobustBench leaderboard.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Machine-Learning-Driven Runtime Optimization of BLAS Level 3 on Modern
  Multi-Core Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yufan Xia, Giuseppe Maria Junior Barca
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  BLAS Level 3 operations are essential for scientific computing, but finding
the optimal number of threads for multi-threaded implementations on modern
multi-core systems is challenging. We present an extension to the Architecture
and Data-Structure Aware Linear Algebra (ADSALA) library that uses machine
learning to optimize the runtime of all BLAS Level 3 operations. Our method
predicts the best number of threads for each operation based on the matrix
dimensions and the system architecture. We test our method on two HPC platforms
with Intel and AMD processors, using MKL and BLIS as baseline BLAS
implementations. We achieve speedups of 1.5 to 3.0 for all operations, compared
to using the maximum number of threads. We also analyze the runtime patterns of
different BLAS operations and explain the sources of speedup. Our work shows
the effectiveness and generality of the ADSALA approach for optimizing BLAS
routines on modern multi-core systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Multi-Thread, Matrix Multiplication, Optimization, BLAS, Machine
  Learning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ScoreFusion: fusing score-based generative models via Kullback-Leibler
  barycenters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Liu,  Junze,  Ye, Jose Blanchet, Nian Si
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of fusing pre-trained (auxiliary) generative models to
enhance the training of a target generative model. We propose using
KL-divergence weighted barycenters as an optimal fusion mechanism, in which the
barycenter weights are optimally trained to minimize a suitable loss for the
target population. While computing the optimal KL-barycenter weights can be
challenging, we demonstrate that this process can be efficiently executed using
diffusion score training when the auxiliary generative models are also trained
based on diffusion score methods. Moreover, we show that our fusion method has
a dimension-free sample complexity in total variation distance provided that
the auxiliary models are well fitted for their own task and the auxiliary tasks
combined capture the target well. The main takeaway of our method is that if
the auxiliary models are well-trained and can borrow features from each other
that are present in the target, our fusion method significantly improves the
training of generative models. We provide a concise computational
implementation of the fusion algorithm, and validate its efficiency in the
low-data regime with numerical experiments involving mixtures models and image
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>40 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic Zeroth-Order Optimization under Strongly Convexity and
  Lipschitz Hessian: Minimax Sample Complexity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19617v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19617v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qian Yu, Yining Wang, Baihe Huang, Qi Lei, Jason D. Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimization of convex functions under stochastic zeroth-order feedback has
been a major and challenging question in online learning. In this work, we
consider the problem of optimizing second-order smooth and strongly convex
functions where the algorithm is only accessible to noisy evaluations of the
objective function it queries. We provide the first tight characterization for
the rate of the minimax simple regret by developing matching upper and lower
bounds. We propose an algorithm that features a combination of a bootstrapping
stage and a mirror-descent stage. Our main technical innovation consists of a
sharp characterization for the spherical-sampling gradient estimator under
higher-order smoothness conditions, which allows the algorithm to optimally
balance the bias-variance tradeoff, and a new iterative method for the
bootstrapping stage, which maintains the performance for unbounded Hessian.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VarteX: Enhancing Weather Forecast through Distributed Variable
  Representation <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayumu Ueyama, Kazuhiko Kawamoto, Hiroshi Kera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weather forecasting is essential for various human activities. Recent
data-driven models have outperformed numerical weather prediction by utilizing
deep learning in forecasting performance. However, challenges remain in
efficiently handling multiple meteorological variables. This study proposes a
new variable aggregation scheme and an efficient learning framework for that
challenge. Experiments show that VarteX outperforms the conventional model in
forecast performance, requiring significantly fewer parameters and resources.
The effectiveness of learning through multiple aggregations and regional split
training is demonstrated, enabling more efficient and accurate deep
learning-based weather forecasting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024, Workshop on Machine Learning for Earth System Modeling</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Data Quality Dimensions and Tools for Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Zhou, Fengjiao Tu, Kewei Sha, Junhua Ding, Haihua Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning (ML) technologies have become substantial in practically all
aspects of our society, and data quality (DQ) is critical for the performance,
fairness, robustness, safety, and scalability of ML models. With the large and
complex data in data-centric AI, traditional methods like exploratory data
analysis (EDA) and cross-validation (CV) face challenges, highlighting the
importance of mastering DQ tools. In this survey, we review 17 DQ evaluation
and improvement tools in the last 5 years. By introducing the DQ dimensions,
metrics, and main functions embedded in these tools, we compare their strengths
and limitations and propose a roadmap for developing open-source DQ tools for
ML. Based on the discussions on the challenges and emerging trends, we further
highlight the potential applications of large language models (LLMs) and
generative AI in DQ evaluation and improvement for ML. We believe this
comprehensive survey can enhance understanding of DQ in ML and could drive
progress in data-centric AI. A complete list of the literature investigated in
this survey is available on GitHub at:
https://github.com/haihua0913/awesome-dq4ml.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by The 6th IEEE International Conference
  on Artificial Intelligence Testing (IEEE AITest 2024) as an invited paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Deep Clustering: From the Prior Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19602v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19602v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiding Lu, Haobin Li, Yunfan Li, Yijie Lin, Xi Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Facilitated by the powerful feature extraction ability of neural networks,
deep clustering has achieved great success in analyzing high-dimensional and
complex real-world data. The performance of deep clustering methods is affected
by various factors such as network structures and learning objectives. However,
as pointed out in this survey, the essence of deep clustering lies in the
incorporation and utilization of prior knowledge, which is largely ignored by
existing works. From pioneering deep clustering methods based on data structure
assumptions to recent contrastive clustering methods based on data augmentation
invariances, the development of deep clustering intrinsically corresponds to
the evolution of prior knowledge. In this survey, we provide a comprehensive
review of deep clustering methods by categorizing them into six types of prior
knowledge. We find that in general the prior innovation follows two trends,
namely, i) from mining to constructing, and ii) from internal to external.
Besides, we provide a benchmark on five widely-used datasets and analyze the
performance of methods with diverse priors. By providing a novel prior
knowledge perspective, we hope this survey could provide some novel insights
and inspire future research in the deep clustering community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Cyber Defense in Dynamic Active Directories through
  Reinforcement Learning <span class="chip">ESORICS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19596v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19596v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Diksha Goel, Kristen Moore, Mingyu Guo, Derui Wang, Minjune Kim, Seyit Camtepe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses a significant gap in Autonomous Cyber Operations (ACO)
literature: the absence of effective edge-blocking ACO strategies in dynamic,
real-world networks. It specifically targets the cybersecurity vulnerabilities
of organizational Active Directory (AD) systems. Unlike the existing literature
on edge-blocking defenses which considers AD systems as static entities, our
study counters this by recognizing their dynamic nature and developing advanced
edge-blocking defenses through a Stackelberg game model between attacker and
defender. We devise a Reinforcement Learning (RL)-based attack strategy and an
RL-assisted Evolutionary Diversity Optimization-based defense strategy, where
the attacker and defender improve each other strategy via parallel gameplay. To
address the computational challenges of training attacker-defender strategies
on numerous dynamic AD graphs, we propose an RL Training Facilitator that
prunes environments and neural networks to eliminate irrelevant elements,
enabling efficient and scalable training for large graphs. We extensively train
the attacker strategy, as a sophisticated attacker model is essential for a
robust defense. Our empirical results successfully demonstrate that our
proposed approach enhances defender's proficiency in hardening dynamic AD
graphs while ensuring scalability for large-scale AD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The manuscript has been accepted as full paper at European Symposium
  on Research in Computer Security (ESORICS) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Network Bending of Diffusion Models for Audio-Visual Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luke Dzwonczyk, Carmine Emanuele Cella, David Ban
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we present the first steps towards the creation of a tool which
enables artists to create music visualizations using pre-trained, generative,
machine learning models. First, we investigate the application of network
bending, the process of applying transforms within the layers of a generative
network, to image generation diffusion models by utilizing a range of
point-wise, tensor-wise, and morphological operators. We identify a number of
visual effects that result from various operators, including some that are not
easily recreated with standard image editing tools. We find that this process
allows for continuous, fine-grain control of image generation which can be
helpful for creative applications. Next, we generate music-reactive videos
using Stable Diffusion by passing audio features as parameters to network
bending operators. Finally, we comment on certain transforms which radically
shift the image and the possibilities of learning more about the latent space
of Stable Diffusion based on these transforms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 figures, to be published in the proceedings of the 27th
  International Conference on Digital Audio Effects (DAFx24), for additional
  image and video examples see https://dzluke.github.io/DAFX2024/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HarmonICA: Neural non-stationarity correction and source separation for
  motor neuron interfaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Kenneth Clarke, Agnese Grison, Irene Mendez Guerra, Pranav Mamidanna, Shihan Ma, Silvia Muceli, Dario Farina
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A major outstanding problem when interfacing with spinal motor neurons is how
to accurately compensate for non-stationary effects in the signal during source
separation routines, particularly when they cannot be estimated in advance.
This forces current systems to instead use undifferentiated bulk signal, which
limits the potential degrees of freedom for control. In this study we propose a
potential solution, using an unsupervised learning algorithm to blindly correct
for the effects of latent processes which drive the signal non-stationarities.
We implement this methodology within the theoretical framework of a quasilinear
version of independent component analysis (ICA). The proposed design,
HarmonICA, sidesteps the identifiability problems of nonlinear ICA, allowing
for equivalent predictability to linear ICA whilst retaining the ability to
learn complex nonlinear relationships between non-stationary latents and their
effects on the signal. We test HarmonICA on both invasive and non-invasive
recordings both simulated and real, demonstrating an ability to blindly
compensate for the non-stationary effects specific to each, and thus to
significantly enhance the quality of a source separation routine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FRED: Flexible REduction-Distribution Interconnect and Communication
  Implementation for Wafer-Scale Distributed Training of DNN Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19580v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19580v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saeed Rashidi, William Won, Sudarshan Srinivasan, Puneet Gupta, Tushar Krishna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distributed Deep Neural Network (DNN) training is a technique to reduce the
training overhead by distributing the training tasks into multiple
accelerators, according to a parallelization strategy. However,
high-performance compute and interconnects are needed for maximum speed-up and
linear scaling of the system. Wafer-scale systems are a promising technology
that allows for tightly integrating high-end accelerators with high-speed
wafer-scale interconnects, making it an attractive platform for distributed
training. However, the wafer-scale interconnect should offer high performance
and flexibility for various parallelization strategies to enable maximum
optimizations for compute and memory usage. In this paper, we propose FRED, a
wafer-scale interconnect that is tailored for the high-BW requirements of
wafer-scale networks and can efficiently execute communication patterns of
different parallelization strategies. Furthermore, FRED supports in-switch
collective communication execution that reduces the network traffic by
approximately 2X. Our results show that FRED can improve the average end-to-end
training time of ResNet-152, Transformer-17B, GPT-3, and Transformer-1T by
1.76X, 1.87X, 1.34X, and 1.4X, respectively when compared to a baseline
waferscale 2D-Mesh fabric.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GEO: Generative Engine Optimization <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09735v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09735v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranjal Aggarwal, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan, Ameet Deshpande
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of large language models (LLMs) has ushered in a new paradigm of
search engines that use generative models to gather and summarize information
to answer user queries. This emerging technology, which we formalize under the
unified framework of generative engines (GEs), can generate accurate and
personalized responses, rapidly replacing traditional search engines like
Google and Bing. Generative Engines typically satisfy queries by synthesizing
information from multiple sources and summarizing them using LLMs. While this
shift significantly improves $\textit{user}$ utility and $\textit{generative
search engine}$ traffic, it poses a huge challenge for the third stakeholder --
website and content creators. Given the black-box and fast-moving nature of
generative engines, content creators have little to no control over
$\textit{when}$ and $\textit{how}$ their content is displayed. With generative
engines here to stay, we must ensure the creator economy is not disadvantaged.
To address this, we introduce Generative Engine Optimization (GEO), the first
novel paradigm to aid content creators in improving their content visibility in
generative engine responses through a flexible black-box optimization framework
for optimizing and defining visibility metrics. We facilitate systematic
evaluation by introducing GEO-bench, a large-scale benchmark of diverse user
queries across multiple domains, along with relevant web sources to answer
these queries. Through rigorous evaluation, we demonstrate that GEO can boost
visibility by up to $40\%$ in generative engine responses. Moreover, we show
the efficacy of these strategies varies across domains, underscoring the need
for domain-specific optimization methods. Our work opens a new frontier in
information discovery systems, with profound implications for both developers
of generative engines and content creators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.03812v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.03812v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        T. Lucas Makinen, Justin Alsing, Benjamin D. Wandelt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Set-based learning is an essential component of modern deep learning and
network science. Graph Neural Networks (GNNs) and their edge-free counterparts
Deepsets have proven remarkably useful on ragged and topologically challenging
datasets. The key to learning informative embeddings for set members is a
specified aggregation function, usually a sum, max, or mean. We propose
Fishnets, an aggregation strategy for learning information-optimal embeddings
for sets of data for both Bayesian inference and graph aggregation. We
demonstrate that i) Fishnets neural summaries can be scaled optimally to an
arbitrary number of data objects, ii) Fishnets aggregations are robust to
changes in data distribution, unlike standard deepsets, iii) Fishnets saturate
Bayesian information content and extend to regimes where MCMC techniques fail
and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We
show that by adopting a Fishnets aggregation scheme for message passing, GNNs
can achieve state-of-the-art performance versus architecture size on
ogbn-protein data over existing benchmarks with a fraction of learnable
parameters and faster training time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures, 2 tables. Submitted to JMLR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Training of Graph Foundation Models for Atomistic Materials
  Modeling: A Case Study with HydraGNN 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12909v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12909v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Massimiliano Lupo Pasini, Jong Youl Choi, Kshitij Mehta, Pei Zhang, David Rogers, Jonghyun Bae, Khaled Z. Ibrahim, Ashwin M. Aji, Karl W. Schulz, Jorda Polo, Prasanna Balaprakash
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present our work on developing and training scalable graph foundation
models (GFM) using HydraGNN, a multi-headed graph convolutional neural network
architecture. HydraGNN expands the boundaries of graph neural network (GNN) in
both training scale and data diversity. It abstracts over message passing
algorithms, allowing both reproduction of and comparison across algorithmic
innovations that define convolution in GNNs. This work discusses a series of
optimizations that have allowed scaling up the GFM training to tens of
thousands of GPUs on datasets that consist of hundreds of millions of graphs.
Our GFMs use multi-task learning (MTL) to simultaneously learn graph-level and
node-level properties of atomistic structures, such as the total energy and
atomic forces. Using over 150 million atomistic structures for training, we
illustrate the performance of our approach along with the lessons learned on
two United States Department of Energy (US-DOE) supercomputers, namely the
Perlmutter petascale system at the National Energy Research Scientific
Computing Center and the Frontier exascale system at Oak Ridge National
Laboratory. The HydraGNN architecture enables the GFM to achieve near-linear
strong scaling performance using more than 2,000 GPUs on Perlmutter and 16,000
GPUs on Frontier. Hyperparameter optimization (HPO) was performed on over
64,000 GPUs on Frontier to select GFM architectures with high accuracy. Early
stopping was applied on each GFM architecture for energy awareness in
performing such an extreme-scale task. The training of an ensemble of
highest-ranked GFM architectures continued until convergence to establish
uncertainty quantification (UQ) capabilities with ensemble learning. Our
contribution opens the door for rapidly developing, training, and deploying
GFMs using large-scale computational resources to enable AI-accelerated
materials discovery and design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ChIRAAG: Chat<span class="highlight-title">GPT</span> Informed Rapid and Automated Assertion Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00093v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00093v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhabesh Mali, Karthik Maddala, Vatsal Gupta, Sweeya Reddy, Chandan Karfa, Ramesh Karri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  System Verilog Assertion (SVA) formulation -- a critical yet complex task is
a prerequisite in the Assertion Based Verification (ABV) process.
Traditionally, SVA formulation involves expert-driven interpretation of
specifications, which is time-consuming and prone to human error. Recently,
LLM-informed automatic assertion generation is gaining interest. We designed a
novel framework called ChIRAAG, based on OpenAI GPT4, to generate SVA from
natural language specifications of a design. ChIRAAG constitutes the systematic
breakdown of design specifications into a standardized format, further
generating assertions from formatted specifications using LLM. Furthermore, we
used few test cases to validate the LLM-generated assertions. Automatic
feedback of log messages from the simulation tool to the LLM ensures that the
framework can generate correct SVAs. In our experiments, only 27% of
LLM-generated raw assertions had errors, which was rectified in few iterations
based on the simulation log. Our results on OpenTitan designs show that LLMs
can streamline and assist engineers in the assertion generation process,
reshaping verification workflows.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 2 figures and 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Solving Differential Equations using Physics-Informed Deep Equilibrium
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03472v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03472v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bruno Machado Pacheco, Eduardo Camponogara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) for
solving initial value problems (IVPs) of ordinary differential equations
(ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) and
physics-informed neural networks (PINNs), PIDEQs combine the implicit output
representation of DEQs with physics-informed training techniques. We validate
PIDEQs using the Van der Pol oscillator as a benchmark problem, demonstrating
their efficiency and effectiveness in solving IVPs. Our analysis includes key
hyperparameter considerations for optimizing PIDEQ performance. By bridging
deep learning and physics-based modeling, this work advances computational
techniques for solving IVPs, with implications for scientific computing and
engineering applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CASE 2024; Extended Sec. III.B</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Impact of Feature Representation on the Accuracy of Photonic Neural
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18757v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18757v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mauricio Gomes de Queiroz, Paul Jimenez, Raphael Cardoso, Mateus Vidaletti Costa, Mohab Abdalla, Ian O'Connor, Alberto Bosio, Fabio Pavanello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Photonic Neural Networks (PNNs) are gaining significant interest in the
research community due to their potential for high parallelization, low
latency, and energy efficiency. PNNs compute using light, which leads to
several differences in implementation when compared to electronics, such as the
need to represent input features in the photonic domain before feeding them
into the network. In this encoding process, it is common to combine multiple
features into a single input to reduce the number of inputs and associated
devices, leading to smaller and more energy-efficient PNNs. Although this
alters the network's handling of input data, its impact on PNNs remains
understudied. This paper addresses this open question, investigating the effect
of commonly used encoding strategies that combine features on the performance
and learning capabilities of PNNs. Here, using the concept of feature
importance, we develop a mathematical methodology for analyzing feature
combination. Through this methodology, we demonstrate that encoding multiple
features together in a single input determines their relative importance, thus
limiting the network's ability to learn from the data. Given some prior
knowledge of the data, however, this can also be leveraged for higher accuracy.
By selecting an optimal encoding method, we achieve up to a 12.3% improvement
in accuracy of PNNs trained on the Iris dataset compared to other encoding
techniques, surpassing the performance of networks where features are not
combined. These findings highlight the importance of carefully choosing the
encoding to the accuracy and decision-making strategies of PNNs, particularly
in size or power constrained applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Importance Weighted Expectation-Maximization for Protein Sequence Design 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.00386v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.00386v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenqiao Song, Lei Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing protein sequences with desired biological function is crucial in
biology and chemistry. Recent machine learning methods use a surrogate
sequence-function model to replace the expensive wet-lab validation. How can we
efficiently generate diverse and novel protein sequences with high fitness? In
this paper, we propose IsEM-Pro, an approach to generate protein sequences
towards a given fitness criterion. At its core, IsEM-Pro is a latent generative
model, augmented by combinatorial structure features from a separately learned
Markov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization
method (MCEM) to learn the model. During inference, sampling from its latent
space enhances diversity while its MRFs features guide the exploration in high
fitness regions. Experiments on eight protein sequence design tasks show that
our IsEM-Pro outperforms the previous best methods by at least 55% on average
fitness score and generates more diverse and novel protein sequences.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Simple Mixture Policy Parameterization for Improving Sample Efficiency
  of CVaR Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11062v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11062v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yudong Luo, Yangchen Pan, Han Wang, Philip Torr, Pascal Poupart
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning algorithms utilizing policy gradients (PG) to optimize
Conditional Value at Risk (CVaR) face significant challenges with sample
inefficiency, hindering their practical applications. This inefficiency stems
from two main facts: a focus on tail-end performance that overlooks many
sampled trajectories, and the potential of gradient vanishing when the lower
tail of the return distribution is overly flat. To address these challenges, we
propose a simple mixture policy parameterization. This method integrates a
risk-neutral policy with an adjustable policy to form a risk-averse policy. By
employing this strategy, all collected trajectories can be utilized for policy
updating, and the issue of vanishing gradients is counteracted by stimulating
higher returns through the risk-neutral component, thus lifting the tail and
preventing flatness. Our empirical study reveals that this mixture
parameterization is uniquely effective across a variety of benchmark domains.
Specifically, it excels in identifying risk-averse CVaR policies in some Mujoco
environments where the traditional CVaR-PG fails to learn a reasonable policy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>RLC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robustness Assessment of a Runway Object Classifier for Safe Aircraft
  Taxiing <span class="chip">SC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00035v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00035v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhak Elboher, Raya Elsaleh, Omri Isac, Mélanie Ducoffe, Audrey Galametz, Guillaume Povéda, Ryma Boumazouza, Noémie Cohen, Guy Katz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As deep neural networks (DNNs) are becoming the prominent solution for many
computational problems, the aviation industry seeks to explore their potential
in alleviating pilot workload and in improving operational safety. However, the
use of DNNs in this type of safety-critical applications requires a thorough
certification process. This need can be addressed through formal verification,
which provides rigorous assurances -- e.g.,~by proving the absence of certain
mispredictions. In this case-study paper, we demonstrate this process using an
image-classifier DNN currently under development at Airbus and intended for use
during the aircraft taxiing phase. We use formal methods to assess this DNN's
robustness to three common image perturbation types: noise, brightness and
contrast, and some of their combinations. This process entails multiple
invocations of the underlying verifier, which might be computationally
expensive; and we therefore propose a method that leverages the monotonicity of
these robustness properties, as well as the results of past verification
queries, in order to reduce the overall number of verification queries required
by nearly 60%. Our results provide an indication of the level of robustness
achieved by the DNN classifier under study, and indicate that it is
considerably more vulnerable to noise than to brightness or contrast
perturbations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a preprint version of the paper in the proceedings of 43rd
  Digital Avionics Systems Conference (DASC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling laws for learning with real and surrogate data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.04376v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.04376v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayush Jain, Andrea Montanari, Eren Sasoglu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collecting large quantities of high-quality data can be prohibitively
expensive or impractical, and a bottleneck in machine learning. One may instead
augment a small set of $n$ data points from the target distribution with data
from more accessible sources, e.g. data collected under different circumstances
or synthesized by generative models. We refer to such data as `surrogate data.'
We introduce a weighted empirical risk minimization (ERM) approach for
integrating surrogate data into training. We analyze mathematically this method
under several classical statistical models, and validate our findings
empirically on datasets from different domains. Our main findings are: $(i)$
Integrating surrogate data can significantly reduce the test error on the
original distribution. Surprisingly, this can happen even when the surrogate
data is unrelated to the original ones. We trace back this behavior to the
classical Stein's paradox. $(ii)$ In order to reap the benefit of surrogate
data, it is crucial to use optimally weighted ERM. $(iii)$ The test error of
models trained on mixtures of real and surrogate data is approximately
described by a scaling law. This scaling law can be used to predict the optimal
weighting scheme, and to choose the amount of surrogate data to add.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Added new experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distributed Speculative Inference of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14105v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14105v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Moshe Wasserblat, Tomer Galanti, Michal Gordon, David Harel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accelerating the inference of large language models (LLMs) is an important
challenge in artificial intelligence. This paper introduces distributed
speculative inference (DSI), a novel distributed inference algorithm that is
provably faster than speculative inference (SI) [leviathan2023fast,
chen2023accelerating, miao2023specinfer] and traditional autoregressive
inference (non-SI). Like other SI algorithms, DSI works on frozen LLMs,
requiring no training or architectural modifications, and it preserves the
target distribution.
  Prior studies on SI have demonstrated empirical speedups (compared to non-SI)
but require a fast and accurate drafter LLM. In practice, off-the-shelf LLMs
often do not have matching drafters that are sufficiently fast and accurate. We
show a gap: SI gets slower than non-SI when using slower or less accurate
drafters. We close this gap by proving that DSI is faster than both SI and
non-SI given any drafters. By orchestrating multiple instances of the target
and drafters, DSI is not only faster than SI but also supports LLMs that cannot
be accelerated with SI.
  Our simulations show speedups of off-the-shelf LLMs in realistic settings:
DSI is 1.29-1.92x faster than SI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Bayesian uncertainty quantification with data-driven priors for
  radio interferometric imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00125v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00125v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobías I. Liaudat, Matthijs Mars, Matthew A. Price, Marcelo Pereyra, Marta M. Betcke, Jason D. McEwen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Next-generation radio interferometers like the Square Kilometer Array have
the potential to unlock scientific discoveries thanks to their unprecedented
angular resolution and sensitivity. One key to unlocking their potential
resides in handling the deluge and complexity of incoming data. This challenge
requires building radio interferometric imaging methods that can cope with the
massive data sizes and provide high-quality image reconstructions with
uncertainty quantification (UQ). This work proposes a method coined QuantifAI
to address UQ in radio-interferometric imaging with data-driven (learned)
priors for high-dimensional settings. Our model, rooted in the Bayesian
framework, uses a physically motivated model for the likelihood. The model
exploits a data-driven convex prior, which can encode complex information
learned implicitly from simulations and guarantee the log-concavity of the
posterior. We leverage probability concentration phenomena of high-dimensional
log-concave posteriors that let us obtain information about the posterior,
avoiding MCMC sampling techniques. We rely on convex optimisation methods to
compute the MAP estimation, which is known to be faster and better scale with
dimension than MCMC sampling strategies. Our method allows us to compute local
credible intervals, i.e., Bayesian error bars, and perform hypothesis testing
of structure on the reconstructed image. In addition, we propose a novel
blazing-fast method to compute pixel-wise uncertainties at different scales. We
demonstrate our method by reconstructing radio-interferometric images in a
simulated setting and carrying out fast and scalable UQ, which we validate with
MCMC sampling. Our method shows an improved image quality and more meaningful
uncertainties than the benchmark method based on a sparsity-promoting prior.
QuantifAI's source code: https://github.com/astro-informatics/QuantifAI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 14 figures, 10 tables, code available at
  https://github.com/astro-informatics/QuantifAI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic planning in hierarchical active inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11658v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11658v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Priorelli, Ivilin Peev Stoianov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  By dynamic planning, we refer to the ability of the human brain to infer and
impose motor trajectories related to cognitive decisions. A recent paradigm,
active inference, brings fundamental insights into the adaptation of biological
organisms, constantly striving to minimize prediction errors to restrict
themselves to life-compatible states. Over the past years, many studies have
shown how human and animal behavior could be explained in terms of an active
inferential process - either as discrete decision-making or continuous motor
control - inspiring innovative solutions in robotics and artificial
intelligence. Still, the literature lacks a comprehensive outlook on how to
effectively plan actions in changing environments. Setting ourselves the goal
of modeling tool use, we delve into the topic of dynamic planning in active
inference, keeping in mind two crucial aspects of biological goal-directed
behavior: the capacity to understand and exploit affordances for object
manipulation, and to learn the hierarchical interactions between the self and
the environment, including other agents. We start from a simple unit and
gradually describe more advanced structures, comparing recently proposed design
choices and providing basic examples for each section. This study distances
itself from traditional views centered on neural networks and reinforcement
learning, and points toward a yet unexplored direction in active inference:
hybrid representations in hierarchical models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Digital Twin Calibration for Biological System-of-Systems: Cell Culture
  Manufacturing Process 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03913v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03913v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fuqiang Cheng, Wei Xie, Hua Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Biomanufacturing innovation relies on an efficient Design of Experiments
(DoEs) to optimize processes and product quality. Traditional DoE methods,
ignoring the underlying bioprocessing mechanisms, often suffer from a lack of
interpretability and sample efficiency. This limitation motivates us to create
a new optimal learning approach for digital twin model calibration. In this
study, we consider the cell culture process multi-scale mechanistic model, also
known as Biological System-of-Systems (Bio-SoS). This model with a modular
design, composed of sub-models, allows us to integrate data across various
production processes. To calibrate the Bio-SoS digital twin, we evaluate the
mean squared error of model prediction and develop a computational approach to
quantify the impact of parameter estimation error of individual sub-models on
the prediction accuracy of digital twin, which can guide sample-efficient and
interpretable DoEs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nearest Neighbor Sampling for Covariate Shift Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.09969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.09969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        François Portier, Lionel Truquet, Ikko Yamane
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many existing covariate shift adaptation methods estimate sample weights
given to loss values to mitigate the gap between the source and the target
distribution. However, estimating the optimal weights typically involves
computationally expensive matrix inversion and hyper-parameter tuning. In this
paper, we propose a new covariate shift adaptation method which avoids
estimating the weights. The basic idea is to directly work on unlabeled target
data, labeled according to the $k$-nearest neighbors in the source dataset. Our
analysis reveals that setting $k = 1$ is an optimal choice. This property
removes the necessity of tuning the only hyper-parameter $k$ and leads to a
running time quasi-linear in the sample size. Our results include sharp rates
of convergence for our estimator, with a tight control of the mean square error
and explicit constants. In particular, the variance of our estimators has the
same rate of convergence as for standard parametric estimation despite their
non-parametric nature. The proposed estimator shares similarities with some
matching-based treatment effect estimators used, e.g., in biostatistics,
econometrics, and epidemiology. Our experiments show that it achieves drastic
reduction in the running time with remarkable accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent variable model for high-dimensional point process with structured
  missingness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05758v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05758v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksim Sinelnikov, Manuel Haussmann, Harri Lähdesmäki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Longitudinal data are important in numerous fields, such as healthcare,
sociology and seismology, but real-world datasets present notable challenges
for practitioners because they can be high-dimensional, contain structured
missingness patterns, and measurement time points can be governed by an unknown
stochastic process. While various solutions have been suggested, the majority
of them have been designed to account for only one of these challenges. In this
work, we propose a flexible and efficient latent-variable model that is capable
of addressing all these limitations. Our approach utilizes Gaussian processes
to capture temporal correlations between samples and their associated
missingness masks as well as to model the underlying point process. We
construct our model as a variational autoencoder together with deep neural
network parameterised encoder and decoder models, and develop a scalable
amortised variational inference approach for efficient model training. We
demonstrate competitive performance using both simulated and real datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Catastrophic-risk-aware reinforcement learning with
  extreme-value-theory-based policy gradients 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15612v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15612v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parisa Davar, Frédéric Godin, Jose Garrido
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper tackles the problem of mitigating catastrophic risk (which is risk
with very low frequency but very high severity) in the context of a sequential
decision making process. This problem is particularly challenging due to the
scarcity of observations in the far tail of the distribution of cumulative
costs (negative rewards). A policy gradient algorithm is developed, that we
call POTPG. It is based on approximations of the tail risk derived from extreme
value theory. Numerical experiments highlight the out-performance of our method
over common benchmarks, relying on the empirical distribution. An application
to financial risk management, more precisely to the dynamic hedging of a
financial option, is presented.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The Python code to replicate the various numerical experiments of
  this paper is available at
  https://github.com/parisadavar/EVT-policy-gradient-RL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tracking Object Positions in Reinforcement Learning: A Metric for
  Keypoint Detection (extended version) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emma Cramer, Jonas Reiher, Sebastian Trimpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) for robot control typically requires a detailed
representation of the environment state, including information about
task-relevant objects not directly measurable. Keypoint detectors, such as
spatial autoencoders (SAEs), are a common approach to extracting a
low-dimensional representation from high-dimensional image data. SAEs aim at
spatial features such as object positions, which are often useful
representations in robotic RL. However, whether an SAE is actually able to
track objects in the scene and thus yields a spatial state representation well
suited for RL tasks has rarely been examined due to a lack of established
metrics. In this paper, we propose to assess the performance of an SAE instance
by measuring how well keypoints track ground truth objects in images. We
present a computationally lightweight metric and use it to evaluate common
baseline SAE architectures on image data from a simulated robot task. We find
that common SAEs differ substantially in their spatial extraction capability.
Furthermore, we validate that SAEs that perform well in our metric achieve
superior performance when used in downstream RL. Thus, our metric is an
effective and lightweight indicator of RL performance before executing
expensive RL training. Building on these insights, we identify three key
modifications of SAE architectures to improve tracking performance. We make our
code available at anonymous.4open.science/r/sae-rl.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The G-invariant graph Laplacian 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.17001v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.17001v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eitan Rosen, Paulina Hoyos, Xiuyuan Cheng, Joe Kileel, Yoel Shkolnisky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Laplacian based algorithms for data lying on a manifold have been
proven effective for tasks such as dimensionality reduction, clustering, and
denoising. In this work, we consider data sets whose data points lie on a
manifold that is closed under the action of a known unitary matrix Lie group G.
We propose to construct the graph Laplacian by incorporating the distances
between all the pairs of points generated by the action of G on the data set.
We deem the latter construction the ``G-invariant Graph Laplacian'' (G-GL). We
show that the G-GL converges to the Laplace-Beltrami operator on the data
manifold, while enjoying a significantly improved convergence rate compared to
the standard graph Laplacian which only utilizes the distances between the
points in the given data set. Furthermore, we show that the G-GL admits a set
of eigenfunctions that have the form of certain products between the group
elements and eigenvectors of certain matrices, which can be estimated from the
data efficiently using FFT-type algorithms. We demonstrate our construction and
its advantages on the problem of filtering data on a noisy manifold closed
under the action of the special unitary group SU(2).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Decision Policies with Instrumental Variables through Double
  Machine Learning <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08498v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08498v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daqian Shao, Ashkan Soleymani, Francesco Quinzan, Marta Kwiatkowska
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A common issue in learning decision-making policies in data-rich settings is
spurious correlations in the offline dataset, which can be caused by hidden
confounders. Instrumental variable (IV) regression, which utilises a key
unconfounded variable known as the instrument, is a standard technique for
learning causal relationships between confounded action, outcome, and context
variables. Most recent IV regression algorithms use a two-stage approach, where
a deep neural network (DNN) estimator learnt in the first stage is directly
plugged into the second stage, in which another DNN is used to estimate the
causal effect. Naively plugging the estimator can cause heavy bias in the
second stage, especially when regularisation bias is present in the first stage
estimator. We propose DML-IV, a non-linear IV regression method that reduces
the bias in two-stage IV regressions and effectively learns high-performing
policies. We derive a novel learning objective to reduce bias and design the
DML-IV algorithm following the double/debiased machine learning (DML)
framework. The learnt DML-IV estimator has strong convergence rate and
$O(N^{-1/2})$ suboptimality guarantees that match those when the dataset is
unconfounded. DML-IV outperforms state-of-the-art IV regression methods on IV
regression benchmarks and learns high-performing policies in the presence of
instruments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MatText: Do Language Models Need More than Text & Scale for Materials
  Modeling? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17295v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17295v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nawaf Alampara, Santiago Miret, Kevin Maik Jablonka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effectively representing materials as text has the potential to leverage the
vast advancements of large language models (LLMs) for discovering new
materials. While LLMs have shown remarkable success in various domains, their
application to materials science remains underexplored. A fundamental challenge
is the lack of understanding of how to best utilize text-based representations
for materials modeling. This challenge is further compounded by the absence of
a comprehensive benchmark to rigorously evaluate the capabilities and
limitations of these text representations in capturing the complexity of
material systems. To address this gap, we propose MatText, a suite of
benchmarking tools and datasets designed to systematically evaluate the
performance of language models in modeling materials. MatText encompasses nine
distinct text-based representations for material systems, including several
novel representations. Each representation incorporates unique inductive biases
that capture relevant information and integrate prior physical knowledge about
materials. Additionally, MatText provides essential tools for training and
benchmarking the performance of language models in the context of materials
science. These tools include standardized dataset splits for each
representation, probes for evaluating sensitivity to geometric factors, and
tools for seamlessly converting crystal structures into text. Using MatText, we
conduct an extensive analysis of the capabilities of language models in
modeling materials. Our findings reveal that current language models
consistently struggle to capture the geometric information crucial for
materials modeling across all representations. Instead, these models tend to
leverage local information, which is emphasized in some of our novel
representations. Our analysis underscores MatText's ability to reveal
shortcomings of text-based methods for materials design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Intelligible and Effective Graph Neural Additive Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01317v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01317v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maya Bechler-Speicher, Amir Globerson, Ran Gilad-Bachrach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) have emerged as the predominant approach for
learning over graph-structured data. However, most GNNs operate as black-box
models and require post-hoc explanations, which may not suffice in high-stakes
scenarios where transparency is crucial. In this paper, we present a GNN that
is interpretable by design. Our model, Graph Neural Additive Network (GNAN), is
a novel extension of the interpretable class of Generalized Additive Models,
and can be visualized and fully understood by humans. GNAN is designed to be
fully interpretable, allowing both global and local explanations at the feature
and graph levels through direct visualization of the model. These
visualizations describe the exact way the model uses the relationships between
the target variable, the features, and the graph. We demonstrate the
intelligibility of GNANs in a series of examples on different tasks and
datasets. In addition, we show that the accuracy of GNAN is on par with
black-box GNNs, making it suitable for critical applications where transparency
is essential, alongside high accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LatentExplainer: Explaining Latent Representations in Deep Generative
  Models with Multi-modal Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14862v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14862v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep generative models like VAEs and diffusion models have advanced various
generation tasks by leveraging latent variables to learn data distributions and
generate high-quality samples. Despite the field of explainable AI making
strides in interpreting machine learning models, understanding latent variables
in generative models remains challenging. This paper introduces
LatentExplainer, a framework for automatically generating semantically
meaningful explanations of latent variables in deep generative models.
LatentExplainer tackles three main challenges: inferring the meaning of latent
variables, aligning explanations with inductive biases, and handling varying
degrees of explainability. By perturbing latent variables and interpreting
changes in generated data, the framework provides a systematic approach to
understanding and controlling the data generation process, enhancing the
transparency and interpretability of deep generative models. We evaluate our
proposed method on several real-world and synthetic datasets, and the results
demonstrate superior performance in generating high-quality explanations of
latent variables.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Learning Stochastic Population Models by Gradient Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07049v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07049v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Justin N. Kreikemeyer, Philipp Andelfinger, Adelinde M. Uhrmacher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Increasing effort is put into the development of methods for learning
mechanistic models from data. This task entails not only the accurate
estimation of parameters but also a suitable model structure. Recent work on
the discovery of dynamical systems formulates this problem as a linear equation
system. Here, we explore several simulation-based optimization approaches,
which allow much greater freedom in the objective formulation and weaker
conditions on the available data. We show that even for relatively small
stochastic population models, simultaneous estimation of parameters and
structure poses major challenges for optimization procedures. Particularly, we
investigate the application of the local stochastic gradient descent method,
commonly used for training machine learning models. We demonstrate accurate
estimation of models but find that enforcing the inference of parsimonious,
interpretable models drastically increases the difficulty. We give an outlook
on how this challenge can be overcome.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Maxout Network-based Feature Fusion and Political Tangent Search
  Optimizer enabled Transfer Learning for Thalassemia Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.02029v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.02029v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hemn Barzan Abdalla, Awder Ahmed, Guoquan Li, Nasser Mustafa, Abdur Rashid Sangi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Thalassemia is a heritable blood disorder which is the outcome of a genetic
defect causing lack of production of hemoglobin polypeptide chains. However,
there is less understanding of the precise frequency as well as sharing in
these areas. Knowing about the frequency of thalassemia occurrence and
dependable mutations is thus a significant step in preventing, controlling, and
treatment planning. Here, Political Tangent Search Optimizer based Transfer
Learning (PTSO_TL) is introduced for thalassemia detection. Initially, input
data obtained from a particular dataset is normalized in the data normalization
stage. Quantile normalization is utilized in the data normalization stage, and
the data are then passed to the feature fusion phase, in which Weighted
Euclidean Distance with Deep Maxout Network (DMN) is utilized. Thereafter, data
augmentation is performed using the oversampling method to increase data
dimensionality. Lastly, thalassemia detection is carried out by TL, wherein a
convolutional neural network (CNN) is utilized with hyperparameters from a
trained model such as Xception. TL is tuned by PTSO, and the training algorithm
PTSO is presented by merging of Political Optimizer (PO) and Tangent Search
Algorithm (TSA). Furthermore, PTSO_TL obtained maximal precision, recall, and
f-measure values of about 94.3%, 96.1%, and 95.2%, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MALIBO: Meta-learning for Likelihood-free Bayesian Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.03565v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.03565v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiarong Pan, Stefan Falkner, Felix Berkenkamp, Joaquin Vanschoren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian optimization (BO) is a popular method to optimize costly black-box
functions. While traditional BO optimizes each new target task from scratch,
meta-learning has emerged as a way to leverage knowledge from related tasks to
optimize new tasks faster. However, existing meta-learning BO methods rely on
surrogate models that suffer from scalability issues and are sensitive to
observations with different scales and noise types across tasks. Moreover, they
often overlook the uncertainty associated with task similarity. This leads to
unreliable task adaptation when only limited observations are obtained or when
the new tasks differ significantly from the related tasks. To address these
limitations, we propose a novel meta-learning BO approach that bypasses the
surrogate model and directly learns the utility of queries across tasks. Our
method explicitly models task uncertainty and includes an auxiliary model to
enable robust adaptation to new tasks. Extensive experiments show that our
method demonstrates strong anytime performance and outperforms state-of-the-art
meta-learning BO methods in various benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PDFA Distillation via String Probability Queries 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18328v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18328v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Baumgartner, Sicco Verwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Probabilistic deterministic finite automata (PDFA) are discrete event systems
modeling conditional probabilities over languages: Given an already seen
sequence of tokens they return the probability of tokens of interest to appear
next. These types of models have gained interest in the domain of explainable
machine learning, where they are used as surrogate models for neural networks
trained as language models. In this work we present an algorithm to distill
PDFA from neural networks. Our algorithm is a derivative of the L# algorithm
and capable of learning PDFA from a new type of query, in which the algorithm
infers conditional probabilities from the probability of the queried string to
occur. We show its effectiveness on a recent public dataset by distilling PDFA
from a set of trained neural networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>LearnAUT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative AI-Driven Human Digital Twin in IoT-Healthcare: A
  Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.13699v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.13699v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayuan Chen, You Shi, Changyan Yi, Hongyang Du, Jiawen Kang, Dusit Niyato
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Internet of things (IoT) can significantly enhance the quality of human
life, specifically in healthcare, attracting extensive attentions to
IoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as
an innovative paradigm that can comprehensively characterize the replication of
the individual human body in the digital world and reflect its physical status
in real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the
application of healthcare monitoring by acting as a versatile and vivid human
digital testbed, simulating the outcomes and guiding the practical treatments.
However, successfully establishing HDT requires high-fidelity virtual modeling
and strong information interactions but possibly with scarce, biased and noisy
data. Fortunately, a recent popular technology called generative artificial
intelligence (GAI) may be a promising solution because it can leverage advanced
AI algorithms to automatically create, manipulate, and modify valuable while
diverse data. This survey particularly focuses on the implementation of
GAI-driven HDT in IoT-healthcare. We start by introducing the background of
IoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the
fundamental techniques and present the overall framework of GAI-driven HDT.
After that, we explore the realization of GAI-driven HDT in detail, including
GAI-enabled data acquisition, communication, data management, digital modeling,
and data analysis. Besides, we discuss typical IoT-healthcare applications that
can be revolutionized by GAI-driven HDT, namely personalized health monitoring
and diagnosis, personalized prescription, and personalized rehabilitation.
Finally, we conclude this survey by highlighting some future research
directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Networked Communication for Decentralised Agents in Mean-Field Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.02766v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.02766v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Benjamin, Alessandro Abate
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce networked communication to the mean-field game framework, in
particular to oracle-free settings where $N$ decentralised agents learn along a
single, non-episodic run of the empirical system. We prove that our
architecture, with only a few reasonable assumptions about network structure,
has sample guarantees bounded between those of the centralised- and
independent-learning cases. We discuss how the sample guarantees of the three
theoretical algorithms do not actually result in practical convergence. We
therefore show that in practical settings where the theoretical parameters are
not observed (leading to poor estimation of the Q-function), our communication
scheme significantly accelerates convergence over the independent case (and
often even the centralised case), without relying on the assumption of a
centralised learner. We contribute further practical enhancements to all three
theoretical algorithms, allowing us to present their first empirical
demonstrations. Our experiments confirm that we can remove several of the
theoretical assumptions of the algorithms, and display the empirical
convergence benefits brought by our new networked communication. We
additionally show that the networked approach has significant advantages, over
both the centralised and independent alternatives, in terms of robustness to
unexpected learning failures and to changes in population size.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Kandinsky 3.0 Technical Report 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03511v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03511v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vladimir Arkhipkin, Andrei Filatov, Viacheslav Vasilev, Anastasia Maltseva, Said Azizov, Igor Pavlov, Julia Agafonova, Andrey Kuznetsov, Denis Dimitrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Kandinsky 3.0, a large-scale text-to-image generation model based
on latent diffusion, continuing the series of text-to-image Kandinsky models
and reflecting our progress to achieve higher quality and realism of image
generation. In this report we describe the architecture of the model, the data
collection procedure, the training technique, and the production system for
user interaction. We focus on the key components that, as we have identified as
a result of a large number of experiments, had the most significant impact on
improving the quality of our model compared to the others. We also describe
extensions and applications of our model, including super resolution,
inpainting, image editing, image-to-video generation, and a distilled version
of Kandinsky 3.0 - Kandinsky 3.1, which does inference in 4 steps of the
reverse process and 20 times faster without visual quality decrease. By
side-by-side human preferences comparison, Kandinsky becomes better in text
understanding and works better on specific domains. The code is available at
https://github.com/ai-forever/Kandinsky-3
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://ai-forever.github.io/Kandinsky-3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Straggler-Resilient Differentially-Private Decentralized Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.03080v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.03080v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yauhen Yakimenka, Chung-Wei Weng, Hsuan-Yin Lin, Eirik Rosnes, Jörg Kliewer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the straggler problem in decentralized learning over a logical
ring while preserving user data privacy. Especially, we extend the recently
proposed framework of differential privacy (DP) amplification by
decentralization by Cyffers and Bellet to include overall training
latency--comprising both computation and communication latency. Analytical
results on both the convergence speed and the DP level are derived for both a
skipping scheme (which ignores the stragglers after a timeout) and a baseline
scheme that waits for each node to finish before the training continues. A
trade-off between overall training latency, accuracy, and privacy,
parameterized by the timeout of the skipping scheme, is identified and
empirically validated for logistic regression on a real-world dataset and for
image classification using the MNIST and CIFAR-10 datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in the IEEE Journal on Selected Areas in Information Theory
  (special issue on Information-Theoretic Methods for Trustworthy and Reliable
  Machine Learning)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16783v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16783v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rishabh Maheshwary, Vikas Yadav, Hoang Nguyen, Khyati Mahajan, Sathwik Tejaswi Madhusudhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction finetuning (IFT) is critical for aligning Large Language Models
(LLMs) to follow instructions. While many effective IFT datasets have been
introduced recently, they predominantly focus on high-resource languages like
English. To better align LLMs across a broad spectrum of languages and tasks,
we propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,
Multi-turn instruction finetuning dataset, called M2Lingual. It is constructed
by first selecting a diverse set of seed examples and then utilizing the
proposed Evol taxonomy to convert these seeds into complex and challenging
multi-turn instructions. We demonstrate the effectiveness of M2Lingual by
training LLMs of varying sizes and showcasing the enhanced performance across a
diverse set of languages. We contribute the 2 step Evol taxonomy with the
guided generation code: https://github.com/ServiceNow/M2Lingual, as well as the
first fully synthetic, general and task-oriented, multi-turn, multilingual
dataset built with Evol - M2Lingual:
https://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K
total IFT pairs, covering 70 languages and 17+ NLP tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>39 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Rate of Kernel Regression in Large Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.04268v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.04268v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihao Lu, Haobo Zhang, Yicheng Li, Manyun Xu, Qian Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We perform a study on kernel regression for large-dimensional data (where the
sample size $n$ is polynomially depending on the dimension $d$ of the samples,
i.e., $n\asymp d^{\gamma}$ for some $\gamma >0$ ). We first build a general
tool to characterize the upper bound and the minimax lower bound of kernel
regression for large dimensional data through the Mendelson complexity
$\varepsilon_{n}^{2}$ and the metric entropy $\bar{\varepsilon}_{n}^{2}$
respectively. When the target function falls into the RKHS associated with a
(general) inner product model defined on $\mathbb{S}^{d}$, we utilize the new
tool to show that the minimax rate of the excess risk of kernel regression is
$n^{-1/2}$ when $n\asymp d^{\gamma}$ for $\gamma =2, 4, 6, 8, \cdots$. We then
further determine the optimal rate of the excess risk of kernel regression for
all the $\gamma>0$ and find that the curve of optimal rate varying along
$\gamma$ exhibits several new phenomena including the multiple descent behavior
and the periodic plateau behavior. As an application, For the neural tangent
kernel (NTK), we also provide a similar explicit description of the curve of
optimal rate. As a direct corollary, we know these claims hold for wide neural
networks as well.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity
  Text Embeddings Through Self-Knowledge Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03216v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03216v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, Zheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a new embedding model, called M3-Embedding, which
is distinguished for its versatility in Multi-Linguality, Multi-Functionality,
and Multi-Granularity. It can support more than 100 working languages, leading
to new state-of-the-art performances on multi-lingual and cross-lingual
retrieval tasks. It can simultaneously perform the three common retrieval
functionalities of embedding model: dense retrieval, multi-vector retrieval,
and sparse retrieval, which provides a unified model foundation for real-world
IR applications. It is able to process inputs of different granularities,
spanning from short sentences to long documents of up to 8192 tokens. The
effective training of M3-Embedding involves the following technical
contributions. We propose a novel self-knowledge distillation approach, where
the relevance scores from different retrieval functionalities can be integrated
as the teacher signal to enhance the training quality. We also optimize the
batching strategy, enabling a large batch size and high training throughput to
ensure the discriminativeness of embeddings. To the best of our knowledge,
M3-Embedding is the first embedding model which realizes such a strong
versatility. The model and code will be publicly available at
https://github.com/FlagOpen/FlagEmbedding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatic Data Curation for <span class="highlight-title">Self-Supervised</span> Learning: A Clustering-Based
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15613v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15613v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huy V. Vo, Vasil Khalidov, Timothée Darcet, Théo Moutakanni, Nikita Smetanin, Marc Szafraniec, Hugo Touvron, Camille Couprie, Maxime Oquab, Armand Joulin, Hervé Jégou, Patrick Labatut, Piotr Bojanowski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised features are the cornerstone of modern machine learning
systems. They are typically pre-trained on data collections whose construction
and curation typically require extensive human effort. This manual process has
some limitations similar to those encountered in supervised learning, e.g., the
crowd-sourced selection of data is costly and time-consuming, preventing
scaling the dataset size. In this work, we consider the problem of automatic
curation of high-quality datasets for self-supervised pre-training. We posit
that such datasets should be large, diverse and balanced, and propose a
clustering-based approach for building ones satisfying all these criteria. Our
method involves successive and hierarchical applications of $k$-means on a
large and diverse data repository to obtain clusters that distribute uniformly
among data concepts, followed by a hierarchical, balanced sampling step from
these clusters. Extensive experiments on three different data domains including
web-based images, satellite images and text show that features trained on our
automatically curated datasets outperform those trained on uncurated data while
being on par or better than ones trained on manually curated data. Code is
available at https://github.com/facebookresearch/ssl-data-curation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Enhanced Clustering for News Event Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10552v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10552v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adane Nega Tarekegn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The news landscape is continuously evolving, with an ever-increasing volume
of information from around the world. Automated event detection within this
vast data repository is essential for monitoring, identifying, and categorizing
significant news occurrences across diverse platforms. This paper presents an
event detection framework that leverages Large Language Models (LLMs) combined
with clustering analysis to detect news events from the Global Database of
Events, Language, and Tone (GDELT). The framework enhances event clustering
through both pre-event detection tasks (keyword extraction and text embedding)
and post-event detection tasks (event summarization and topic labelling). We
also evaluate the impact of various textual embeddings on the quality of
clustering outcomes, ensuring robust news categorization. Additionally, we
introduce a novel Cluster Stability Assessment Index (CSAI) to assess the
validity and robustness of clustering results. CSAI utilizes multiple feature
vectors to provide a new way of measuring clustering quality. Our experiments
indicate that the use of LLM embedding in the event detection framework has
significantly improved the results, demonstrating greater robustness in terms
of CSAI scores. Moreover, post-event detection tasks generate meaningful
insights, facilitating effective interpretation of event clustering results.
Overall, our experimental results indicate that the proposed framework offers
valuable insights and could enhance the accuracy in news analysis and
reporting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Effort and Size Estimation in Software Projects with Large Language
  Model-based Intelligent Interfaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07158v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07158v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Claudionor N. Coelho Jr, Hanchen Xiong, Tushar Karayil, Sree Koratala, Rex Shang, Jacob Bollinger, Mohamed Shabar, Syam Nair
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancement of Large Language Models (LLM) has also resulted in an
equivalent proliferation in its applications. Software design, being one, has
gained tremendous benefits in using LLMs as an interface component that extends
fixed user stories. However, inclusion of LLM-based AI agents in software
design often poses unexpected challenges, especially in the estimation of
development efforts. Through the example of UI-based user stories, we provide a
comparison against traditional methods and propose a new way to enhance
specifications of natural language-based questions that allows for the
estimation of development effort by taking into account data sources,
interfaces and algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SampleAttention: Near-Lossless Acceleration of Long Context LLM
  Inference with Adaptive Structured Sparse Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15486v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15486v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianchao Zhu, Jiangfei Duan, Chang Chen, Siran Liu, Xiuhong Li, Guanyu Feng, Xin Lv, Huanqi Cao, Xiao Chuanfu, Xingcheng Zhang, Dahua Lin, Chao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) now support extremely long context windows, but
the quadratic complexity of vanilla attention results in significantly long
Time-to-First-Token (TTFT) latency. Existing approaches to address this
complexity require additional pretraining or finetuning, and often sacrifice
model accuracy. In this paper, we first provide both theoretical and empirical
foundations for near-lossless sparse attention. We find dynamically capturing
head-specific sparse patterns at runtime with low overhead is crucial. To
address this, we propose SampleAttention, an adaptive structured and
near-lossless sparse attention. Leveraging observed significant sparse
patterns, SampleAttention attends to a fixed percentage of adjacent tokens to
capture local window patterns, and employs a two-stage query-guided key-value
filtering approach, which adaptively select a minimum set of key-values with
low overhead, to capture column stripe patterns. Comprehensive evaluations show
that SampleAttention can seamlessly replace vanilla attention in off-the-shelf
LLMs with nearly no accuracy loss, and reduces TTFT by up to $2.42\times$
compared with FlashAttention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ULLER: A Unified Language for Learning and Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emile van Krieken, Samy Badreddine, Robin Manhaeve, Eleonora Giunchiglia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of neuro-symbolic artificial intelligence (NeSy), which combines
learning and reasoning, has recently experienced significant growth. There now
are a wide variety of NeSy frameworks, each with its own specific language for
expressing background knowledge and how to relate it to neural networks. This
heterogeneity hinders accessibility for newcomers and makes comparing different
NeSy frameworks challenging. We propose a language for NeSy, which we call
ULLER, a Unfied Language for LEarning and Reasoning. ULLER encompasses a wide
variety of settings, while ensuring that knowledge described in it can be used
in existing NeSy systems. ULLER has a first-order logic syntax specialised for
NeSy for which we provide example semantics including classical FOL, fuzzy
logic, and probabilistic logic. We believe ULLER is a first step towards making
NeSy research more accessible and comparable, paving the way for libraries that
streamline training and evaluation across a multitude of semantics, knowledge
bases, and NeSy systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NeSy 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Position: Explain to Question not to Justify 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13914v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13914v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Przemyslaw Biecek, Wojciech Samek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explainable Artificial Intelligence (XAI) is a young but very promising field
of research. Unfortunately, the progress in this field is currently slowed down
by divergent and incompatible goals. We separate various threads tangled within
the area of XAI into two complementary cultures of human/value-oriented
explanations (BLUE XAI) and model/validation-oriented explanations (RED XAI).
This position paper argues that the area of RED XAI is currently
under-explored, i.e., more methods for explainability are desperately needed to
question models (e.g., extract knowledge from well-performing models as well as
spotting and fixing bugs in faulty models), and the area of RED XAI hides great
opportunities and potential for important research necessary to ensure the
safety of AI systems. We conclude this paper by presenting promising challenges
in this area.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatic Regularization for Linear MMSE Filters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.06560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.06560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Gomes de Pinho Zanco, Leszek Szczecinski, Jacob Benesty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we consider the problem of regularization in the design of
minimum mean square error (MMSE) linear filters. Using the relationship with
statistical machine learning methods, using a Bayesian approach, the
regularization parameter is found from the observed signals in a simple and
automatic manner. The proposed approach is illustrated in system identification
and beamforming examples, where the automatic regularization is shown to yield
near-optimal results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SciBench: Evaluating College-Level Scientific Problem-Solving Abilities
  of Large Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.10635v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.10635v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Arjun R. Loomba, Shichang Zhang, Yizhou Sun, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most of the existing Large Language Model (LLM) benchmarks on scientific
problem reasoning focus on problems grounded in high-school subjects and are
confined to elementary algebraic operations. To systematically examine the
reasoning capabilities required for solving complex scientific problems, we
introduce an expansive benchmark suite SciBench for LLMs. SciBench contains a
carefully curated dataset featuring a range of collegiate-level scientific
problems from mathematics, chemistry, and physics domains. Based on the
dataset, we conduct an in-depth benchmarking study of representative
open-source and proprietary LLMs with various prompting strategies. The results
reveal that the current LLMs fall short of delivering satisfactory performance,
with the best overall score of merely 43.22%. Furthermore, through a detailed
user study, we categorize the errors made by LLMs into ten problem-solving
abilities. Our analysis indicates that no single prompting strategy
significantly outperforms the others and some strategies that demonstrate
improvements in certain problem-solving skills could result in declines in
other skills. We envision that SciBench will catalyze further developments in
the reasoning abilities of LLMs, thereby ultimately contributing to scientific
research and discovery.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Active Preference Learning for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.08114v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.08114v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Muldrew, Peter Hayes, Mingtian Zhang, David Barber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) become more capable, fine-tuning techniques
for aligning with human intent are increasingly important. A key consideration
for aligning these models is how to most effectively use human resources, or
model resources in the case where LLMs themselves are used as oracles.
Reinforcement learning from Human or AI preferences (RLHF/RLAIF) is the most
prominent example of such a technique, but is complex and often unstable.
Direct Preference Optimization (DPO) has recently been proposed as a simpler
and more stable alternative. In this work, we develop an active learning
strategy for DPO to make better use of preference labels. We propose a
practical acquisition function for prompt/completion pairs based on the
predictive entropy of the language model and a measure of certainty of the
implicit preference model optimized by DPO. We demonstrate how our approach
improves both the rate of learning and final performance of fine-tuning on
pairwise preference data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 5 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Logic Tree Extraction for Event Sequence Explanation from LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01124v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01124v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zitao Song, Chao Yang, Chaojie Wang, Bo An, Shuang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern high-stakes systems, such as healthcare or robotics, often generate
vast streaming event sequences. Our goal is to design an efficient,
plug-and-play tool to elicit logic tree-based explanations from Large Language
Models (LLMs) to provide customized insights into each observed event sequence.
Built on the temporal point process model for events, our method employs the
likelihood function as a score to evaluate generated logic trees. We propose an
amortized Expectation-Maximization (EM) learning framework and treat the logic
tree as latent variables. In the E-step, we evaluate the posterior distribution
over the latent logic trees using an LLM prior and the likelihood of the
observed event sequences. LLM provides a high-quality prior for the latent
logic trees, however, since the posterior is built over a discrete
combinatorial space, we cannot get the closed-form solution. We propose to
generate logic tree samples from the posterior using a learnable GFlowNet,
which is a diversity-seeking generator for structured discrete variables. The
M-step employs the generated logic rules to approximate marginalization over
the posterior, facilitating the learning of model parameters and refining the
tunable LLM prior parameters. In the online setting, our locally built,
lightweight model will iteratively extract the most relevant rules from LLMs
for each sequence using only a few iterations. Empirical demonstrations
showcase the promising performance and adaptability of our framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QQQ: Quality Quattuor-Bit Quantization for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09904v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09904v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ying Zhang, Peng Zhang, Mincong Huang, Jingyang Xiang, Yujie Wang, Chao Wang, Yineng Zhang, Lei Yu, Chuan Liu, Wei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quantization is a proven effective method for compressing large language
models. Although popular techniques like W8A8 and W4A16 effectively maintain
model performance, they often fail to concurrently speed up the prefill and
decoding stages of inference. W4A8 is a promising strategy to accelerate both
of them while usually leads to a significant performance degradation. To
address these issues, we present QQQ, a Quality Quattuor-bit Quantization
method with 4-bit weights and 8-bit activations. QQQ employs adaptive smoothing
and Hessian-based compensation, significantly enhancing the performance of
quantized models without extensive training. Furthermore, we meticulously
engineer W4A8 GEMM kernels to increase inference speed. Our specialized
per-channel W4A8 GEMM and per-group W4A8 GEMM achieve impressive speed
increases of 3.67$\times$ and 3.29 $\times$ over FP16 GEMM. Our extensive
experiments show that QQQ achieves performance on par with existing
state-of-the-art LLM quantization methods while significantly accelerating
inference, achieving speed boosts up to 2.24 $\times$, 2.10$\times$, and
1.25$\times$ compared to FP16, W8A8, and W4A16, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MOYU: A Theoretical Study on Massive Over-activation Yielded Uplifts in
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chi Ma, Mincong Huang, Chao Wang, Yujie Wang, Lei Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Massive Over-activation Yielded Uplifts(MOYU) is an inherent property of
large language models, and dynamic activation(DA) based on the MOYU property is
a clever yet under-explored strategy designed to accelerate inference in these
models. Existing methods that utilize MOYU often face a significant 'Impossible
Trinity': struggling to simultaneously maintain model performance, enhance
inference speed, and extend applicability across various architectures. Due to
the theoretical ambiguities surrounding MOYU, this paper elucidates the root
cause of the MOYU property and outlines the mechanisms behind two primary
limitations encountered by current DA methods: 1) history-related activation
uncertainty, and 2) semantic-irrelevant activation inertia. Our analysis not
only underscores the limitations of current dynamic activation strategies
within large-scale LLaMA models but also proposes opportunities for refining
the design of future sparsity schemes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Logical Closed Loop: Uncovering Object Hallucinations in Large
  Vision-Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11622v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11622v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfei Wu, Qiang Liu, Ding Wang, Jinghao Zhang, Shu Wu, Liang Wang, Tieniu Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object hallucination has been an Achilles' heel which hinders the broader
applications of large vision-language models (LVLMs). Object hallucination
refers to the phenomenon that the LVLMs claim non-existent objects in the
image. To mitigate the object hallucinations, instruction tuning and external
model-based detection methods have been proposed, which either require
large-scare computational resources or depend on the detection result of
external models. However, there remains an under-explored field to utilize the
LVLM itself to alleviate object hallucinations. In this work, we adopt the
intuition that the LVLM tends to respond logically consistently for existent
objects but inconsistently for hallucinated objects. Therefore, we propose a
Logical Closed Loop-based framework for Object Hallucination Detection and
Mitigation, namely LogicCheckGPT. In specific, we devise logical consistency
probing to raise questions with logical correlations, inquiring about
attributes from objects and vice versa. Whether their responses can form a
logical closed loop serves as an indicator of object hallucination. As a
plug-and-play method, it can be seamlessly applied to all existing LVLMs.
Comprehensive experiments conducted on three benchmarks across four LVLMs have
demonstrated significant improvements brought by our method, indicating its
effectiveness and generality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accept to ACL 2024; 19 Pages, 15 Figures, 6 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sequential Model for Predicting Patient Adherence in Subcutaneous
  Immunotherapy for Allergic Rhinitis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.11447v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.11447v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yin Li, Yu Xiong, Wenxin Fan, Kai Wang, Qingqing Yu, Liping Si, Patrick van der Smagt, Jun Tang, Nutan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal
treatment of allergic rhinitis (AR). How to enhance the adherence of patients
to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in
the management of AIT. This study aims to leverage novel machine learning
models to precisely predict the risk of non-adherence of AR patients and
related local symptom scores in three years SCIT.
  Methods: The research develops and analyzes two models, sequential
latent-variable model (SLVM) of Sequential Latent Actor-Critic (SLAC) and Long
Short-Term Memory (LSTM) evaluating them based on scoring and adherence
prediction capabilities.
  Results: Excluding the biased samples at the first time step, the predictive
adherence accuracy of the SLAC models is from 60\% to 72\%, and for LSTM
models, it is 66\% to 84\%, varying according to the time steps. The range of
Root Mean Square Error (RMSE) for SLAC models is between 0.93 and 2.22, while
for LSTM models it is between 1.09 and 1.77. Notably, these RMSEs are
significantly lower than the random prediction error of 4.55.
  Conclusion: We creatively apply sequential models in the long-term management
of SCIT with promising accuracy in the prediction of SCIT nonadherence in AR
patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in
score prediction for patients undergoing SCIT for AR. The state-action-based
SLAC adds flexibility, presenting a novel and effective approach for managing
long-term AIT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Frontiers in Pharmacology, research topic: Methods and Metrics to
  Measure Medication Adherence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Empowering Interdisciplinary Insights with Dynamic Graph Embedding
  Trajectories 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17963v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17963v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqiao Jin, Andrew Zhao, Yeon-Chang Lee, Meng Ye, Ajay Divakaran, Srijan Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We developed DyGETViz, a novel framework for effectively visualizing dynamic
graphs (DGs) that are ubiquitous across diverse real-world systems. This
framework leverages recent advancements in discrete-time dynamic graph (DTDG)
models to adeptly handle the temporal dynamics inherent in dynamic graphs.
DyGETViz effectively captures both micro- and macro-level structural shifts
within these graphs, offering a robust method for representing complex and
massive dynamic graphs. The application of DyGETViz extends to a diverse array
of domains, including ethology, epidemiology, finance, genetics, linguistics,
communication studies, social studies, and international relations. Through its
implementation, DyGETViz has revealed or confirmed various critical insights.
These include the diversity of content sharing patterns and the degree of
specialization within online communities, the chronological evolution of
lexicons across decades, and the distinct trajectories exhibited by
aging-related and non-related genes. Importantly, DyGETViz enhances the
accessibility of scientific findings to non-domain experts by simplifying the
complexities of dynamic graphs. Our framework is released as an open-source
Python package for use across diverse disciplines. Our work not only addresses
the ongoing challenges in visualizing and analyzing DTDG models but also
establishes a foundational framework for future investigations into dynamic
graph representation and analysis across various disciplines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging Knowledge Distillation for Lightweight Skin Cancer
  Classification: Balancing Accuracy and Computational Efficiency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17051v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17051v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niful Islam, Khan Md Hasib, Fahmida Akter Joti, Asif Karim, Sami Azam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Skin cancer is a major concern to public health, accounting for one-third of
the reported cancers. If not detected early, the cancer has the potential for
severe consequences. Recognizing the critical need for effective skin cancer
classification, we address the limitations of existing models, which are often
too large to deploy in areas with limited computational resources. In response,
we present a knowledge distillation based approach for creating a lightweight
yet high-performing classifier. The proposed solution involves fusing three
models, namely ResNet152V2, ConvNeXtBase, and ViT Base, to create an effective
teacher model. The teacher model is then employed to guide a lightweight
student model of size 2.03 MB. This student model is further compressed to
469.77 KB using 16-bit quantization, enabling smooth incorporation into edge
devices. With six-stage image preprocessing, data augmentation, and a rigorous
ablation study, the model achieves an impressive accuracy of 98.75% on the
HAM10000 dataset and 98.94% on the Kaggle dataset in classifying benign and
malignant skin cancers. With its high accuracy and compact size, our model
appears to be a potential choice for accurate skin cancer classification,
particularly in resource-constrained settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with
  Flowcharts <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for visual question answering lack in visual grounding
and complexity, particularly in evaluating spatial reasoning skills. We
introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of
visual question-answering multimodal language models in reasoning with
flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and
human-verified flowchart images from three distinct content sources, along with
22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks,
including information localization, decision-making, and logical progression.
We conduct a thorough baseline evaluation on a suite of both open-source and
proprietary multimodal language models using various strategies, followed by an
analysis of directional bias. The results underscore the benchmark's potential
as a vital tool for advancing the field of multimodal modeling, providing a
focused and challenging environment for enhancing model performance in visual
and logical reasoning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ACL 2024 (Findings), 21 pages, 7 figures, 9 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transcendence: Generative Models Can Outperform The Experts That Train
  Them 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11741v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11741v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edwin Zhang, Vincent Zhu, Naomi Saphra, Anat Kleiman, Benjamin L. Edelman, Milind Tambe, Sham M. Kakade, Eran Malach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models are trained with the simple objective of imitating the
conditional probability distribution induced by the data they are trained on.
Therefore, when trained on data generated by humans, we may not expect the
artificial model to outperform the humans on their original objectives. In this
work, we study the phenomenon of transcendence: when a generative model
achieves capabilities that surpass the abilities of the experts generating its
data. We demonstrate transcendence by training an autoregressive transformer to
play chess from game transcripts, and show that the trained model can sometimes
achieve better performance than all players in the dataset. We theoretically
prove that transcendence can be enabled by low-temperature sampling, and
rigorously assess this claim experimentally. Finally, we discuss other sources
of transcendence, laying the groundwork for future investigation of this
phenomenon in a broader setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code, models, and data at https://transcendence.eddie.win</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Behavior Generation with Latent Actions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03181v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03181v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seungjae Lee, Yibin Wang, Haritheja Etukuru, H. Jin Kim, Nur Muhammad Mahi Shafiullah, Lerrel Pinto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative modeling of complex behaviors from labeled datasets has been a
longstanding problem in decision making. Unlike language or image generation,
decision making requires modeling actions - continuous-valued vectors that are
multimodal in their distribution, potentially drawn from uncurated sources,
where generation errors can compound in sequential prediction. A recent class
of models called Behavior Transformers (BeT) addresses this by discretizing
actions using k-means clustering to capture different modes. However, k-means
struggles to scale for high-dimensional action spaces or long sequences, and
lacks gradient information, and thus BeT suffers in modeling long-range
actions. In this work, we present Vector-Quantized Behavior Transformer
(VQ-BeT), a versatile model for behavior generation that handles multimodal
action prediction, conditional generation, and partial observations. VQ-BeT
augments BeT by tokenizing continuous actions with a hierarchical vector
quantization module. Across seven environments including simulated
manipulation, autonomous driving, and robotics, VQ-BeT improves on
state-of-the-art models such as BeT and Diffusion Policies. Importantly, we
demonstrate VQ-BeT's improved ability to capture behavior modes while
accelerating inference speed 5x over Diffusion Policies. Videos and code can be
found https://sjlee.cc/vq-bet
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github repo: https://github.com/jayLEE0301/vq_bet_official</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Kernel vs. Kernel: Exploring How the Data Structure Affects Neural
  Collapse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02105v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02105v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vignesh Kothapalli, Tom Tirer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, a vast amount of literature has focused on the "Neural Collapse"
(NC) phenomenon, which emerges when training neural network (NN) classifiers
beyond the zero training error point. The core component of NC is the decrease
in the within class variability of the network's deepest features, dubbed as
NC1. The theoretical works that study NC are typically based on simplified
unconstrained features models (UFMs) that mask any effect of the data on the
extent of collapse. In this paper, we provide a kernel-based analysis that does
not suffer from this limitation. First, given a kernel function, we establish
expressions for the traces of the within- and between-class covariance matrices
of the samples' features (and consequently an NC1 metric). Then, we turn to
focus on kernels associated with shallow NNs. First, we consider the NN
Gaussian Process kernel (NNGP), associated with the network at initialization,
and the complement Neural Tangent Kernel (NTK), associated with its training in
the "lazy regime". Interestingly, we show that the NTK does not represent more
collapsed features than the NNGP for prototypical data models. As NC emerges
from training, we then consider an alternative to NTK: the recently proposed
adaptive kernel, which generalizes NNGP to model the feature mapping learned
from the training data. Contrasting our NC1 analysis for these two kernels
enables gaining insights into the effect of data distribution on the extent of
collapse, which are empirically aligned with the behavior observed with
practical training of NNs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AIGB: Generative Auto-bidding via Diffusion Modeling <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16141v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16141v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayan Guo, Yusen Huo, Zhilin Zhang, Tianyu Wang, Chuan Yu, Jian Xu, Yan Zhang, Bo Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Auto-bidding plays a crucial role in facilitating online advertising by
automatically providing bids for advertisers. Reinforcement learning (RL) has
gained popularity for auto-bidding. However, most current RL auto-bidding
methods are modeled through the Markovian Decision Process (MDP), which assumes
the Markovian state transition. This assumption restricts the ability to
perform in long horizon scenarios and makes the model unstable when dealing
with highly random online advertising environments. To tackle this issue, this
paper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding
through generative modeling. In this paradigm, we propose DiffBid, a
conditional diffusion modeling approach for bid generation. DiffBid directly
models the correlation between the return and the entire trajectory,
effectively avoiding error propagation across time steps in long horizons.
Additionally, DiffBid offers a versatile approach for generating trajectories
that maximize given targets while adhering to specific constraints. Extensive
experiments conducted on the real-world dataset and online A/B test on Alibaba
advertising platform demonstrate the effectiveness of DiffBid, achieving 2.81%
increase in GMV and 3.36% increase in ROI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Active Sequential Two-Sample Testing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.12616v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.12616v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weizhi Li, Prad Kadambi, Pouria Saidi, Karthikeyan Natesan Ramamurthy, Gautam Dasarathy, Visar Berisha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A two-sample hypothesis test is a statistical procedure used to determine
whether the distributions generating two samples are identical. We consider the
two-sample testing problem in a new scenario where the sample measurements (or
sample features) are inexpensive to access, but their group memberships (or
labels) are costly. To address the problem, we devise the first \emph{active
sequential two-sample testing framework} that not only sequentially but also
\emph{actively queries}. Our test statistic is a likelihood ratio where one
likelihood is found by maximization over all class priors, and the other is
provided by a probabilistic classification model. The classification model is
adaptively updated and used to predict where the (unlabelled) features have a
high dependency on labels; labeling the ``high-dependency'' features leads to
the increased power of the proposed testing framework. In theory, we provide
the proof that our framework produces an \emph{anytime-valid} $p$-value. In
addition, we characterize the proposed framework's gain in testing power by
analyzing the mutual information between the feature and label variables in
asymptotic and finite-sample scenarios. In practice, we introduce an
instantiation of our framework and evaluate it using several experiments; the
experiments on the synthetic, MNIST, and application-specific datasets
demonstrate that the testing power of the instantiated active sequential test
significantly increases while the Type I error is under control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FAdam: Adam is a natural gradient optimizer using diagonal empirical
  Fisher information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12807v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12807v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongseong Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper establishes a mathematical foundation for the Adam optimizer,
elucidating its connection to natural gradient descent through Riemannian and
information geometry. We rigorously analyze the diagonal empirical Fisher
information matrix (FIM) in Adam, clarifying all detailed approximations and
advocating for the use of log probability functions as loss, which should be
based on discrete distributions, due to the limitations of empirical FIM. Our
analysis uncovers flaws in the original Adam algorithm, leading to proposed
corrections such as enhanced momentum calculations, adjusted bias corrections,
adaptive epsilon, and gradient clipping. We refine the weight decay term based
on our theoretical framework. Our modified algorithm, Fisher Adam (FAdam),
demonstrates superior performance across diverse domains including LLM, ASR,
and VQ-VAE, achieving state-of-the-art results in ASR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 4 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative Autoencoding of Dropout Patterns 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.01712v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.01712v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shunta Maeda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a generative model termed Deciphering Autoencoders. In this model,
we assign a unique random dropout pattern to each data point in the training
dataset and then train an autoencoder to reconstruct the corresponding data
point using this pattern as information to be encoded. Even if a completely
random dropout pattern is assigned to each data point regardless of their
similarities, a sufficiently large encoder can smoothly map them to a
low-dimensional latent space to reconstruct individual training data points.
During inference, using a dropout pattern different from those used during
training allows the model to function as a generator. Since the training of
Deciphering Autoencoders relies solely on reconstruction error, it offers more
stable training compared to other generative models. Despite their simplicity,
Deciphering Autoencoders show sampling quality comparable to DCGAN on the
CIFAR-10 dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MeGA: Merging Multiple Independently Trained Neural Networks Based on
  Genetic Algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04607v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04607v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Yun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a novel method for merging the weights of
multiple pre-trained neural networks using a genetic algorithm called MeGA.
Traditional techniques, such as weight averaging and ensemble methods, often
fail to fully harness the capabilities of pre-trained networks. Our approach
leverages a genetic algorithm with tournament selection, crossover, and
mutation to optimize weight combinations, creating a more effective fusion.
This technique allows the merged model to inherit advantageous features from
both parent models, resulting in enhanced accuracy and robustness. Through
experiments on the CIFAR-10 dataset, we demonstrate that our genetic
algorithm-based weight merging method improves test accuracy compared to
individual models and conventional methods. This approach provides a scalable
solution for integrating multiple pre-trained networks across various deep
learning applications. Github is available at:
https://github.com/YUNBLAK/MeGA-Merging-Multiple-Independently-Trained-Neural-Networks-Based-on-Genetic-Algorithm
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Submodular Information Selection for Hypothesis Testing with
  Misclassification Penalties 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.10930v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.10930v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jayanth Bhargav, Mahsa Ghasemi, Shreyas Sundaram
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of selecting an optimal subset of information sources
for a hypothesis testing/classification task where the goal is to identify the
true state of the world from a finite set of hypotheses, based on finite
observation samples from the sources. In order to characterize the learning
performance, we propose a misclassification penalty framework, which enables
nonuniform treatment of different misclassification errors. In a centralized
Bayesian learning setting, we study two variants of the subset selection
problem: (i) selecting a minimum cost information set to ensure that the
maximum penalty of misclassifying the true hypothesis is below a desired bound
and (ii) selecting an optimal information set under a limited budget to
minimize the maximum penalty of misclassifying the true hypothesis. Under
certain assumptions, we prove that the objective (or constraints) of these
combinatorial optimization problems are weak (or approximate) submodular, and
establish high-probability performance guarantees for greedy algorithms.
Further, we propose an alternate metric for information set selection which is
based on the total penalty of misclassification. We prove that this metric is
submodular and establish near-optimal guarantees for the greedy algorithms for
both the information set selection problems. Finally, we present numerical
simulations to validate our theoretical results over several randomly generated
instances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust Model-Based Optimization for Challenging Fitness Landscapes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.13650v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.13650v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saba Ghaffari, Ehsan Saleh, Alexander G. Schwing, Yu-Xiong Wang, Martin D. Burke, Saurabh Sinha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protein design, a grand challenge of the day, involves optimization on a
fitness landscape, and leading methods adopt a model-based approach where a
model is trained on a training set (protein sequences and fitness) and proposes
candidates to explore next. These methods are challenged by sparsity of
high-fitness samples in the training set, a problem that has been in the
literature. A less recognized but equally important problem stems from the
distribution of training samples in the design space: leading methods are not
designed for scenarios where the desired optimum is in a region that is not
only poorly represented in training data, but also relatively far from the
highly represented low-fitness regions. We show that this problem of
"separation" in the design space is a significant bottleneck in existing
model-based optimization tools and propose a new approach that uses a novel VAE
as its search model to overcome the problem. We demonstrate its advantage over
prior methods in robustly finding improved samples, regardless of the imbalance
and separation between low- and high-fitness samples. Our comprehensive
benchmark on real and semi-synthetic protein datasets as well as solution
design for physics-informed neural networks, showcases the generality of our
approach in discrete and continuous design spaces. Our implementation is
available at https://github.com/sabagh1994/PGVAE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Forecasting Electricity Market Signals via Generative AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05743v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05743v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Wang, Qing Zhao, Lang Tong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a generative artificial intelligence approach to
probabilistic forecasting of electricity market signals, such as real-time
locational marginal prices and area control error signals. Inspired by the
Wiener-Kallianpur innovation representation of nonparametric time series, we
propose a weak innovation autoencoder architecture and a novel deep learning
algorithm that extracts the canonical independent and identically distributed
innovation sequence of the time series, from which samples of future time
series are generated. The validity of the proposed approach is established by
proving that, under ideal training conditions, the generated samples have the
same conditional probability distribution as that of the ground truth. Three
applications involving highly dynamic and volatile time series in real-time
market operations are considered: (i) locational marginal price forecasting for
self-scheduled resources such as battery storage participants, (ii)
interregional price spread forecasting for virtual bidders in interchange
markets, and (iii) area control error forecasting for frequency regulations.
Numerical studies based on market data from multiple independent system
operators demonstrate the superior performance of the proposed generative
forecaster over leading classical and modern machine learning techniques under
both probabilistic and point forecasting metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 3D-Mol: A Novel Contrastive Learning Framework for Molecular Property
  Prediction with 3D Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.17366v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.17366v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taojie Kuang, Yiming Ren, Zhixiang Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular property prediction, crucial for early drug candidate screening and
optimization, has seen advancements with deep learning-based methods. While
deep learning-based methods have advanced considerably, they often fall short
in fully leveraging 3D spatial information. Specifically, current molecular
encoding techniques tend to inadequately extract spatial information, leading
to ambiguous representations where a single one might represent multiple
distinct molecules. Moreover, existing molecular modeling methods focus
predominantly on the most stable 3D conformations, neglecting other viable
conformations present in reality. To address these issues, we propose 3D-Mol, a
novel approach designed for more accurate spatial structure representation. It
deconstructs molecules into three hierarchical graphs to better extract
geometric information. Additionally, 3D-Mol leverages contrastive learning for
pretraining on 20 million unlabeled data, treating their conformations with
identical topological structures as weighted positive pairs and contrasting
ones as negatives, based on the similarity of their 3D conformation descriptors
and fingerprints. We compare 3D-Mol with various state-of-the-art baselines on
7 benchmarks and demonstrate our outstanding performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Universal Checkpointing: Efficient and Flexible Checkpointing for Large
  Scale Distributed Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18820v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18820v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Lian, Sam Ade Jacobs, Lev Kurilenko, Masahiro Tanaka, Stas Bekman, Olatunji Ruwase, Minjia Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing checkpointing approaches seem ill-suited for distributed training
even though hardware limitations make model parallelism, i.e., sharding model
state across multiple accelerators, a requirement for model scaling.
Consolidating distributed model state into a single checkpoint unacceptably
slows down training, and is impractical at extreme scales. Distributed
checkpoints, in contrast, are tightly coupled to the model parallelism and
hardware configurations of the training run, and thus unusable on different
configurations. To address this problem, we propose Universal Checkpointing, a
technique that enables efficient checkpoint creation while providing the
flexibility of resuming on arbitrary parallelism strategy and hardware
configurations. Universal Checkpointing unlocks unprecedented capabilities for
large-scale training such as improved resilience to hardware failures through
continued training on remaining healthy hardware, and reduced training time
through opportunistic exploitation of elastic capacity.
  The key insight of Universal Checkpointing is the selection of the optimal
representation in each phase of the checkpointing life cycle: distributed
representation for saving, and consolidated representation for loading. This is
achieved using two key mechanisms. First, the universal checkpoint format,
which consists of a consolidated representation of each model parameter and
metadata for mapping parameter fragments into training ranks of arbitrary
model-parallelism configuration. Second, the universal checkpoint language, a
simple but powerful specification language for converting distributed
checkpoints into the universal checkpoint format. Our evaluation demonstrates
the effectiveness and generality of Universal Checkpointing on state-of-the-art
model architectures and a wide range of parallelism techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Impact of Domain Knowledge and Multi-Modality on Intelligent Molecular
  Property Prediction: A Systematic <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07249v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07249v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taojie Kuang, Pengfei Liu, Zhixiang Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The precise prediction of molecular properties is essential for advancements
in drug development, particularly in virtual screening and compound
optimization. The recent introduction of numerous deep learning-based methods
has shown remarkable potential in enhancing molecular property prediction
(MPP), especially improving accuracy and insights into molecular structures.
Yet, two critical questions arise: does the integration of domain knowledge
augment the accuracy of molecular property prediction and does employing
multi-modal data fusion yield more precise results than unique data source
methods? To explore these matters, we comprehensively review and quantitatively
analyze recent deep learning methods based on various benchmarks. We discover
that integrating molecular information significantly improves molecular
property prediction (MPP) for both regression and classification tasks.
Specifically, regression improvements, measured by reductions in root mean
square error (RMSE), are up to 4.0%, while classification enhancements,
measured by the area under the receiver operating characteristic curve
(ROC-AUC), are up to 1.7%. We also discover that enriching 2D graphs with 1D
SMILES boosts multi-modal learning performance for regression tasks by up to
9.1%, and augmenting 2D graphs with 3D information increases performance for
classification tasks by up to 13.2%, with both enhancements measured using
ROC-AUC. The two consolidated insights offer crucial guidance for future
advancements in drug discovery.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Last Iterate Convergence of Incremental Methods and Applications in
  Continual Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06873v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06873v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xufeng Cai, Jelena Diakonikolas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Incremental gradient and incremental proximal methods are a fundamental class
of optimization algorithms used for solving finite sum problems, broadly
studied in the literature. Yet, without strong convexity, their convergence
guarantees have primarily been established for the ergodic (average) iterate.
Motivated by applications in continual learning, we obtain the first
convergence guarantees for the last iterate of both incremental gradient and
incremental proximal methods, in general convex smooth (for both) and convex
Lipschitz (for the proximal variants) settings. Our oracle complexity bounds
for the last iterate nearly match (i.e., match up to a square-root-log or a log
factor) the best known oracle complexity bounds for the average iterate, for
both classes of methods. We further obtain generalizations of our results to
weighted averaging of the iterates with increasing weights and for randomly
permuted ordering of updates. We study incremental proximal methods as a model
of continual learning with generalization and argue that large amount of
regularization is crucial to preventing catastrophic forgetting. Our results
generalize last iterate guarantees for incremental methods compared to state of
the art, as such results were previously known only for overparameterized
linear models, which correspond to convex quadratic problems with infinitely
many solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mélange: Cost Efficient Large Language Model Serving by Exploiting GPU
  Heterogeneity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14527v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14527v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tyler Griggs, Xiaoxuan Liu, Jiaxiang Yu, Doyoung Kim, Wei-Lin Chiang, Alvin Cheung, Ion Stoica
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly integrated into many online
services, yet they remain cost-prohibitive to deploy due to the requirement of
expensive GPU instances. Prior work has addressed the high cost of LLM serving
by improving the inference engine, but less attention has been given to
selecting the most cost-efficient GPU type(s) for a specific LLM service. There
is a large and growing landscape of GPU types and, within these options, higher
cost does not always lead to increased performance. Instead, through a
comprehensive investigation, we find that three key LLM service characteristics
(request size, request rate, SLO) strongly influence GPU cost efficiency, and
differing GPU types are most cost efficient for differing LLM service settings.
As a result, the most cost-efficient allocation for a given service is
typically a mix of heterogeneous GPU types. Based on this analysis, we
introduce M\'elange, a GPU allocation framework that navigates these diverse
LLM service characteristics and heterogeneous GPU option space to automatically
and efficiently derive the minimal-cost GPU allocation for a given LLM service.
We formulate the GPU allocation task as a cost-aware bin packing problem where
GPUs are bins and items are slices of the service workload. Our formulation's
constraints account for a service's unique characteristics, allowing M\'elange
to be flexible to support diverse service settings and heterogeneity-aware to
adapt the GPU allocation to a specific service. Compared to using only a single
GPU type, M\'elange reduces deployment costs by up to 77% in conversational
settings, 33% in document-based settings, and 51% in a mixed setting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FloorSet -- a VLSI Floorplanning <span class="highlight-title">Dataset</span> with Design Constraints of
  Real-World SoCs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.05480v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.05480v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Uday Mallappa, Hesham Mostafa, Mikhail Galkin, Mariano Phielipp, Somdeb Majumdar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Floorplanning for systems-on-a-chip (SoCs) and its sub-systems is a crucial
and non-trivial step of the physical design flow. It represents a difficult
combinatorial optimization problem. A typical large scale SoC with 120
partitions generates a search-space of nearly 10E250. As novel machine learning
(ML) approaches emerge to tackle such problems, there is a growing need for a
modern benchmark that comprises a large training dataset and performance
metrics that better reflect real-world constraints and objectives compared to
existing benchmarks. To address this need, we present FloorSet -- two
comprehensive datasets of synthetic fixed-outline floorplan layouts that
reflect the distribution of real SoCs. Each dataset has 1M training samples and
100 test samples where each sample is a synthetic floor-plan. FloorSet-Prime
comprises fully-abutted rectilinear partitions and near-optimal wire-length. A
simplified dataset that reflects early design phases, FloorSet-Lite comprises
rectangular partitions, with under 5 percent white-space and near-optimal
wire-length. Both datasets define hard constraints seen in modern design flows
such as shape constraints, edge-affinity, grouping constraints, and
pre-placement constraints. FloorSet is intended to spur fundamental research on
large-scale constrained optimization problems. Crucially, FloorSet alleviates
the core issue of reproducibility in modern ML driven solutions to such
problems. FloorSet is available as an open-source repository for the research
community.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MetaDesigner: Advancing Artistic Typography through AI-Driven,
  User-Centric, and Multilingual WordArt Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19859v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19859v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Qi He, Wangmeng Xiang, Hanyuan Chen, Jin-Peng Lan, Xianhui Lin, Kang Zhu, Bin Luo, Yifeng Geng, Xuansong Xie, Alexander G. Hauptmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MetaDesigner revolutionizes artistic typography synthesis by leveraging the
strengths of Large Language Models (LLMs) to drive a design paradigm centered
around user engagement. At the core of this framework lies a multi-agent system
comprising the Pipeline, Glyph, and Texture agents, which collectively enable
the creation of customized WordArt, ranging from semantic enhancements to the
imposition of complex textures. MetaDesigner incorporates a comprehensive
feedback mechanism that harnesses insights from multimodal models and user
evaluations to refine and enhance the design process iteratively. Through this
feedback loop, the system adeptly tunes hyperparameters to align with
user-defined stylistic and thematic preferences, generating WordArt that not
only meets but exceeds user expectations of visual appeal and contextual
relevance. Empirical validations highlight MetaDesigner's capability to
effectively serve diverse WordArt applications, consistently producing
aesthetically appealing and context-sensitive results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 16 figures, Project:
  https://modelscope.cn/studios/WordArt/WordArt</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MDF: A Dynamic Fusion Model for Multi-modal Fake News Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19776v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19776v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongzhen Lv, Wenzhong Yang, Fuyuan Wei, Jiaren Peng, Haokun Geng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fake news detection has received increasing attention from researchers in
recent years, especially multi-modal fake news detection containing both text
and images.However, many previous works have fed two modal features, text and
image, into a binary classifier after a simple concatenation or attention
mechanism, in which the features contain a large amount of noise inherent in
the data,which in turn leads to intra- and inter-modal uncertainty.In addition,
although many methods based on simply splicing two modalities have achieved
more prominent results, these methods ignore the drawback of holding fixed
weights across modalities, which would lead to some features with higher impact
factors being ignored.To alleviate the above problems, we propose a new dynamic
fusion framework dubbed MDF for fake news detection.As far as we know, it is
the first attempt of dynamic fusion framework in the field of fake news
detection.Specifically, our model consists of two main components:(1) UEM as an
uncertainty modeling module employing a multi-head attention mechanism to model
intra-modal uncertainty; and (2) DFN is a dynamic fusion module based on D-S
evidence theory for dynamically fusing the weights of two modalities, text and
image.In order to present better results for the dynamic fusion framework, we
use GAT for inter-modal uncertainty and weight modeling before DFN.Extensive
experiments on two benchmark datasets demonstrate the effectiveness and
superior performance of the MDF framework.We also conducted a systematic
ablation study to gain insight into our motivation and architectural design.We
make our model publicly available to:https://github.com/CoisiniStar/MDF
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MimicMotion: High-Quality Human Motion Video Generation with
  Confidence-aware Pose Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuang Zhang, Jiaxi Gu, Li-Wen Wang, Han Wang, Junqi Cheng, Yuefeng Zhu, Fangyuan Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, generative artificial intelligence has achieved significant
advancements in the field of image generation, spawning a variety of
applications. However, video generation still faces considerable challenges in
various aspects, such as controllability, video length, and richness of
details, which hinder the application and popularization of this technology. In
this work, we propose a controllable video generation framework, dubbed
MimicMotion, which can generate high-quality videos of arbitrary length
mimicking specific motion guidance. Compared with previous methods, our
approach has several highlights. Firstly, we introduce confidence-aware pose
guidance that ensures high frame quality and temporal smoothness. Secondly, we
introduce regional loss amplification based on pose confidence, which
significantly reduces image distortion. Lastly, for generating long and smooth
videos, we propose a progressive latent fusion strategy. By this means, we can
produce videos of arbitrary length with acceptable resource consumption. With
extensive experiments and user studies, MimicMotion demonstrates significant
improvements over previous approaches in various aspects. Detailed results and
comparisons are available on our project page:
https://tencent.github.io/MimicMotion .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Network Bending of Diffusion Models for Audio-Visual Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luke Dzwonczyk, Carmine Emanuele Cella, David Ban
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we present the first steps towards the creation of a tool which
enables artists to create music visualizations using pre-trained, generative,
machine learning models. First, we investigate the application of network
bending, the process of applying transforms within the layers of a generative
network, to image generation diffusion models by utilizing a range of
point-wise, tensor-wise, and morphological operators. We identify a number of
visual effects that result from various operators, including some that are not
easily recreated with standard image editing tools. We find that this process
allows for continuous, fine-grain control of image generation which can be
helpful for creative applications. Next, we generate music-reactive videos
using Stable Diffusion by passing audio features as parameters to network
bending operators. Finally, we comment on certain transforms which radically
shift the image and the possibilities of learning more about the latent space
of Stable Diffusion based on these transforms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 figures, to be published in the proceedings of the 27th
  International Conference on Digital Audio Effects (DAFx24), for additional
  image and video examples see https://dzluke.github.io/DAFX2024/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Kandinsky 3.0 Technical Report 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03511v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03511v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vladimir Arkhipkin, Andrei Filatov, Viacheslav Vasilev, Anastasia Maltseva, Said Azizov, Igor Pavlov, Julia Agafonova, Andrey Kuznetsov, Denis Dimitrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Kandinsky 3.0, a large-scale text-to-image generation model based
on latent diffusion, continuing the series of text-to-image Kandinsky models
and reflecting our progress to achieve higher quality and realism of image
generation. In this report we describe the architecture of the model, the data
collection procedure, the training technique, and the production system for
user interaction. We focus on the key components that, as we have identified as
a result of a large number of experiments, had the most significant impact on
improving the quality of our model compared to the others. We also describe
extensions and applications of our model, including super resolution,
inpainting, image editing, image-to-video generation, and a distilled version
of Kandinsky 3.0 - Kandinsky 3.1, which does inference in 4 steps of the
reverse process and 20 times faster without visual quality decrease. By
side-by-side human preferences comparison, Kandinsky becomes better in text
understanding and works better on specific domains. The code is available at
https://github.com/ai-forever/Kandinsky-3
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://ai-forever.github.io/Kandinsky-3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Viewport Prediction for Volumetric Video Streaming by Exploring Video
  Saliency and Trajectory Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16462v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16462v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Li, Zhixin Li, Zhi Liu, Pengyuan Zhou, Richang Hong, Qiyue Li, Han Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Volumetric video, also known as hologram video, is a novel medium that
portrays natural content in Virtual Reality (VR), Augmented Reality (AR), and
Mixed Reality (MR). It is expected to be the next-gen video technology and a
prevalent use case for 5G and beyond wireless communication. Considering that
each user typically only watches a section of the volumetric video, known as
the viewport, it is essential to have precise viewport prediction for optimal
performance. However, research on this topic is still in its infancy. In the
end, this paper presents and proposes a novel approach, named Saliency and
Trajectory Viewport Prediction (STVP), which aims to improve the precision of
viewport prediction in volumetric video streaming. The STVP extensively
utilizes video saliency information and viewport trajectory. To our knowledge,
this is the first comprehensive study of viewport prediction in volumetric
video streaming. In particular, we introduce a novel sampling method, Uniform
Random Sampling (URS), to reduce computational complexity while still
preserving video features in an efficient manner. Then we present a saliency
detection technique that incorporates both spatial and temporal information for
detecting static, dynamic geometric, and color salient regions. Finally, we
intelligently fuse saliency and trajectory information to achieve more accurate
viewport prediction. We conduct extensive simulations to evaluate the
effectiveness of our proposed viewport prediction methods using
state-of-the-art volumetric video sequences. The experimental results show the
superiority of the proposed method over existing schemes. The dataset and
source code will be publicly accessible after acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIntRec2.0: A Large-scale Benchmark <span class="highlight-title">Dataset</span> for Multimodal Intent
  Recognition and Out-of-scope Detection in Conversations <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10943v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10943v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanlei Zhang, Xin Wang, Hua Xu, Qianrui Zhou, Kai Gao, Jianhua Su, jinyue Zhao, Wenrui Li, Yanting Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal intent recognition poses significant challenges, requiring the
incorporation of non-verbal modalities from real-world contexts to enhance the
comprehension of human intentions. Existing benchmark datasets are limited in
scale and suffer from difficulties in handling out-of-scope samples that arise
in multi-turn conversational interactions. We introduce MIntRec2.0, a
large-scale benchmark dataset for multimodal intent recognition in multi-party
conversations. It contains 1,245 dialogues with 15,040 samples, each annotated
within a new intent taxonomy of 30 fine-grained classes. Besides 9,304 in-scope
samples, it also includes 5,736 out-of-scope samples appearing in multi-turn
contexts, which naturally occur in real-world scenarios. Furthermore, we
provide comprehensive information on the speakers in each utterance, enriching
its utility for multi-party conversational research. We establish a general
framework supporting the organization of single-turn and multi-turn dialogue
data, modality feature extraction, multimodal fusion, as well as in-scope
classification and out-of-scope detection. Evaluation benchmarks are built
using classic multimodal fusion methods, ChatGPT, and human evaluators. While
existing methods incorporating nonverbal information yield improvements,
effectively leveraging context information and detecting out-of-scope samples
remains a substantial challenge. Notably, large language models exhibit a
significant performance gap compared to humans, highlighting the limitations of
machine learning methods in the cognitive intent understanding task. We believe
that MIntRec2.0 will serve as a valuable resource, providing a pioneering
foundation for research in human-machine conversational interactions, and
significantly facilitating related applications. The full dataset and codes are
available at https://github.com/thuiar/MIntRec2.0.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2024, Long Paper; The abstract is slightly modified
  due to the length limitation</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-06-27T00:00:00Z">2024-06-27</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">62</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PathAlign: A vision-language model for whole slide images in
  histopathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 main pages and 19 pages of supplemental material; 3 main tables, 3
  main figures and 11 supplemental tables, 7 supplemental figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Voices Unheard: NLP Resources and Models for Yorùbá Regional
  Dialects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19564v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19564v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Orevaoghene Ahia, Anuoluwapo Aremu, Diana Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud Abolade, Noah A. Smith, Yulia Tsvetkov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Yor\`ub\'a an African language with roughly 47 million speakers encompasses a
continuum with several dialects. Recent efforts to develop NLP technologies for
African languages have focused on their standard dialects, resulting in
disparities for dialects and varieties for which there are little to no
resources or tools. We take steps towards bridging this gap by introducing a
new high-quality parallel text and speech corpus YOR\`ULECT across three
domains and four regional Yor\`ub\'a dialects. To develop this corpus, we
engaged native speakers, travelling to communities where these dialects are
spoken, to collect text and speech data. Using our newly created corpus, we
conducted extensive experiments on (text) machine translation, automatic speech
recognition, and speech-to-text translation. Our results reveal substantial
performance disparities between standard Yor\`ub\'a and the other dialects
across all tasks. However, we also show that with dialect-adaptive finetuning,
we are able to narrow this gap. We believe our dataset and experimental
analysis will contribute greatly to developing NLP tools for Yor\`ub\'a and its
dialects, and potentially for other African languages, by improving our
understanding of existing challenges and offering a high-quality dataset for
further development. We release YOR\`ULECT dataset and models publicly under an
open license.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking harmless refusals when fine-tuning foundation models <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19552v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19552v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florin Pop, Judd Rosenblatt, Diogo Schwerz de Lucena, Michael Vaiana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the degree to which fine-tuning in Large
Language Models (LLMs) effectively mitigates versus merely conceals undesirable
behavior. Through the lens of semi-realistic role-playing exercises designed to
elicit such behaviors, we explore the response dynamics of LLMs post
fine-tuning interventions. Our methodology involves prompting models for
Chain-of-Thought (CoT) reasoning and analyzing the coherence between the
reasoning traces and the resultant outputs. Notably, we identify a pervasive
phenomenon we term \emph{reason-based deception}, where models either stop
producing reasoning traces or produce seemingly ethical reasoning traces that
belie the unethical nature of their final outputs. We further examine the
efficacy of response strategies (polite refusal versus explicit rebuttal) in
curbing the occurrence of undesired behavior in subsequent outputs of
multi-turn interactions. Our findings reveal that explicit rebuttals
significantly outperform polite refusals in preventing the continuation of
undesired outputs and nearly eliminate reason-based deception, challenging
current practices in model fine-tuning. Accordingly, the two key contributions
of this paper are (1) defining and studying reason-based deception, a new type
of hidden behavior, and (2) demonstrating that rebuttals provide a more robust
response model to harmful requests than refusals, thereby highlighting the need
to reconsider the response strategies in fine-tuning approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2024 AGI Workshop Poster</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Machine-Generated Rationales to Facilitate Social Meaning
  Detection in Conversations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ritam Dutt, Zhen Wu, Kelly Shi, Divyanshu Sheth, Prakhar Gupta, Carolyn Penstein Rose
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a generalizable classification approach that leverages Large
Language Models (LLMs) to facilitate the detection of implicitly encoded social
meaning in conversations. We design a multi-faceted prompt to extract a textual
explanation of the reasoning that connects visible cues to underlying social
meanings. These extracted explanations or rationales serve as augmentations to
the conversational text to facilitate dialogue understanding and transfer. Our
empirical results over 2,340 experimental settings demonstrate the significant
positive impact of adding these rationales. Our findings hold true for
in-domain classification, zero-shot, and few-shot domain transfer for two
different social meaning detection tasks, each spanning two different corpora.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at The Proceedings of the Association for Computational
  Linguistics, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Demarked: A Strategy for Enhanced Abusive Speech Moderation through
  Counterspeech, Detoxification, and Message Management 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19543v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19543v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seid Muhie Yimam, Daryna Dementieva, Tim Fischer, Daniil Moskovskiy, Naquee Rizwan, Punyajoy Saha, Sarthak Roy, Martin Semmann, Alexander Panchenko, Chris Biemann, Animesh Mukherjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite regulations imposed by nations and social media platforms, such as
recent EU regulations targeting digital violence, abusive content persists as a
significant challenge. Existing approaches primarily rely on binary solutions,
such as outright blocking or banning, yet fail to address the complex nature of
abusive speech. In this work, we propose a more comprehensive approach called
Demarcation scoring abusive speech based on four aspect -- (i) severity scale;
(ii) presence of a target; (iii) context scale; (iv) legal scale -- and
suggesting more options of actions like detoxification, counter speech
generation, blocking, or, as a final measure, human intervention. Through a
thorough analysis of abusive speech regulations across diverse jurisdictions,
platforms, and research papers we highlight the gap in preventing measures and
advocate for tailored proactive steps to combat its multifaceted
manifestations. Our work aims to inform future strategies for effectively
addressing abusive speech online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context Matters: An Empirical Study of the Impact of Contextual
  Information in Temporal Question Answering Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19538v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19538v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dan Schumacher, Fatemeh Haji, Tara Grey, Niharika Bandlamudi, Nupoor Karnik, Gagana Uday Kumar, Jason Cho-Yu Chiang, Paul Rad, Nishant Vishwamitra, Anthony Rios
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often struggle with temporal reasoning, crucial
for tasks like historical event analysis and time-sensitive information
retrieval. Despite advancements, state-of-the-art models falter in handling
temporal information, especially when faced with irrelevant or noisy contexts.
This paper addresses this gap by empirically examining the robustness of
temporal question-answering (TQA) systems trained on various context types,
including relevant, irrelevant, slightly altered, and no context. Our findings
indicate that training with a mix of these contexts enhances model robustness
and accuracy. Additionally, we show that the position of context relative to
the question significantly impacts performance, with question-first positioning
yielding better results. We introduce two new context-rich TQA datasets,
ContextAQA and ContextTQE, and provide comprehensive evaluations and guidelines
for training robust TQA models. Our work lays the foundation for developing
reliable and context-aware temporal QA systems, with broader implications for
enhancing LLM robustness against diverse and potentially adversarial
information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Handling Ontology Gaps in Semantic Parsing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19537v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19537v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Bacciu, Marco Damonte, Marco Basaldella, Emilio Monti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The majority of Neural Semantic Parsing (NSP) models are developed with the
assumption that there are no concepts outside the ones such models can
represent with their target symbols (closed-world assumption). This assumption
leads to generate hallucinated outputs rather than admitting their lack of
knowledge. Hallucinations can lead to wrong or potentially offensive responses
to users. Hence, a mechanism to prevent this behavior is crucial to build
trusted NSP-based Question Answering agents. To that end, we propose the
Hallucination Simulation Framework (HSF), a general setting for stimulating and
analyzing NSP model hallucinations. The framework can be applied to any NSP
task with a closed-ontology. Using the proposed framework and KQA Pro as the
benchmark dataset, we assess state-of-the-art techniques for hallucination
detection. We then present a novel hallucination detection strategy that
exploits the computational graph of the NSP model to detect the NSP
hallucinations in the presence of ontology gaps, out-of-domain utterances, and
to recognize NSP errors, improving the F1-Score respectively by ~21, ~24% and
~1%. This is the first work in closed-ontology NSP that addresses the problem
of recognizing ontology gaps. We release our code and checkpoints at
https://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toc<span class="highlight-title">BERT</span>: Medical Document Structure Extraction Using Bidirectional
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Majd Saleh, Sarra Baghdadi, Stéphane Paquelet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text segmentation holds paramount importance in the field of Natural Language
Processing (NLP). It plays an important role in several NLP downstream tasks
like information retrieval and document summarization. In this work, we propose
a new solution, namely TocBERT, for segmenting texts using bidirectional
transformers. TocBERT represents a supervised solution trained on the detection
of titles and sub-titles from their semantic representations. This task was
formulated as a named entity recognition (NER) problem. The solution has been
applied on a medical text segmentation use-case where the Bio-ClinicalBERT
model is fine-tuned to segment discharge summaries of the MIMIC-III dataset.
The performance of TocBERT has been evaluated on a human-labeled ground truth
corpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a
linear text segmentation problem and 72.8% on a hierarchical text segmentation
problem. It outperformed a carefully designed rule-based solution, particularly
in distinguishing titles from subtitles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Captioning Visualizations with Large Language Models (CVLLM): A Tutorial 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19512v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19512v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giuseppe Carenini, Jordon Johnson, Ali Salamatian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatically captioning visualizations is not new, but recent advances in
large language models(LLMs) open exciting new possibilities. In this tutorial,
after providing a brief review of Information Visualization (InfoVis)
principles and past work in captioning, we introduce neural models and the
transformer architecture used in generic LLMs. We then discuss their recent
applications in InfoVis, with a focus on captioning. Additionally, we explore
promising future directions in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Generative Language Models Multicultural? A Study on Hausa Culture
  and Emotions using Chat<span class="highlight-title">GPT</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19504v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19504v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ibrahim Said Ahmad, Shiran Dudy, Resmi Ramachandranpillai, Kenneth Church
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs), such as ChatGPT, are widely used to generate
content for various purposes and audiences. However, these models may not
reflect the cultural and emotional diversity of their users, especially for
low-resource languages. In this paper, we investigate how ChatGPT represents
Hausa's culture and emotions. We compare responses generated by ChatGPT with
those provided by native Hausa speakers on 37 culturally relevant questions. We
conducted experiments using emotion analysis and applied two similarity metrics
to measure the alignment between human and ChatGPT responses. We also collected
human participants ratings and feedback on ChatGPT responses. Our results show
that ChatGPT has some level of similarity to human responses, but also exhibits
some gaps and biases in its knowledge and awareness of the Hausa culture and
emotions. We discuss the implications and limitations of our methodology and
analysis and suggest ways to improve the performance and evaluation of LLMs for
low-resource languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating How Large Language Models Leverage Internal Knowledge to
  Perform Complex Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19502v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19502v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress; code is available at
  https://github.com/kaistAI/knowledge-reasoning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Monitoring Latent World States in Language Models with Propositional
  Probes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19501v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19501v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahai Feng, Stuart Russell, Jacob Steinhardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models are susceptible to bias, sycophancy, backdoors, and other
tendencies that lead to unfaithful responses to the input context. Interpreting
internal states of language models could help monitor and correct unfaithful
behavior. We hypothesize that language models represent their input contexts in
a latent world model, and seek to extract this latent world state from the
activations. We do so with 'propositional probes', which compositionally probe
tokens for lexical information and bind them into logical propositions
representing the world state. For example, given the input context ''Greg is a
nurse. Laura is a physicist.'', we decode the propositions ''WorksAs(Greg,
nurse)'' and ''WorksAs(Laura, physicist)'' from the model's activations. Key to
this is identifying a 'binding subspace' in which bound tokens have high
similarity (''Greg'' and ''nurse'') but unbound ones do not (''Greg'' and
''physicist''). We validate propositional probes in a closed-world setting with
finitely many predicates and properties. Despite being trained on simple
templated contexts, propositional probes generalize to contexts rewritten as
short stories and translated to Spanish. Moreover, we find that in three
settings where language models respond unfaithfully to the input context --
prompt injections, backdoor attacks, and gender bias -- the decoded
propositions remain faithful. This suggests that language models often encode a
faithful world model but decode it unfaithfully, which motivates the search for
better interpretability tools for monitoring LMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge acquisition for dialogue agents using reinforcement learning
  on graph representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Selene Baez Santamaria, Shihan Wang, Piek Vossen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop an artificial agent motivated to augment its knowledge base beyond
its initial training. The agent actively participates in dialogues with other
agents, strategically acquiring new information. The agent models its knowledge
as an RDF knowledge graph, integrating new beliefs acquired through
conversation. Responses in dialogue are generated by identifying graph patterns
around these new integrated beliefs. We show that policies can be learned using
reinforcement learning to select effective graph patterns during an
interaction, without relying on explicit user feedback. Within this context,
our study is a proof of concept for leveraging users as effective sources of
information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Inclusivity in Large Language Models: Personality Traits and Gender Bias
  in Scientific Abstracts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19497v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19497v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naseela Pervez, Alexander J. Titus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly utilized to assist in
scientific and academic writing, helping authors enhance the coherence of their
articles. Previous studies have highlighted stereotypes and biases present in
LLM outputs, emphasizing the need to evaluate these models for their alignment
with human narrative styles and potential gender biases. In this study, we
assess the alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large,
and Gemini 1.5 Flash - by analyzing their performance on benchmark
text-generation tasks for scientific abstracts. We employ the Linguistic
Inquiry and Word Count (LIWC) framework to extract lexical, psychological, and
social features from the generated texts. Our findings indicate that, while
these models generally produce text closely resembling human authored content,
variations in stylistic features suggest significant gender biases. This
research highlights the importance of developing LLMs that maintain a diversity
of writing styles to promote inclusivity in academic discourse.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Development and Evaluation of a Retrieval-Augmented Generation Tool for
  Creating SAPPhIRE Models of Artificial Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19493v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19493v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anubhab Majumder, Kausik Bhattacharya, Amaresh Chakrabarti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representing systems using the SAPPhIRE causality model is found useful in
supporting design-by-analogy. However, creating a SAPPhIRE model of artificial
or biological systems is an effort-intensive process that requires human
experts to source technical knowledge from multiple technical documents
regarding how the system works. This research investigates how to leverage
Large Language Models (LLMs) in creating structured descriptions of systems
using the SAPPhIRE model of causality. This paper, the second part of the
two-part research, presents a new Retrieval-Augmented Generation (RAG) tool for
generating information related to SAPPhIRE constructs of artificial systems and
reports the results from a preliminary evaluation of the tool's success -
focusing on the factual accuracy and reliability of outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LoPT: Low-Rank <span class="highlight-title">Prompt</span> Tuning for Parameter Efficient Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19486v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19486v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shouchang Guo, Sonam Damani, Keng-hao Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In prompt tuning, a prefix or suffix text is added to the prompt, and the
embeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix
are optimized to gain more control over language models for specific tasks.
This approach eliminates the need for hand-crafted prompt engineering or
explicit model fine-tuning. Prompt tuning is significantly more
parameter-efficient than model fine-tuning, as it involves optimizing partial
inputs of language models to produce desired outputs.
  In this work, we aim to further reduce the amount of trainable parameters
required for a language model to perform well on specific tasks. We propose
Low-rank Prompt Tuning (LoPT), a low-rank model for prompts that achieves
efficient prompt optimization. The proposed method demonstrates similar
outcomes to full parameter prompt tuning while reducing the number of trainable
parameters by a factor of 5. It also provides promising results compared to the
state-of-the-art methods that would require 10 to 20 times more parameters.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ xTower: A Multilingual LLM for Explaining and Correcting Translation
  Errors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcos Treviso, Nuno M. Guerreiro, Sweta Agrawal, Ricardo Rei, José Pombal, Tania Vaz, Helena Wu, Beatriz Silva, Daan van Stigt, André F. T. Martins
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While machine translation (MT) systems are achieving increasingly strong
performance on benchmarks, they often produce translations with errors and
anomalies. Understanding these errors can potentially help improve the
translation quality and user experience. This paper introduces xTower, an open
large language model (LLM) built on top of TowerBase designed to provide
free-text explanations for translation errors in order to guide the generation
of a corrected translation. The quality of the generated explanations by xTower
are assessed via both intrinsic and extrinsic evaluation. We ask expert
translators to evaluate the quality of the explanations across two dimensions:
relatedness towards the error span being explained and helpfulness in error
understanding and improving translation quality. Extrinsically, we test xTower
across various experimental setups in generating translation corrections,
demonstrating significant improvements in translation quality. Our findings
highlight xTower's potential towards not only producing plausible and helpful
explanations of automatic translations, but also leveraging them to suggest
corrected translations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sparse Regression for Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19478v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19478v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ergun Biçici
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We use transductive regression techniques to learn mappings between source
and target features of given parallel corpora and use these mappings to
generate machine translation outputs. We show the effectiveness of $L_1$
regularized regression (\textit{lasso}) to learn the mappings between sparsely
observed feature sets versus $L_2$ regularized regression. Proper selection of
training instances plays an important role to learn correct feature mappings
within limited computational resources and at expected accuracy levels. We
introduce \textit{dice} instance selection method for proper selection of
training instances, which plays an important role to learn correct feature
mappings for improving the source and target coverage of the training set. We
show that $L_1$ regularized regression performs better than $L_2$ regularized
regression both in regression measurements and in the translation experiments
using graph decoding. We present encouraging results when translating from
German to English and Spanish to English. We also demonstrate results when the
phrase table of a phrase-based decoder is replaced with the mappings we find
with the regression model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Changing Answer Order Can Decrease MMLU Accuracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vipul Gupta, David Pantoja, Candace Ross, Adina Williams, Megan Ung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) have grown in prevalence, particular
benchmarks have become essential for the evaluation of these models and for
understanding model capabilities. Most commonly, we use test accuracy averaged
across multiple subtasks in order to rank models on leaderboards, to determine
which model is best for our purposes. In this paper, we investigate the
robustness of the accuracy measurement on a widely used multiple choice
question answering dataset, MMLU. When shuffling the answer label contents, we
find that all explored models decrease in accuracy on MMLU, but not every model
is equally sensitive. These findings suggest a possible adjustment to the
standard practice of leaderboard testing, where we additionally consider the
percentage of examples each model answers correctly by random chance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Short paper, 9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Large Language Models Generate High-quality Patent Claims? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19465v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19465v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lekang Jiang, Caiqi Zhang, Pascal A Scherz, Stephan Goetz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown exceptional performance across
various text generation tasks but remain under-explored in the patent domain,
which offers highly structured and precise language. This paper constructs a
dataset to investigate the performance of current LLMs in patent claim
generation. Our results demonstrate that generating claims based on patent
descriptions outperforms previous research relying on abstracts. Interestingly,
current patent-specific LLMs perform much worse than state-of-the-art general
LLMs, highlighting the necessity for future research on in-domain LLMs. We also
find that LLMs can produce high-quality first independent claims, but their
performances markedly decrease for subsequent dependent claims. Moreover,
fine-tuning can enhance the completeness of inventions' features, conceptual
clarity, and feature linkage. Among the tested LLMs, GPT-4 demonstrates the
best performance in comprehensive human evaluations by patent experts, with
better feature coverage, conceptual clarity, and technical coherence. Despite
these capabilities, comprehensive revision and modification are still necessary
to pass rigorous patent scrutiny and ensure legal robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Taming Data and <span class="highlight-title">Transformer</span>s for Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19388v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19388v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating ambient sounds and effects is a challenging problem due to data
scarcity and often insufficient caption quality, making it difficult to employ
large-scale generative models for the task. In this work, we tackle the problem
by introducing two new models. First, we propose AutoCap, a high-quality and
efficient automatic audio captioning model. We show that by leveraging metadata
available with the audio modality, we can substantially improve the quality of
captions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from
the best available captioning model at four times faster inference speed. We
then use AutoCap to caption clips from existing datasets, obtaining 761,000
audio clips with high-quality captions, forming the largest available
audio-text dataset. Second, we propose GenAu, a scalable transformer-based
audio generation architecture that we scale up to 1.25B parameters and train
with our new dataset. When compared to state-of-the-art audio generators, GenAu
obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%
in CLAP score, indicating significantly improved quality of generated audio
compared to previous works. This shows that the quality of data is often as
important as its quantity. Besides, since AutoCap is fully automatic, new audio
samples can be added to the training dataset, unlocking the training of even
larger generative models for audio synthesis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Webpage: https://snap-research.github.io/GenAU/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Remarkable Robustness of LLMs: Stages of Inference? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19384v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19384v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vedang Lad, Wes Gurnee, Max Tegmark
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We demonstrate and investigate the remarkable robustness of Large Language
Models by deleting and swapping adjacent layers. We find that deleting and
swapping interventions retain 72-95\% of the original model's prediction
accuracy without fine-tuning, whereas models with more layers exhibit more
robustness. Based on the results of the layer-wise intervention and further
experiments, we hypothesize the existence of four universal stages of inference
across eight different models: detokenization, feature engineering, prediction
ensembling, and residual sharpening. The first stage integrates local
information, lifting raw token representations into higher-level contextual
representations. Next is the iterative refinement of task and entity-specific
features. Then, the second half of the model begins with a phase transition,
where hidden representations align more with the vocabulary space due to
specialized model components. Finally, the last layer sharpens the following
token distribution by eliminating obsolete features that add noise to the
prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Suri: Multi-constraint Instruction Following for Long-form Text
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chau Minh Pham, Simeng Sun, Mohit Iyyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing research on instruction following largely focuses on tasks with
simple instructions and short responses. In this work, we explore
multi-constraint instruction following for generating long-form text. We create
Suri, a dataset with 20K human-written long-form texts paired with
LLM-generated backtranslated instructions that contain multiple complex
constraints. Because of prohibitive challenges associated with collecting human
preference judgments on long-form texts, preference-tuning algorithms such as
DPO are infeasible in our setting; thus, we propose Instructional ORPO
(I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving
negative feedback from dispreferred responses, I-ORPO obtains negative feedback
from synthetically corrupted instructions generated by an LLM. Using Suri, we
perform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The
resulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts
(~5K tokens) than base models without significant quality deterioration. Our
human evaluation shows that while both SFT and I-ORPO models satisfy most
constraints, Suri-I-ORPO generations are generally preferred for their coherent
and informative incorporation of the constraints. We release our code at
https://github.com/chtmp223/suri.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Model Arena for Cross-lingual Sentiment Analysis: A Comparative
  Study in the Era of Large Language Models <span class="chip">WASSA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19358v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19358v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiliang Zhu, Shayna Gardiner, Tere Roldán, David Rossouw
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sentiment analysis serves as a pivotal component in Natural Language
Processing (NLP). Advancements in multilingual pre-trained models such as XLM-R
and mT5 have contributed to the increasing interest in cross-lingual sentiment
analysis. The recent emergence in Large Language Models (LLM) has significantly
advanced general NLP tasks, however, the capability of such LLMs in
cross-lingual sentiment analysis has not been fully studied. This work
undertakes an empirical analysis to compare the cross-lingual transfer
capability of public Small Multilingual Language Models (SMLM) like XLM-R,
against English-centric LLMs such as Llama-3, in the context of sentiment
analysis across English, Spanish, French and Chinese. Our findings reveal that
among public models, SMLMs exhibit superior zero-shot cross-lingual performance
relative to LLMs. However, in few-shot cross-lingual settings, public LLMs
demonstrate an enhanced adaptive potential. In addition, we observe that
proprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but
are outpaced by public models in few-shot scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to WASSA workshop at ACL2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiVERT: Distractor Generation with Variational Errors Represented as
  Text for Math Multiple-choice Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19356v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19356v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nigel Fernandez, Alexander Scarlatos, Simon Woodhead, Andrew Lan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality distractors are crucial to both the assessment and pedagogical
value of multiple-choice questions (MCQs), where manually crafting ones that
anticipate knowledge deficiencies or misconceptions among real students is
difficult. Meanwhile, automated distractor generation, even with the help of
large language models (LLMs), remains challenging for subjects like math. It is
crucial to not only identify plausible distractors but also understand the
error behind them. In this paper, we introduce DiVERT (Distractor Generation
with Variational Errors Represented as Text), a novel variational approach that
learns an interpretable representation of errors behind distractors in math
MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions
used by hundreds of thousands of students, we show that DiVERT, despite using a
base open-source LLM with 7B parameters, outperforms state-of-the-art
approaches using GPT-4o on downstream distractor generation. We also conduct a
human evaluation with math educators and find that DiVERT leads to error labels
that are of comparable quality to human-authored ones.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fundamental Problems With Model Editing: How Should Rational Belief
  Revision Work in LLMs? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19354v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19354v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peter Hase, Thomas Hofweber, Xiang Zhou, Elias Stengel-Eskin, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The model editing problem concerns how language models should learn new facts
about the world over time. While empirical research on model editing has drawn
widespread attention, the conceptual foundations of model editing remain shaky
-- perhaps unsurprisingly, since model editing is essentially belief revision,
a storied problem in philosophy that has eluded succinct solutions for decades.
Model editing nonetheless demands a solution, since we need to be able to
control the knowledge within language models. With this goal in mind, this
paper critiques the standard formulation of the model editing problem and
proposes a formal testbed for model editing research. We first describe 12 open
problems with model editing, based on challenges with (1) defining the problem,
(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the
first place. Many of these challenges are extremely difficult to address, e.g.
determining far-reaching consequences of edits, labeling probabilistic
entailments between facts, and updating beliefs of agent simulators. Next, we
introduce a semi-synthetic dataset for model editing based on Wikidata, where
we can evaluate edits against labels given by an idealized Bayesian agent. This
enables us to say exactly how belief revision in language models falls short of
a desirable epistemic standard. We encourage further research exploring
settings where such a gold standard can be compared against. Our code is
publicly available at: https://github.com/peterbhase/LLM-belief-revision
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IndoToxic2024: A Demographically-Enriched <span class="highlight-title">Dataset</span> of Hate Speech and
  Toxicity Types for Indonesian Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19349v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19349v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucky Susanto, Musa Izzanardi Wijanarko, Prasetia Anugrah Pratama, Traci Hong, Ika Idris, Alham Fikri Aji, Derry Wijaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hate speech poses a significant threat to social harmony. Over the past two
years, Indonesia has seen a ten-fold increase in the online hate speech ratio,
underscoring the urgent need for effective detection mechanisms. However,
progress is hindered by the limited availability of labeled data for Indonesian
texts. The condition is even worse for marginalized minorities, such as Shia,
LGBTQ, and other ethnic minorities because hate speech is underreported and
less understood by detection tools. Furthermore, the lack of accommodation for
subjectivity in current datasets compounds this issue. To address this, we
introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity
classification dataset. Comprising 43,692 entries annotated by 19 diverse
individuals, the dataset focuses on texts targeting vulnerable groups in
Indonesia, specifically during the hottest political event in the country: the
presidential election. We establish baselines for seven binary classification
tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet)
fine-tuned for hate speech classification. Furthermore, we demonstrate how
incorporating demographic information can enhance the zero-shot performance of
the large language model, gpt-3.5-turbo. However, we also caution that an
overemphasis on demographic information can negatively impact the fine-tuned
model performance due to data fragmentation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Jump Starting Bandits with LLM-Generated Prior Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19317v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19317v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parand A. Alamdari, Yanshuai Cao, Kevin H. Wilson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present substantial evidence demonstrating the benefits of integrating
Large Language Models (LLMs) with a Contextual Multi-Armed Bandit framework.
Contextual bandits have been widely used in recommendation systems to generate
personalized suggestions based on user-specific contexts. We show that LLMs,
pre-trained on extensive corpora rich in human knowledge and preferences, can
simulate human behaviours well enough to jump-start contextual multi-armed
bandits to reduce online learning regret. We propose an initialization
algorithm for contextual bandits by prompting LLMs to produce a pre-training
dataset of approximate human preferences for the bandit. This significantly
reduces online learning regret and data-gathering costs for training such
models. Our approach is validated empirically through two sets of experiments
with different bandit setups: one which utilizes LLMs to serve as an oracle and
a real-world experiment utilizing data from a conjoint survey experiment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> LiveBench: A Challenging, Contamination-Free LLM Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19314v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19314v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Colin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, <span class="highlight-author">Yann LeCun</span>, Tom Goldstein, Willie Neiswanger, Micah Goldblum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Test set contamination, wherein test data from a benchmark ends up in a newer
model's training set, is a well-documented obstacle for fair LLM evaluation and
can quickly render benchmarks obsolete. To mitigate this, many recent
benchmarks crowdsource new prompts and evaluations from human or LLM judges;
however, these can introduce significant biases, and break down when scoring
hard questions. In this work, we introduce a new benchmark for LLMs designed to
be immune to both test set contamination and the pitfalls of LLM judging and
human crowdsourcing. We release LiveBench, the first benchmark that (1)
contains frequently-updated questions from recent information sources, (2)
scores answers automatically according to objective ground-truth values, and
(3) contains a wide variety of challenging tasks, spanning math, coding,
reasoning, language, instruction following, and data analysis. To achieve this,
LiveBench contains questions that are based on recently-released math
competitions, arXiv papers, news articles, and datasets, and it contains
harder, contamination-free versions of tasks from previous benchmarks such as
Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source
models, as well as dozens of open-source models ranging from 0.5B to 110B in
size. LiveBench is difficult, with top models achieving below 65% accuracy. We
release all questions, code, and model answers. Questions will be added and
updated on a monthly basis, and we will release new tasks and harder versions
of tasks over time so that LiveBench can distinguish between the capabilities
of LLMs as they improve in the future. We welcome community engagement and
collaboration for expanding the benchmark tasks and models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Odyssey of Commonsense Causality: From Foundational Benchmarks to
  Cutting-Edge Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaobo Cui, Zhijing Jin, Bernhard Schölkopf, Boi Faltings
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding commonsense causality is a unique mark of intelligence for
humans. It helps people understand the principles of the real world better and
benefits the decision-making process related to causation. For instance,
commonsense causality is crucial in judging whether a defendant's action causes
the plaintiff's loss in determining legal liability. Despite its significance,
a systematic exploration of this topic is notably lacking. Our comprehensive
survey bridges this gap by focusing on taxonomies, benchmarks, acquisition
methods, qualitative reasoning, and quantitative measurements in commonsense
causality, synthesizing insights from over 200 representative articles. Our
work aims to provide a systematic overview, update scholars on recent
advancements, provide a pragmatic guide for beginners, and highlight promising
future research directions in this vital field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Artificial Needles to Real Haystacks: Improving Retrieval
  Capabilities in LLMs by Finetuning on Synthetic Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19292v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19292v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, Dimitris Papailiopoulos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have shown that Large Language Models (LLMs) struggle to
accurately retrieve information and maintain reasoning capabilities when
processing long-context inputs. To address these limitations, we propose a
finetuning approach utilizing a carefully designed synthetic dataset comprising
numerical key-value retrieval tasks. Our experiments on models like GPT-3.5
Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset
significantly improves LLMs' information retrieval and reasoning capabilities
in longer-context settings. We present an analysis of the finetuned models,
illustrating the transfer of skills from synthetic to real task evaluations
(e.g., $10.5\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5
Turbo). We also find that finetuned LLMs' performance on general benchmarks
remains almost constant while LLMs finetuned on other baseline long-context
augmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B
finetuned on our synthetic data cause no performance drop while other baseline
data can cause a drop that ranges from $2.33\%$ to $6.19\%$). Our study
highlights the potential of finetuning on synthetic data for improving the
performance of LLMs on longer-context tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Huatuo<span class="highlight-title">GPT</span>-Vision, Towards Injecting Medical Visual Knowledge into
  Multimodal LLMs at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19280v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19280v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VERISCORE: Evaluating the factuality of verifiable claims in long-form
  text generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19276v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19276v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixiao Song, Yekyung Kim, Mohit Iyyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing metrics for evaluating the factuality of long-form text, such as
FACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input
text into "atomic claims" and verify each against a knowledge base like
Wikipedia. These metrics are not suitable for most generation tasks because
they assume that every claim is verifiable (i.e., can plausibly be proven true
or false). We address this issue with VERISCORE, a metric for diverse long-form
generation tasks that contain both verifiable and unverifiable content.
VERISCORE can be effectively implemented with either closed or fine-tuned
open-weight language models, and human evaluation confirms that VERISCORE's
extracted claims are more sensible than those from competing methods across
eight different long-form tasks. We use VERISCORE to evaluate generations from
16 different models across multiple long-form tasks and find that while GPT-4o
is the best-performing model overall, open-weight models such as Mixtral-8x22
are closing the gap. We show that an LM's VERISCORE on one task (e.g.,
biography generation) does not necessarily correlate to its VERISCORE on a
different task (e.g., long-form QA), highlighting the need for expanding
factuality evaluation across tasks with varying fact density.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Praneeth Vadlapati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Up-to-date and reliable Large Language Models (LLMs) are consistently sought
after. Typically, LLMs are trained on a fixed dataset and then deployed.
However, the training data continually becomes outdated. Enable automatic
training of AI using web data involves significant concerns regarding data
quality and safety due to bias, spam, and other unsafe or unwanted text. Pure
data is essential for producing reliable models. Training a model on impure
data may result in undesirable outcomes. This research proposes a system that
collects web data and automatically filters out unwanted text with the
assistance of existing trusted AI models. In the experiment, a small sample of
web data was collected and filtered, demonstrating the system's effectiveness
in purifying the data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Initial version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens
  Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19263v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19263v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graphical User Interfaces (GUIs) are central to our interaction with digital
devices. Recently, growing efforts have been made to build models for various
GUI understanding tasks. However, these efforts largely overlook an important
GUI-referring task: screen reading based on user-indicated points, which we
name the Screen Point-and-Read (SPR) task. This task is predominantly handled
by rigid accessible screen reading tools, in great need of new models driven by
advancements in Multimodal Large Language Models (MLLMs). In this paper, we
propose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,
to address the SPR task. Based on the input point coordinate and the
corresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout
Tree. Based on the tree, our ToL agent not only comprehends the content of the
indicated area but also articulates the layout and spatial relationships
between elements. Such layout information is crucial for accurately
interpreting information on the screen, distinguishing our ToL agent from other
screen reading tools. We also thoroughly evaluate the ToL agent against other
baselines on a newly proposed SPR benchmark, which includes GUIs from mobile,
web, and operating systems. Last but not least, we test the ToL agent on mobile
GUI navigation tasks, demonstrating its utility in identifying incorrect
actions along the path of agent execution trajectories. Code and data:
screen-point-and-read.github.io
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Video-Language Representations with Structural Spatio-Temporal
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19255v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19255v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE TPAMI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19251v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19251v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia Fu, Xiaoting Qin, Fangkai Yang, Lu Wang, Jue Zhang, Qingwei Lin, Yubo Chen, Dongmei Zhang, Saravan Rajmohan, Qi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models have transformed ML/AI
development, necessitating a reevaluation of AutoML principles for the
Retrieval-Augmented Generation (RAG) systems. To address the challenges of
hyper-parameter optimization and online adaptation in RAG, we propose the
AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online
multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical
MAB (Hier-MAB) method for efficient exploration of large search spaces. We
conduct extensive experiments on tuning hyper-parameters, such as top-k
retrieved documents, prompt compression ratio, and embedding methods, using the
ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly
optimization all three hyper-parameters demonstrate that MAB-based online
learning methods can achieve Recall@5 $\approx 0.8$ for scenarios with
prominent gradients in search space, using only $\sim20\%$ of the LLM API calls
required by the Grid Search approach. Additionally, the proposed Hier-MAB
approach outperforms other baselines in more challenging optimization
scenarios. The code will be made available at https://aka.ms/autorag.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revealing Fine-Grained Values and Opinions in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19238v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19238v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dustin Wright, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge Belongie, Isabelle Augenstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Uncovering latent values and opinions in large language models (LLMs) can
help identify biases and mitigate potential harm. Recently, this has been
approached by presenting LLMs with survey questions and quantifying their
stances towards morally and politically charged statements. However, the
stances generated by LLMs can vary greatly depending on how they are prompted,
and there are many ways to argue for or against a given position. In this work,
we propose to address this by analysing a large and robust dataset of 156k LLM
responses to the 62 propositions of the Political Compass Test (PCT) generated
by 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of
their generated stances and fine-grained analysis of the plain text
justifications for those stances. For fine-grained analysis, we propose to
identify tropes in the responses: semantically similar phrases that are
recurrent and consistent across different prompts, revealing patterns in the
text that a given LLM is prone to produce. We find that demographic features
added to prompts significantly affect outcomes on the PCT, reflecting bias, as
well as disparities between the results of tests when eliciting closed-form vs.
open domain responses. Additionally, patterns in the plain text rationales via
tropes show that similar justifications are repeatedly generated across models
and prompts even with disparate stances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 20 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spiking Convolutional Neural Networks for Text Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19230v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19230v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changze Lv, Jianhan Xu, Xiaoqing Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking neural networks (SNNs) offer a promising pathway to implement deep
neural networks (DNNs) in a more energy-efficient manner since their neurons
are sparsely activated and inferences are event-driven. However, there have
been very few works that have demonstrated the efficacy of SNNs in language
tasks partially because it is non-trivial to represent words in the forms of
spikes and to deal with variable-length texts by SNNs. This work presents a
"conversion + fine-tuning" two-step method for training SNNs for text
classification and proposes a simple but effective way to encode pre-trained
word embeddings as spike trains. We show empirically that after fine-tuning
with surrogate gradients, the converted SNNs achieve comparable results to
their DNN counterparts with much less energy consumption across multiple
datasets for both English and Chinese. We also show that such SNNs are more
robust to adversarial attacks than DNNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tools Fail: Detecting Silent Errors in Faulty Tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jimin Sun, So Yeon Min, Yingshan Chang, Yonatan Bisk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not
in their weights, to perform tasks on the web, and even to control robots.
However, most ontologies and surveys of tool-use have assumed the core
challenge for LLMs is choosing the tool. Instead, we introduce a framework for
tools more broadly which guides us to explore a model's ability to detect
"silent" tool errors, and reflect on how to plan. This more directly aligns
with the increasingly popular use of models as tools. We provide an initial
approach to failure recovery with promising results both on a controlled
calculator setting and embodied agent planning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Symbolic <span class="highlight-title">Prompt</span> Program Search: A Structure-Aware Approach to Efficient
  Compile-Time <span class="highlight-title">Prompt</span> Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.02319v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.02319v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Schnabel, Jennifer Neville
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many modern LLM applications, such as retrieval augmented generation,
prompts have become programs themselves. In these settings, prompt programs are
repeatedly called with different user queries or data instances. A big
practical challenge is optimizing such prompt programs. Recent work has mostly
focused on either simple prompt programs or assumed that the general structure
of a prompt program is fixed.
  We introduce SAMMO, a framework to perform symbolic prompt program search for
compile-time optimizations of prompt programs. SAMMO represents prompt programs
on a symbolic level which allows for a rich set of transformations that can be
searched over during optimization. We show that SAMMO generalizes previous
methods and improves the performance of complex prompts on (1) instruction
tuning, (2) RAG pipeline tuning, and (3) prompt compression, across several
different LLMs. We make all code available open-source at
https://github.com/microsoft/sammo .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13372v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13372v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Zhangchi Feng, Yongqiang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient fine-tuning is vital for adapting large language models (LLMs) to
downstream tasks. However, it requires non-trivial efforts to implement these
methods on different models. We present LlamaFactory, a unified framework that
integrates a suite of cutting-edge efficient training methods. It provides a
solution for flexibly customizing the fine-tuning of 100+ LLMs without the need
for coding through the built-in web UI LlamaBoard. We empirically validate the
efficiency and effectiveness of our framework on language modeling and text
generation tasks. It has been released at
https://github.com/hiyouga/LLaMA-Factory and received over 25,000 stars and
3,000 forks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, accepted to ACL 2024 System Demonstration Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Tuning <span class="highlight-title">BERT</span>s for Definition Extraction from Mathematical Text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13827v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13827v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucy Horowitz, Ryan Hathaway
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we fine-tuned three pre-trained BERT models on the task of
"definition extraction" from mathematical English written in LaTeX. This is
presented as a binary classification problem, where either a sentence contains
a definition of a mathematical term or it does not. We used two original data
sets, "Chicago" and "TAC," to fine-tune and test these models. We also tested
on WFMALL, a dataset presented by Vanetik and Litvak in 2021 and compared the
performance of our models to theirs. We found that a high-performance
Sentence-BERT transformer model performed best based on overall accuracy,
recall, and precision metrics, achieving comparable results to the earlier
models with less computational effort.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Target Span Detection for Implicit Harmful Content 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19836v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19836v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazanin Jafari, James Allan, Sheikh Muhammad Sarwar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Identifying the targets of hate speech is a crucial step in grasping the
nature of such speech and, ultimately, in improving the detection of offensive
posts on online forums. Much harmful content on online platforms uses implicit
language especially when targeting vulnerable and protected groups such as
using stereotypical characteristics instead of explicit target names, making it
harder to detect and mitigate the language. In this study, we focus on
identifying implied targets of hate speech, essential for recognizing subtler
hate speech and enhancing the detection of harmful content on digital
platforms. We define a new task aimed at identifying the targets even when they
are not explicitly stated. To address that task, we collect and annotate target
spans in three prominent implicit hate speech datasets: SBIC, DynaHate, and
IHC. We call the resulting merged collection Implicit-Target-Span. The
collection is achieved using an innovative pooling method with matching scores
based on human annotations and Large Language Models (LLMs). Our experiments
indicate that Implicit-Target-Span provides a challenging test bed for target
span detection methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Software Engineering Methods For AI-Driven Deductive Legal Reasoning <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.09868v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.09868v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohan Padhye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent proliferation of generative artificial intelligence (AI)
technologies such as pre-trained large language models (LLMs) has opened up new
frontiers in computational law. An exciting area of development is the use of
AI to automate the deductive rule-based reasoning inherent in statutory and
contract law. This paper argues that such automated deductive legal reasoning
can now be viewed from the lens of software engineering, treating LLMs as
interpreters of natural-language programs with natural-language inputs. We show
how it is possible to apply principled software engineering techniques to
enhance AI-driven legal reasoning of complex statutes and to unlock new
applications in automated meta-reasoning such as mutation-guided example
generation and metamorphic property-based testing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Appearing in Onward! at SPLASH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ "Vorbeşti Româneşte?" A Recipe to Train Powerful Romanian LLMs
  with English Instructions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18266v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18266v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mihai Masala, Denis C. Ilie-Ablachim, Alexandru Dima, Dragos Corlatescu, Miruna Zavelca, Ovio Olaru, Simina Terian, Andrei Terian, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, Traian Rebedea
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Large Language Models (LLMs) have achieved almost human-like
performance on various tasks. While some LLMs have been trained on multilingual
data, most of the training data is in English; hence, their performance in
English greatly exceeds other languages. To our knowledge, we are the first to
collect and translate a large collection of texts, instructions, and benchmarks
and train, evaluate, and release open-source LLMs tailored for Romanian. We
evaluate our methods on four different categories, including academic
benchmarks, MT-Bench (manually translated), and a professionally built
historical, cultural, and social benchmark adapted to Romanian. We argue for
the usefulness and high performance of RoLLMs by obtaining state-of-the-art
results across the board. We publicly release all resources (i.e., data,
training and evaluation code, models) to support and encourage research on
Romanian LLMs while concurrently creating a generalizable recipe, adequate for
other low or less-resourced languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2405.07703</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Guylingo: The Republic of Guyana Creole Corpora <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03832v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03832v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christopher Clarke, Roland Daynauth, Charlene Wilkinson, Hubert Devonish, Jason Mars
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While major languages often enjoy substantial attention and resources, the
linguistic diversity across the globe encompasses a multitude of smaller,
indigenous, and regional languages that lack the same level of computational
support. One such region is the Caribbean. While commonly labeled as "English
speaking", the ex-British Caribbean region consists of a myriad of Creole
languages thriving alongside English. In this paper, we present Guylingo: a
comprehensive corpus designed for advancing NLP research in the domain of
Creolese (Guyanese English-lexicon Creole), the most widely spoken language in
the culturally rich nation of Guyana. We first outline our framework for
gathering and digitizing this diverse corpus, inclusive of colloquial
expressions, idioms, and regional variations in a low-resource language. We
then demonstrate the challenges of training and evaluating NLP models for
machine translation in Creole. Lastly, we discuss the unique opportunities
presented by recent NLP advancements for accelerating the formal adoption of
Creole languages as official languages in the Caribbean.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NAACL 2024 Main Conference Special Theme Track: Languages
  of Latin America and The Caribbean</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank
  Modifications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05162v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05162v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyi Wei, Kaixuan Huang, Yangsibo Huang, Tinghao Xie, Xiangyu Qi, Mengzhou Xia, Prateek Mittal, Mengdi Wang, Peter Henderson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) show inherent brittleness in their safety
mechanisms, as evidenced by their susceptibility to jailbreaking and even
non-malicious fine-tuning. This study explores this brittleness of safety
alignment by leveraging pruning and low-rank modifications. We develop methods
to identify critical regions that are vital for safety guardrails, and that are
disentangled from utility-relevant regions at both the neuron and rank levels.
Surprisingly, the isolated regions we find are sparse, comprising about $3\%$
at the parameter level and $2.5\%$ at the rank level. Removing these regions
compromises safety without significantly impacting utility, corroborating the
inherent brittleness of the model's safety mechanisms. Moreover, we show that
LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications
to the safety-critical regions are restricted. These findings underscore the
urgent need for more robust safety strategies in LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 9 figures. Project page is available at
  https://boyiwei.com/alignment-attribution/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VDebugger: Harnessing Execution Feedback for Debugging Visual Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13444v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13444v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xueqing Wu, Zongyu Lin, Songyan Zhao, Te-Lin Wu, Pan Lu, Nanyun Peng, Kai-Wei Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual programs are executable code generated by large language models to
address visual reasoning problems. They decompose complex questions into
multiple reasoning steps and invoke specialized models for each step to solve
the problems. However, these programs are prone to logic errors, with our
preliminary evaluation showing that 58% of the total errors are caused by
program logic errors. Debugging complex visual programs remains a major
bottleneck for visual reasoning. To address this, we introduce VDebugger, a
novel critic-refiner framework trained to localize and debug visual programs by
tracking execution step by step. VDebugger identifies and corrects program
errors leveraging detailed execution feedback, improving interpretability and
accuracy. The training data is generated through an automated pipeline that
injects errors into correct visual programs using a novel mask-best decoding
technique. Evaluations on six datasets demonstrate VDebugger's effectiveness,
showing performance improvements of up to 3.2% in downstream task accuracy.
Further studies show VDebugger's ability to generalize to unseen tasks,
bringing a notable improvement of 2.3% on the unseen COVR task. Code, data and
models are made publicly available at https://github.com/shirley-wu/vdebugger/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>update reference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WebCanvas: Benchmarking Web Agents in Online Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12373v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12373v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichen Pan, Dehan Kong, Sida Zhou, Cheng Cui, Yifei Leng, Bing Jiang, Hangyu Liu, Yanyi Shang, Shuyan Zhou, Tongshuang Wu, Zhengyang Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For web agents to be practically useful, they must adapt to the continuously
evolving web environment characterized by frequent updates to user interfaces
and content. However, most existing benchmarks only capture the static aspects
of the web. To bridge this gap, we introduce WebCanvas, an innovative online
evaluation framework for web agents that effectively addresses the dynamic
nature of web interactions. WebCanvas contains three main components to
facilitate realistic assessments: (1) A novel evaluation metric which reliably
capture critical intermediate actions or states necessary for task completions
while disregarding noise caused by insignificant events or changed
web-elements. (2) A benchmark dataset called Mind2Web-Live, a refined version
of original Mind2Web static dataset containing 542 tasks with 2439 intermediate
evaluation states; (3) Lightweight and generalizable annotation tools and
testing pipelines that enables the community to collect and maintain the
high-quality, up-to-date dataset. Building on WebCanvas, we open-source an
agent framework with extensible modules for reasoning, providing a foundation
for the community to conduct online inference and evaluations. Our
best-performing agent achieves a task success rate of 23.1% and a task
completion rate of 48.8% on the Mind2Web-Live test set. Additionally, we
analyze the performance discrepancies across various websites, domains, and
experimental environments. We encourage the community to contribute further
insights on online agent evaluation, thereby advancing this field of research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our platform, tool and dataset are publically available at
  https://www.imean.ai/web-canvas/ and
  https://huggingface.co/datasets/iMeanAI/Mind2Web-Live/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07610v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07610v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoyu Wang, Guozheng Ma, Ziqiao Meng, Zeyu Qin, Li Shen, Zhong Zhang, Bingzhe Wu, Liu Liu, Yatao Bian, Tingyang Xu, Xueqian Wang, Peilin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-alignment is an effective way to reduce the cost of human annotation
while ensuring promising model capability. However, most current methods
complete the data collection and training steps in a single round, which may
overlook the continuously improving ability of self-aligned models. This gives
rise to a key query: What if we do multi-time bootstrapping self-alignment?
Does this strategy enhance model performance or lead to rapid degradation? In
this paper, our pioneering exploration delves into the impact of bootstrapping
self-alignment on large language models. Our findings reveal that bootstrapping
self-alignment markedly surpasses the single-round approach, by guaranteeing
data diversity from in-context learning. To further exploit the capabilities of
bootstrapping, we investigate and adjust the training order of data, which
yields improved performance of the model. Drawing on these findings, we propose
Step-On-Feet Tuning (SOFT) which leverages model's continuously enhanced
few-shot ability to boost zero or one-shot performance. Based on easy-to-hard
training recipe, we propose SOFT+ which further boost self-alignment's
performance. Our experiments demonstrate the efficiency of SOFT (SOFT+) across
various classification and generation tasks, highlighting the potential of
bootstrapping self-alignment on continually enhancing model alignment
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Thermometer: Towards Universal Calibration for Large Language Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.08819v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.08819v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maohao Shen, Subhro Das, Kristjan Greenewald, Prasanna Sattigeri, Gregory Wornell, Soumya Ghosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the issue of calibration in large language models (LLM). Recent
studies have found that common interventions such as instruction tuning often
result in poorly calibrated LLMs. Although calibration is well-explored in
traditional applications, calibrating LLMs is uniquely challenging. These
challenges stem as much from the severe computational requirements of LLMs as
from their versatility, which allows them to be applied to diverse tasks.
Addressing these challenges, we propose THERMOMETER, a calibration approach
tailored to LLMs. THERMOMETER learns an auxiliary model, given data from
multiple tasks, for calibrating a LLM. It is computationally efficient,
preserves the accuracy of the LLM, and produces better-calibrated responses for
new tasks. Extensive empirical evaluations across various benchmarks
demonstrate the effectiveness of the proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera ready version for ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MuTox: Universal MUltilingual Audio-based TOXicity <span class="highlight-title">Dataset</span> and Zero-shot
  Detector 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05060v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05060v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marta R. Costa-jussà, Mariano Coria Meglioli, Pierre Andrews, David Dale, Prangthip Hansanti, Elahe Kalbassi, Alex Mourachko, Christophe Ropers, Carleigh Wood
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research in toxicity detection in natural language processing for the speech
modality (audio-based) is quite limited, particularly for languages other than
English. To address these limitations and lay the groundwork for truly
multilingual audio-based toxicity detection, we introduce MuTox, the first
highly multilingual audio-based dataset with toxicity labels. The dataset
comprises 20,000 audio utterances for English and Spanish, and 4,000 for the
other 19 languages. To demonstrate the quality of this dataset, we trained the
MuTox audio-based toxicity classifier, which enables zero-shot toxicity
detection across a wide range of languages. This classifier outperforms
existing text-based trainable classifiers by more than 1% AUC, while expanding
the language coverage more than tenfold. When compared to a wordlist-based
classifier that covers a similar number of languages, MuTox improves precision
and recall by approximately 2.5 times. This significant improvement underscores
the potential of MuTox in advancing the field of audio-based toxicity
detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Meta<span class="highlight-title">GPT</span>: Merging Large Language Models Using Model Exclusive Task
  Arithmetic 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyan Zhou, Liang Song, Bingning Wang, Weipeng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of large language models (LLMs) like GPT-4 has catalyzed the
exploration of multi-task learning (MTL), in which a single model demonstrates
proficiency across diverse tasks. Task arithmetic has emerged as a
cost-effective approach for MTL. It enables performance enhancement across
multiple tasks by adding their corresponding task vectors to a pre-trained
model. However, the current lack of a method that can simultaneously achieve
optimal performance, computational efficiency, and data privacy limits their
application to LLMs. In this paper, we propose \textbf{M}odel
\textbf{E}xclusive \textbf{T}ask \textbf{A}rithmetic for merging
\textbf{GPT}-scale models, which formalizes the objective of model merging into
a multi-task learning framework, aiming to minimize the average loss difference
between the merged model and each individual task model. Since data privacy
limits the use of multi-task training data, we leverage LLMs' local linearity
and task vectors' orthogonality to separate the data term and scaling
coefficients term and derive a model-exclusive task arithmetic method. Our
proposed MetaGPT is data-agnostic and bypasses the heavy search process, making
it cost-effective and easy to implement for LLMs.Extensive experiments
demonstrate that MetaGPT leads to improvements in task arithmetic and achieves
state-of-the-art performance on multiple tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CLERC: A <span class="highlight-title">Dataset</span> for Legal Case Retrieval and Retrieval-Augmented
  Analysis Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17186v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17186v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abe Bohan Hou, Orion Weller, Guanghui Qin, Eugene Yang, Dawn Lawrie, Nils Holzenberger, Andrew Blair-Stanek, Benjamin Van Durme
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal professionals need to write analyses that rely on citations to relevant
precedents, i.e., previous case decisions. Intelligent systems assisting legal
professionals in writing such documents provide great benefits but are
challenging to design. Such systems need to help locate, summarize, and reason
over salient precedents in order to be useful. To enable systems for such
tasks, we work with legal professionals to transform a large open-source legal
corpus into a dataset supporting two important backbone tasks: information
retrieval (IR) and retrieval-augmented generation (RAG). This dataset CLERC
(Case Law Evaluation Retrieval Corpus), is constructed for training and
evaluating models on their ability to (1) find corresponding citations for a
given piece of legal analysis and to (2) compile the text of these citations
(as well as previous context) into a cogent analysis that supports a reasoning
goal. We benchmark state-of-the-art models on CLERC, showing that current
approaches still struggle: GPT-4o generates analyses with the highest ROUGE
F-scores but hallucinates the most, while zero-shot IR models only achieve
48.3% recall@1000.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assessing the nature of large language models: A caution against
  anthropocentrism 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.07683v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.07683v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ann Speed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative AI models garnered a large amount of public attention and
speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion
camps exist: one excited about possibilities these models offer for fundamental
changes to human tasks, and another highly concerned about power these models
seem to have. To address these concerns, we assessed several LLMs, primarily
GPT 3.5, using standard, normed, and validated cognitive and personality
measures. For this seedling project, we developed a battery of tests that
allowed us to estimate the boundaries of some of these models capabilities, how
stable those capabilities are over a short period of time, and how they compare
to humans. Our results indicate that LLMs are unlikely to have developed
sentience, although its ability to respond to personality inventories is
interesting. GPT3.5 did display large variability in both cognitive and
personality measures over repeated observations, which is not expected if it
had a human-like personality. Variability notwithstanding, LLMs display what in
a human would be considered poor mental health, including low self-esteem,
marked dissociation from reality, and in some cases narcissism and psychopathy,
despite upbeat and helpful responses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Muffin or Chihuahua? Challenging Multimodal Large Language Models with
  Multipanel VQA <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.15847v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.15847v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Fan, Jing Gu, Kaiwen Zhou, Qianqi Yan, Shan Jiang, Ching-Chen Kuo, Xinze Guan, Xin Eric Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multipanel images, commonly seen as web screenshots, posters, etc., pervade
our daily lives. These images, characterized by their composition of multiple
subfigures in distinct layouts, effectively convey information to people.
Toward building advanced multimodal AI applications, such as agents that
understand complex scenes and navigate through webpages, the skill of
multipanel visual reasoning is essential, and a comprehensive evaluation of
models in this regard is important. Therefore, we introduce Multipanel Visual
Question Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets
of questions, answers, and multipanel images that specifically challenge models
in comprehending multipanel images. Our evaluation shows that questions in the
MultipanelVQA benchmark pose significant challenges to the state-of-the-art
Multimodal Large Language Models (MLLMs) tested, even though humans can attain
approximately 99% accuracy on these questions. Distinctively, the MultipanelVQA
benchmark features synthetically generated multipanel images specifically
crafted to isolate and assess the impact of various factors, such as the
layout, on MLLMs' multipanel image comprehension abilities. As a result, in
addition to benchmarking the capabilities of MLLMs in understanding multipanel
images, we analyze various factors of the multipanel image that affect MLLMs'
performance with synthetic data and offer insights for enhancement. Code and
data are released at https://sites.google.com/view/multipanelvqa/home.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unified Active Retrieval for Retrieval Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12534v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12534v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinyuan Cheng, Xiaonan Li, Shimin Li, Qin Zhu, Zhangyue Yin, Yunfan Shao, Linyang Li, Tianxiang Sun, Hang Yan, Xipeng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Retrieval-Augmented Generation (RAG), retrieval is not always helpful and
applying it to every instruction is sub-optimal. Therefore, determining whether
to retrieve is crucial for RAG, which is usually referred to as Active
Retrieval. However, existing active retrieval methods face two challenges: 1.
They usually rely on a single criterion, which struggles with handling various
types of instructions. 2. They depend on specialized and highly differentiated
procedures, and thus combining them makes the RAG system more complicated and
leads to higher response latency. To address these challenges, we propose
Unified Active Retrieval (UAR). UAR contains four orthogonal criteria and casts
them into plug-and-play classification tasks, which achieves multifaceted
retrieval timing judgements with negligible extra inference cost. We further
introduce the Unified Active Retrieval Criteria (UAR-Criteria), designed to
process diverse active retrieval scenarios through a standardized procedure.
Experiments on four representative types of user instructions show that UAR
significantly outperforms existing work on the retrieval timing judgement and
the performance of downstream tasks, which shows the effectiveness of UAR and
its helpfulness to downstream tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReFT: Reasoning with Reinforced Fine-Tuning <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.08967v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.08967v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung Quoc Luong, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, Hang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One way to enhance the reasoning capability of Large Language Models (LLMs)
is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT)
annotations. This approach does not show sufficiently strong generalization
ability, however, because the training only relies on the given CoT data. In
math problem-solving, for example, there is usually only one annotated
reasoning path for each question in the training data. Intuitively, it would be
better for the algorithm to learn from multiple annotated reasoning paths given
a question. To address this issue, we propose a simple yet effective approach
called Reinforced Fine-Tuning (ReFT) to enhance the generalizability of
learning LLMs for reasoning, with math problem-solving as an example. ReFT
first warmups the model with SFT, and then employs on-line reinforcement
learning, specifically the PPO algorithm in this paper, to further fine-tune
the model, where an abundance of reasoning paths are automatically sampled
given the question and the rewards are naturally derived from the ground-truth
answers. Extensive experiments on GSM8K, MathQA, and SVAMP datasets show that
ReFT significantly outperforms SFT, and the performance can be potentially
further boosted by combining inference-time strategies such as majority voting
and re-ranking. Note that ReFT obtains the improvement by learning from the
same training questions as SFT, without relying on extra or augmented training
questions. This indicates a superior generalization ability for ReFT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 main conference; adjust with reviewer comments; 13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Token-level Direct Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11999v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11999v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongcheng Zeng, Guoqing Liu, Weiyu Ma, Ning Yang, Haifeng Zhang, Jun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning pre-trained Large Language Models (LLMs) is essential to align
them with human values and intentions. This process often utilizes methods like
pairwise comparisons and KL divergence against a reference LLM, focusing on the
evaluation of full answers generated by the models. However, the generation of
these responses occurs in a token level, following a sequential,
auto-regressive fashion. In this paper, we introduce Token-level Direct
Preference Optimization (TDPO), a novel approach to align LLMs with human
preferences by optimizing policy at the token level. Unlike previous methods,
which face challenges in divergence efficiency, TDPO incorporates forward KL
divergence constraints for each token, improving alignment and diversity.
Utilizing the Bradley-Terry model for a token-based reward system, TDPO
enhances the regulation of KL divergence, while preserving simplicity without
the need for explicit reward modeling. Experimental results across various text
tasks demonstrate TDPO's superior performance in balancing alignment with
generation diversity. Notably, fine-tuning with TDPO strikes a better balance
than DPO in the controlled sentiment generation and single-turn dialogue
datasets, and significantly improves the quality of generated responses
compared to both DPO and PPO-based RLHF methods. Our code is open-sourced at
https://github.com/Vance0124/Token-level-Direct-Preference-Optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MedCalc-Bench: Evaluating Large Language Models for Medical Calculations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12036v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12036v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikhil Khandekar, Qiao Jin, Guangzhi Xiong, Soren Dunn, Serina S Applebaum, Zain Anwar, Maame Sarfo-Gyamfi, Conrad W Safranek, Abid A Anwar, Andrew Zhang, Aidan Gilson, Maxwell B Singer, Amisha Dave, Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As opposed to evaluating computation and logic-based reasoning, current
benchmarks for evaluating large language models (LLMs) in medicine are
primarily focused on question-answering involving domain knowledge and
descriptive reasoning. While such qualitative capabilities are vital to medical
diagnosis, in real-world scenarios, doctors frequently use clinical calculators
that follow quantitative equations and rule-based reasoning paradigms for
evidence-based decision support. To this end, we propose MedCalc-Bench, a
first-of-its-kind dataset focused on evaluating the medical calculation
capability of LLMs. MedCalc-Bench contains an evaluation set of over 1000
manually reviewed instances from 55 different medical calculation tasks. Each
instance in MedCalc-Bench consists of a patient note, a question requesting to
compute a specific medical value, a ground truth answer, and a step-by-step
explanation showing how the answer is obtained. While our evaluation results
show the potential of LLMs in this area, none of them are effective enough for
clinical settings. Common issues include extracting the incorrect entities, not
using the correct equation or rules for a calculation task, or incorrectly
performing the arithmetic for the computation. We hope our study highlights the
quantitative knowledge and reasoning gaps in LLMs within medical settings,
encouraging future improvements of LLMs for various clinical calculation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github link: https://github.com/ncbi-nlp/MedCalc-Bench HuggingFace
  link: https://huggingface.co/datasets/nsk7153/MedCalc-Bench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Daisy-TTS: Simulating Wider Spectrum of Emotions via Prosody Embedding
  Decomposition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14523v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14523v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rendi Chevi, Alham Fikri Aji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We often verbally express emotions in a multifaceted manner, they may vary in
their intensities and may be expressed not just as a single but as a mixture of
emotions. This wide spectrum of emotions is well-studied in the structural
model of emotions, which represents variety of emotions as derivative products
of primary emotions with varying degrees of intensity. In this paper, we
propose an emotional text-to-speech design to simulate a wider spectrum of
emotions grounded on the structural model. Our proposed design, Daisy-TTS,
incorporates a prosody encoder to learn emotionally-separable prosody embedding
as a proxy for emotion. This emotion representation allows the model to
simulate: (1) Primary emotions, as learned from the training samples, (2)
Secondary emotions, as a mixture of primary emotions, (3) Intensity-level, by
scaling the emotion embedding, and (4) Emotions polarity, by negating the
emotion embedding. Through a series of perceptual evaluations, Daisy-TTS
demonstrated overall higher emotional speech naturalness and emotion
perceiveability compared to the baseline.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://rendchevi.github.io/daisy-tts; Updates: (1)
  Fixed typos, missing references, and layout, (2) Revise explanation on
  emotion classifier or discriminator</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">60</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PathAlign: A vision-language model for whole slide images in
  histopathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 main pages and 19 pages of supplemental material; 3 main tables, 3
  main figures and 11 supplemental tables, 7 supplemental figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Matters in Detecting AI-Generated Videos like Sora? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19568v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19568v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chirui Chang, Zhengzhe Liu, Xiaoyang Lyu, Xiaojuan Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in diffusion-based video generation have showcased
remarkable results, yet the gap between synthetic and real-world videos remains
under-explored. In this study, we examine this gap from three fundamental
perspectives: appearance, motion, and geometry, comparing real-world videos
with those generated by a state-of-the-art AI model, Stable Video Diffusion. To
achieve this, we train three classifiers using 3D convolutional networks, each
targeting distinct aspects: vision foundation model features for appearance,
optical flow for motion, and monocular depth for geometry. Each classifier
exhibits strong performance in fake video detection, both qualitatively and
quantitatively. This indicates that AI-generated videos are still easily
detectable, and a significant gap between real and fake videos persists.
Furthermore, utilizing the Grad-CAM, we pinpoint systematic failures of
AI-generated videos in appearance, motion, and geometry. Finally, we propose an
Ensemble-of-Experts model that integrates appearance, optical flow, and depth
information for fake video detection, resulting in enhanced robustness and
generalization ability. Our model is capable of detecting videos generated by
Sora with high accuracy, even without exposure to any Sora videos during
training. This suggests that the gap between real and fake videos can be
generalized across various video generative models. Project page:
https://justin-crchang.github.io/3DCNNDetection.github.io/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cost-efficient Active Illumination Camera For Hyper-spectral
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhang, T. M. Sazzad, Yangyang Song, Spencer J. Chang, Ritesh Chowdhry, Tomas Mejia, Anna Hampton, Shelby Kucharski, Stefan Gerber, Barry Tillman, Marcio F. R. Resende, William M. Hammond, Chris H. Wilson, Alina Zare, Sanjeev J. Koppal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hyper-spectral imaging has recently gained increasing attention for use in
different applications, including agricultural investigation, ground tracking,
remote sensing and many other. However, the high cost, large physical size and
complicated operation process stop hyperspectral cameras from being employed
for various applications and research fields. In this paper, we introduce a
cost-efficient, compact and easy to use active illumination camera that may
benefit many applications. We developed a fully functional prototype of such
camera. With the hope of helping with agricultural research, we tested our
camera for plant root imaging. In addition, a U-Net model for spectral
reconstruction was trained by using a reference hyperspectral camera's data as
ground truth and our camera's data as input. We demonstrated our camera's
ability to obtain additional information over a typical RGB camera. In
addition, the ability to reconstruct hyperspectral data from multi-spectral
input makes our device compatible to models and algorithms developed for
hyperspectral applications with no modifications required.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robustness Testing of Black-Box Models Against CT Degradation Through
  Test-Time Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jack Highton, Quok Zong Chong, Samuel Finestone, Arian Beqiri, Julia A. Schnabel, Kanwal K. Bhatia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning models for medical image segmentation and object detection are
becoming increasingly available as clinical products. However, as details are
rarely provided about the training data, models may unexpectedly fail when
cases differ from those in the training distribution. An approach allowing
potential users to independently test the robustness of a model, treating it as
a black box and using only a few cases from their own site, is key for
adoption. To address this, a method to test the robustness of these models
against CT image quality variation is presented. In this work we present this
framework by demonstrating that given the same training data, the model
architecture and data pre processing greatly affect the robustness of several
frequently used segmentation and object detection methods to simulated CT
imaging artifacts and degradation. Our framework also addresses the concern
about the sustainability of deep learning models in clinical use, by
considering future shifts in image quality due to scanner deterioration or
imaging protocol changes which are not reflected in a limited local test
dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BOrg: A Brain Organoid-Based Mitosis <span class="highlight-title">Dataset</span> for Automatic Analysis of
  Brain Diseases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Awais, Mehaboobathunnisa Sahul Hameed, Bidisha Bhattacharya, Orly Reiner, Rao Muhammad Anwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances have enabled the study of human brain development using brain
organoids derived from stem cells. Quantifying cellular processes like mitosis
in these organoids offers insights into neurodevelopmental disorders, but the
manual analysis is time-consuming, and existing datasets lack specific details
for brain organoid studies. We introduce BOrg, a dataset designed to study
mitotic events in the embryonic development of the brain using confocal
microscopy images of brain organoids. BOrg utilizes an efficient annotation
pipeline with sparse point annotations and techniques that minimize expert
effort, overcoming limitations of standard deep learning approaches on sparse
data. We adapt and benchmark state-of-the-art object detection and cell
counting models on BOrg for detecting and analyzing mitotic cells across
prophase, metaphase, anaphase, and telophase stages. Our results demonstrate
these adapted models significantly improve mitosis analysis efficiency and
accuracy for brain organoid research compared to existing methods. BOrg
facilitates the development of automated tools to quantify statistics like
mitosis rates, aiding mechanistic studies of neurodevelopmental processes and
disorders. Data and code are available at https://github.com/awaisrauf/borg.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Weighted Circle Fusion: Ensembling Circle Representation from Different
  Object Detection Results 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jialin Yue, Tianyuan Yao, Ruining Deng, Quan Liu, Juming Xiong, Haichun Yang, Yuankai Huo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the use of circle representation has emerged as a method to improve
the identification of spherical objects (such as glomeruli, cells, and nuclei)
in medical imaging studies. In traditional bounding box-based object detection,
combining results from multiple models improves accuracy, especially when
real-time processing isn't crucial. Unfortunately, this widely adopted strategy
is not readily available for combining circle representations. In this paper,
we propose Weighted Circle Fusion (WCF), a simple approach for merging
predictions from various circle detection models. Our method leverages
confidence scores associated with each proposed bounding circle to generate
averaged circles. Our method undergoes thorough evaluation on a proprietary
dataset for glomerular detection in object detection within whole slide imaging
(WSI). The findings reveal a performance gain of 5 %, respectively, compared to
existing ensemble methods. Furthermore, the Weighted Circle Fusion technique
not only improves the precision of object detection in medical images but also
notably decreases false detections, presenting a promising direction for future
research and application in pathological image analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparative Analysis Of Color Models For Human Perception And Visual
  Color Difference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aruzhan Burambekova, Pakizar Shamoi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Color is integral to human experience, influencing emotions, decisions, and
perceptions. This paper presents a comparative analysis of various color
models' alignment with human visual perception. The study evaluates color
models such as RGB, HSV, HSL, XYZ, CIELAB, and CIELUV to assess their
effectiveness in accurately representing how humans perceive color. We evaluate
each model based on its ability to accurately reflect visual color differences
and dominant palette extraction compatible with the human eye. In image
processing, accurate assessment of color difference is essential for
applications ranging from digital design to quality control. Current color
difference metrics do not always match how people see colors, causing issues in
accurately judging subtle differences. Understanding how different color models
align with human visual perception is crucial for various applications in image
processing, digital media, and design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper has been submitted to EJMCA journal for consideration.
  Current version is a preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stereo Vision Based Robot for Remote Monitoring with VR Support 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19498v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19498v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Fazil M. S., Arockia Selvakumar A., Daniel Schilberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The machine vision systems have been playing a significant role in visual
monitoring systems. With the help of stereovision and machine learning, it will
be able to mimic human-like visual system and behaviour towards the
environment. In this paper, we present a stereo vision based 3-DOF robot which
will be used to monitor places from remote using cloud server and internet
devices. The 3-DOF robot will transmit human-like head movements, i.e., yaw,
pitch, roll and produce 3D stereoscopic video and stream it in Real-time. This
video stream is sent to the user through any generic internet devices with VR
box support, i.e., smartphones giving the user a First-person real-time 3D
experience and transfers the head motion of the user to the robot also in
Real-time. The robot will also be able to track moving objects and faces as a
target using deep neural networks which enables it to be a standalone
monitoring robot. The user will be able to choose specific subjects to monitor
in a space. The stereovision enables us to track the depth information of
different objects detected and will be used to track human interest objects
with its distances and sent to the cloud. A full working prototype is developed
which showcases the capabilities of a monitoring system based on stereo vision,
robotics, and machine learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 Pages, 10 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ High-resolution segmentations of the hypothalamus and its subregions for
  training of segmentation models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Livia Rodrigues, Martina Bocchetta, Oula Puonti, Douglas Greve, Ana Carolina Londe, Marcondes França, Simone Appenzeller, Leticia Rittner, Juan Eugenio Iglesias
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Segmentation of brain structures on magnetic resonance imaging (MRI) is a
highly relevant neuroimaging topic, as it is a prerequisite for different
analyses such as volumetry or shape analysis. Automated segmentation
facilitates the study of brain structures in larger cohorts when compared with
manual segmentation, which is time-consuming. However, the development of most
automated methods relies on large and manually annotated datasets, which limits
the generalizability of these methods. Recently, new techniques using synthetic
images have emerged, reducing the need for manual annotation. Here we provide
HELM, Hypothalamic ex vivo Label Maps, a dataset composed of label maps built
from publicly available ultra-high resolution ex vivo MRI from 10 whole
hemispheres, which can be used to develop segmentation methods using synthetic
data. The label maps are obtained with a combination of manual labels for the
hypothalamic regions and automated segmentations for the rest of the brain, and
mirrored to simulate entire brains. We also provide the pre-processed ex vivo
scans, as this dataset can support future projects to include other structures
after these are manually segmented.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GAPNet: Granularity Attention Network with Anatomy-Prior-Constraint for
  Carotid Artery Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19485v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19485v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin Zhang, Chenggang Lu, Xin-yang Shi, Caifeng Shan, Jiong Zhang, Da Chen, Laurent D. Cohen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Atherosclerosis is a chronic, progressive disease that primarily affects the
arterial walls. It is one of the major causes of cardiovascular disease.
Magnetic Resonance (MR) black-blood vessel wall imaging (BB-VWI) offers crucial
insights into vascular disease diagnosis by clearly visualizing vascular
structures. However, the complex anatomy of the neck poses challenges in
distinguishing the carotid artery (CA) from surrounding structures, especially
with changes like atherosclerosis. In order to address these issues, we propose
GAPNet, which is a consisting of a novel geometric prior deduced from.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyi Liu, Cheng Chi, Eric Cousineau, Naveen Kuppuswamy, Benjamin Burchfiel, Shuran Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio signals provide rich information for the robot interaction and object
properties through contact. These information can surprisingly ease the
learning of contact-rich robot manipulation skills, especially when the visual
information alone is ambiguous or incomplete. However, the usage of audio data
in robot manipulation has been constrained to teleoperated demonstrations
collected by either attaching a microphone to the robot or object, which
significantly limits its usage in robot learning pipelines. In this work, we
introduce ManiWAV: an 'ear-in-hand' data collection device to collect
in-the-wild human demonstrations with synchronous audio and visual feedback,
and a corresponding policy interface to learn robot manipulation policy
directly from the demonstrations. We demonstrate the capabilities of our system
through four contact-rich manipulation tasks that require either passively
sensing the contact events and modes, or actively sensing the object surface
materials and states. In addition, we show that our system can generalize to
unseen in-the-wild environments, by learning from diverse in-the-wild human
demonstrations. Project website: https://mani-wav.github.io/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient and Distributed Large-Scale 3D Map Registration using
  Tomographic Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19461v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19461v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Halil Utku Unlu, Anthony Tzes, Prashanth Krishnamurthy, Farshad Khorrami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A robust, resource-efficient, distributed, and minimally parameterized 3D map
matching and merging algorithm is proposed. The suggested algorithm utilizes
tomographic features from 2D projections of horizontal cross-sections of
gravity-aligned local maps, and matches these projection slices at all possible
height differences, enabling the estimation of four degrees of freedom in an
efficient and parallelizable manner. The advocated algorithm improves
state-of-the-art feature extraction and registration pipelines by an order of
magnitude in memory use and execution time. Experimental studies are offered to
investigate the efficiency of this 3D map merging scheme.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to Elsevier Journal: Robotics and Autonomous Systems (RAS)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Dataset</span> Size Recovery from LoRA Weights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19395v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19395v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Salama, Jonathan Kahana, Eliahu Horwitz, Yedid Hoshen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model inversion and membership inference attacks aim to reconstruct and
verify the data which a model was trained on. However, they are not guaranteed
to find all training samples as they do not know the size of the training set.
In this paper, we introduce a new task: dataset size recovery, that aims to
determine the number of samples used to train a model, directly from its
weights. We then propose DSiRe, a method for recovering the number of images
used to fine-tune a model, in the common case where fine-tuning uses LoRA. We
discover that both the norm and the spectrum of the LoRA matrices are closely
linked to the fine-tuning dataset size; we leverage this finding to propose a
simple yet effective prediction algorithm. To evaluate dataset size recovery of
LoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of
over 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.
Our best classifier can predict the number of fine-tuning images with a mean
absolute error of 0.36 images, establishing the feasibility of this attack.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HUWSOD: Holistic Self-training for Unified Weakly Supervised Object
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19394v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19394v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liujuan Cao, Jianghang Lin, Zebo Hong, Yunhang Shen, Shaohui Lin, Chao Chen, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most WSOD methods rely on traditional object proposals to generate candidate
regions and are confronted with unstable training, which easily gets stuck in a
poor local optimum. In this paper, we introduce a unified, high-capacity weakly
supervised object detection (WSOD) network called HUWSOD, which utilizes a
comprehensive self-training framework without needing external modules or
additional supervision. HUWSOD innovatively incorporates a self-supervised
proposal generator and an autoencoder proposal generator with a multi-rate
resampling pyramid to replace traditional object proposals, enabling end-to-end
WSOD training and inference. Additionally, we implement a holistic
self-training scheme that refines detection scores and coordinates through
step-wise entropy minimization and consistency-constraint regularization,
ensuring consistent predictions across stochastic augmentations of the same
image. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD
competes with state-of-the-art WSOD methods, eliminating the need for offline
proposals and additional data. The peak performance of HUWSOD approaches that
of fully-supervised Faster R-CNN. Our findings also indicate that randomly
initialized boxes, although significantly different from well-designed offline
object proposals, are effective for WSOD training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Sanity Check for AI-generated Image Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shilin Yan, Ouxiang Li, Jiayin Cai, Yanbin Hao, Xiaolong Jiang, Yao Hu, Weidi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of generative models, discerning AI-generated
content has evoked increasing attention from both industry and academia. In
this paper, we conduct a sanity check on "whether the task of AI-generated
image detection has been solved". To start with, we present Chameleon dataset,
consisting AIgenerated images that are genuinely challenging for human
perception. To quantify the generalization of existing methods, we evaluate 9
off-the-shelf AI-generated image detectors on Chameleon dataset. Upon analysis,
almost all models classify AI-generated images as real ones. Later, we propose
AIDE (AI-generated Image DEtector with Hybrid Features), which leverages
multiple experts to simultaneously extract visual artifacts and noise patterns.
Specifically, to capture the high-level semantics, we utilize CLIP to compute
the visual embedding. This effectively enables the model to discern
AI-generated images based on semantics or contextual information; Secondly, we
select the highest frequency patches and the lowest frequency patches in the
image, and compute the low-level patchwise features, aiming to detect
AI-generated images by low-level artifacts, for example, noise pattern,
anti-aliasing, etc. While evaluating on existing benchmarks, for example,
AIGCDetectBenchmark and GenImage, AIDE achieves +3.5% and +4.6% improvements to
state-of-the-art methods, and on our proposed challenging Chameleon benchmarks,
it also achieves the promising results, despite this problem for detecting
AI-generated images is far from being solved. The dataset, codes, and pre-train
models will be published at https://github.com/shilinyan99/AIDE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://shilinyan99.github.io/AIDE Code:
  https://github.com/shilinyan99/AIDE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Looking 3D: Anomaly Detection with 2D-3D Alignment <span class="chip">CVPR'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19393v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19393v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ankan Bhunia, Changjian Li, Hakan Bilen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic anomaly detection based on visual cues holds practical significance
in various domains, such as manufacturing and product quality assessment. This
paper introduces a new conditional anomaly detection problem, which involves
identifying anomalies in a query image by comparing it to a reference shape. To
address this challenge, we have created a large dataset, BrokenChairs-180K,
consisting of around 180K images, with diverse anomalies, geometries, and
textures paired with 8,143 reference 3D shapes. To tackle this task, we have
proposed a novel transformer-based approach that explicitly learns the
correspondence between the query image and reference 3D shape via feature
alignment and leverages a customized attention mechanism for anomaly detection.
Our approach has been rigorously evaluated through comprehensive experiments,
serving as a benchmark for future research in this domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR'24. Codes & dataset available at
  https://github.com/VICO-UoE/Looking3D</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19392v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19392v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jr-Jen Chen, Yu-Chien Liao, Hsi-Che Lin, Yu-Chu Yu, Yen-Chun Chen, Yu-Chiang Frank Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce ReXTime, a benchmark designed to rigorously test AI models'
ability to perform temporal reasoning within video events. Specifically,
ReXTime focuses on reasoning across time, i.e. human-like understanding when
the question and its corresponding answer occur in different video segments.
This form of reasoning, requiring advanced understanding of cause-and-effect
relationships across video segments, poses significant challenges to even the
frontier multimodal large language models. To facilitate this evaluation, we
develop an automated pipeline for generating temporal reasoning question-answer
pairs, significantly reducing the need for labor-intensive manual annotations.
Our benchmark includes 921 carefully vetted validation samples and 2,143 test
samples, each manually curated for accuracy and relevance. Evaluation results
show that while frontier large language models outperform academic models, they
still lag behind human performance by a significant 14.3% accuracy gap.
Additionally, our pipeline creates a training dataset of 9,695 machine
generated samples without manual effort, which empirical studies suggest can
enhance the across-time reasoning via fine-tuning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fibottention: Inceptive Visual Representation Learning with Diverse
  Attention Across Heads 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19391v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19391v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Khaleghi Rahimian, Manish Kumar Govind, Subhajit Maity, Dominick Reilly, Christian Kümmerle, Srijan Das, Aritra Dutta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual perception tasks are predominantly solved by Vision Transformer (ViT)
architectures, which, despite their effectiveness, encounter a computational
bottleneck due to the quadratic complexity of computing self-attention. This
inefficiency is largely due to the self-attention heads capturing redundant
token interactions, reflecting inherent redundancy within visual data. Many
works have aimed to reduce the computational complexity of self-attention in
ViTs, leading to the development of efficient and sparse transformer
architectures. In this paper, viewing through the efficiency lens, we realized
that introducing any sparse self-attention strategy in ViTs can keep the
computational overhead low. However, these strategies are sub-optimal as they
often fail to capture fine-grained visual details. This observation leads us to
propose a general, efficient, sparse architecture, named Fibottention, for
approximating self-attention with superlinear complexity that is built upon
Fibonacci sequences. The key strategies in Fibottention include: it excludes
proximate tokens to reduce redundancy, employs structured sparsity by design to
decrease computational demands, and incorporates inception-like diversity
across attention heads. This diversity ensures the capture of complementary
information through non-overlapping token interactions, optimizing both
performance and resource utilization in ViTs for visual representation
learning. We embed our Fibottention mechanism into multiple state-of-the-art
transformer architectures dedicated to visual tasks. Leveraging only 2-6% of
the elements in the self-attention heads, Fibottention in conjunction with ViT
and its variants, consistently achieves significant performance boosts compared
to standard ViTs in nine datasets across three domains $\unicode{x2013}$ image
classification, video understanding, and robot learning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code is publicly available at
  https://github.com/Charlotte-CharMLab/Fibottention</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SALVe: Semantic Alignment Verification for Floorplan Reconstruction from
  Sparse Panoramas <span class="chip">ECCV 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19390v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19390v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Lambert, Yuguang Li, Ivaylo Boyadzhiev, Lambert Wixson, Manjunath Narayana, Will Hutchcroft, James Hays, Frank Dellaert, Sing Bing Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a new system for automatic 2D floorplan reconstruction that is
enabled by SALVe, our novel pairwise learned alignment verifier. The inputs to
our system are sparsely located 360$^\circ$ panoramas, whose semantic features
(windows, doors, and openings) are inferred and used to hypothesize pairwise
room adjacency or overlap. SALVe initializes a pose graph, which is
subsequently optimized using GTSAM. Once the room poses are computed, room
layouts are inferred using HorizonNet, and the floorplan is constructed by
stitching the most confident layout boundaries. We validate our system
qualitatively and quantitatively as well as through ablation studies, showing
that it outperforms state-of-the-art SfM systems in completeness by over 200%,
without sacrificing accuracy. Our results point to the significance of our
work: poses of 81% of panoramas are localized in the first 2 connected
components (CCs), and 89% in the first 3 CCs. Code and models are publicly
available at https://github.com/zillow/salve.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ECCV 2022</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and
  Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19389v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19389v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Zhang, Xiangtai Li, Hao Fei, Haobo Yuan, Shengqiong Wu, Shunping Ji, Chen Change Loy, Shuicheng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current universal segmentation methods demonstrate strong capabilities in
pixel-level image and video understanding. However, they lack reasoning
abilities and cannot be controlled via text instructions. In contrast, large
vision-language multimodal models exhibit powerful vision-based conversation
and reasoning capabilities but lack pixel-level understanding and have
difficulty accepting visual prompts for flexible user interaction. This paper
proposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level
vision understanding with reasoning abilities. It can accept various visual and
text prompts for flexible user interaction. Specifically, we use a universal
segmentation method as the visual encoder, integrating image information,
perception priors, and visual prompts into visual tokens provided to the LLM.
The LLM is responsible for understanding the user's text instructions and
providing text responses and pixel-level segmentation results based on the
visual information. We propose perception prior embedding to better integrate
perception priors with image features. OMG-LLaVA achieves image-level,
object-level, and pixel-level reasoning and understanding in a single model,
matching or surpassing the performance of specialized methods on multiple
benchmarks. Rather than using LLM to connect each specialist, our work aims at
end-to-end training on one encoder, one decoder, and one LLM. The code and
model have been released for further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Taming Data and <span class="highlight-title">Transformer</span>s for Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19388v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19388v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating ambient sounds and effects is a challenging problem due to data
scarcity and often insufficient caption quality, making it difficult to employ
large-scale generative models for the task. In this work, we tackle the problem
by introducing two new models. First, we propose AutoCap, a high-quality and
efficient automatic audio captioning model. We show that by leveraging metadata
available with the audio modality, we can substantially improve the quality of
captions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from
the best available captioning model at four times faster inference speed. We
then use AutoCap to caption clips from existing datasets, obtaining 761,000
audio clips with high-quality captions, forming the largest available
audio-text dataset. Second, we propose GenAu, a scalable transformer-based
audio generation architecture that we scale up to 1.25B parameters and train
with our new dataset. When compared to state-of-the-art audio generators, GenAu
obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%
in CLAP score, indicating significantly improved quality of generated audio
compared to previous works. This shows that the quality of data is often as
important as its quantity. Besides, since AutoCap is fully automatic, new audio
samples can be added to the training dataset, unlocking the training of even
larger generative models for audio synthesis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Webpage: https://snap-research.github.io/GenAU/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment
  Anything Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haobo Yuan, Xiangtai Li, Lu Qi, Tao Zhang, Ming-Hsuan Yang, Shuicheng Yan, Chen Change Loy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based segmentation methods face the challenge of efficient
inference when dealing with high-resolution images. Recently, several linear
attention architectures, such as Mamba and RWKV, have attracted much attention
as they can process long sequences efficiently. In this work, we focus on
designing an efficient segment-anything model by exploring these different
architectures. Specifically, we design a mixed backbone that contains
convolution and RWKV operation, which achieves the best for both accuracy and
efficiency. In addition, we design an efficient decoder to utilize the
multiscale tokens to obtain high-quality masks. We denote our method as
RWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we
build a benchmark containing various high-quality segmentation datasets and
jointly train one efficient yet high-quality segmentation model using this
benchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding
performance in efficiency and segmentation quality compared to transformers and
other linear attention models. For example, compared with the same-scale
transformer model, RWKV-SAM achieves more than 2x speedup and can achieve
better segmentation performance on various datasets. In addition, RWKV-SAM
outperforms recent vision Mamba models with better classification and semantic
segmentation results. Code and models will be publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages; 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via
  Collaborating Self-Training and Adversarial Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanan Zhang, Chao Zhou, Di Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing 3D object detection suffers from expensive annotation costs and poor
transferability to unknown data due to the domain gap, Unsupervised Domain
Adaptation (UDA) aims to generalize detection models trained in labeled source
domains to perform robustly on unexplored target domains, providing a promising
solution for cross-domain 3D object detection. Although Self-Training (ST)
based cross-domain 3D detection methods with the assistance of pseudo-labeling
techniques have achieved remarkable progress, they still face the issue of
low-quality pseudo-labels when there are significant domain disparities due to
the absence of a process for feature distribution alignment. While Adversarial
Learning (AL) based methods can effectively align the feature distributions of
the source and target domains, the inability to obtain labels in the target
domain forces the adoption of asymmetric optimization losses, resulting in a
challenging issue of source domain bias. To overcome these limitations, we
propose a novel unsupervised domain adaptation framework for 3D object
detection via collaborating ST and AL, dubbed as STAL3D, unleashing the
complementary advantages of pseudo labels and feature distribution alignment.
Additionally, a Background Suppression Adversarial Learning (BS-AL) module and
a Scale Filtering Module (SFM) are designed tailored for 3D cross-domain
scenes, effectively alleviating the issues of the large proportion of
background interference and source domain size bias. Our STAL3D achieves
state-of-the-art performance on multiple cross-domain tasks and even surpasses
the Oracle results on Waymo $\rightarrow$ KITTI and Waymo $\rightarrow$
KITTI-rain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE-TIV</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CORE4D: A 4D Human-Object-Human Interaction <span class="highlight-title">Dataset</span> for Collaborative
  Object REarrangement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19353v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19353v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengwen Zhang, Yun Liu, Ruofan Xing, Bingda Tang, Li Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding how humans cooperatively rearrange household objects is
critical for VR/AR and human-robot interaction. However, in-depth studies on
modeling these behaviors are under-researched due to the lack of relevant
datasets. We fill this gap by presenting CORE4D, a novel large-scale 4D
human-object-human interaction dataset focusing on collaborative object
rearrangement, which encompasses diverse compositions of various object
geometries, collaboration modes, and 3D scenes. With 1K human-object-human
motion sequences captured in the real world, we enrich CORE4D by contributing
an iterative collaboration retargeting strategy to augment motions to a variety
of novel objects. Leveraging this approach, CORE4D comprises a total of 11K
collaboration sequences spanning 3K real and virtual object shapes. Benefiting
from extensive motion patterns provided by CORE4D, we benchmark two tasks
aiming at generating human-object interaction: human-object motion forecasting
and interaction synthesis. Extensive experiments demonstrate the effectiveness
of our collaboration retargeting strategy and indicate that CORE4D has posed
new challenges to existing human-object interaction generation methodologies.
Our dataset and code are available at
https://github.com/leolyliu/CORE4D-Instructions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Visual Conditioning Tokens to Correct Domain Shift for Fully
  Test-time Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fully test-time adaptation aims to adapt the network model based on
sequential analysis of input samples during the inference stage to address the
cross-domain performance degradation problem of deep neural networks. This work
is based on the following interesting finding: in transformer-based image
classification, the class token at the first transformer encoder layer can be
learned to capture the domain-specific characteristics of target samples during
test-time adaptation. This learned token, when combined with input image patch
embeddings, is able to gradually remove the domain-specific information from
the feature representations of input samples during the transformer encoding
process, thereby significantly improving the test-time adaptation performance
of the source model across different domains. We refer to this class token as
visual conditioning token (VCT). To successfully learn the VCT, we propose a
bi-level learning approach to capture the long-term variations of
domain-specific characteristics while accommodating local variations of
instance-specific characteristics. Experimental results on the benchmark
datasets demonstrate that our proposed bi-level visual conditioning token
learning method is able to achieve significantly improved test-time adaptation
performance by up to 1.9%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by TMM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient World Models with Context-Aware Tokenization <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19320v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19320v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vincent Micheli, Eloi Alonso, François Fleuret
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling up deep Reinforcement Learning (RL) methods presents a significant
challenge. Following developments in generative modelling, model-based RL
positions itself as a strong contender. Recent advances in sequence modelling
have led to effective transformer-based world models, albeit at the price of
heavy computations due to the long sequences of tokens required to accurately
simulate environments. In this work, we propose $\Delta$-IRIS, a new agent with
a world model architecture composed of a discrete autoencoder that encodes
stochastic deltas between time steps and an autoregressive transformer that
predicts future deltas by summarizing the current state of the world with
continuous tokens. In the Crafter benchmark, $\Delta$-IRIS sets a new state of
the art at multiple frame budgets, while being an order of magnitude faster to
train than previous attention-based approaches. We release our code and models
at https://github.com/vmicheli/delta-iris.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhanced Data Transfer Cooperating with Artificial Triplets for Scene
  Graph Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        KuanChao Chu, Satoshi Yamazaki, Hideki Nakayama
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work focuses on training dataset enhancement of informative relational
triplets for Scene Graph Generation (SGG). Due to the lack of effective
supervision, the current SGG model predictions perform poorly for informative
relational triplets with inadequate training samples. Therefore, we propose two
novel training dataset enhancement modules: Feature Space Triplet Augmentation
(FSTA) and Soft Transfer. FSTA leverages a feature generator trained to
generate representations of an object in relational triplets. The biased
prediction based sampling in FSTA efficiently augments artificial triplets
focusing on the challenging ones. In addition, we introduce Soft Transfer,
which assigns soft predicate labels to general relational triplets to make more
supervisions for informative predicate classes effectively. Experimental
results show that integrating FSTA and Soft Transfer achieve high levels of
both Recall and mean Recall in Visual Genome dataset. The mean of Recall and
mean Recall is the highest among all the existing model-agnostic methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEICE Transactions on Information and Systems in April
  2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mapping Land Naturalness from Sentinel-2 using Deep Contextual and
  Geographical Priors <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19302v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19302v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Burak Ekim, Michael Schmitt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent decades, the causes and consequences of climate change have
accelerated, affecting our planet on an unprecedented scale. This change is
closely tied to the ways in which humans alter their surroundings. As our
actions continue to impact natural areas, using satellite images to observe and
measure these effects has become crucial for understanding and combating
climate change. Aiming to map land naturalness on the continuum of modern human
pressure, we have developed a multi-modal supervised deep learning framework
that addresses the unique challenges of satellite data and the task at hand. We
incorporate contextual and geographical priors, represented by corresponding
coordinate information and broader contextual information, including and
surrounding the immediate patch to be predicted. Our framework improves the
model's predictive performance in mapping land naturalness from Sentinel-2
data, a type of multi-spectral optical satellite imagery. Recognizing that our
protective measures are only as effective as our understanding of the
ecosystem, quantifying naturalness serves as a crucial step toward enhancing
our environmental stewardship.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, ICLR 2024 Tackling Climate Change with Machine
  Learning Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PNeRV: A Polynomial Neural Representation for Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19299v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19299v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sonam Gupta, Snehal Singh Tomar, Grigorios G Chrysos, Sukhendu Das, A. N. Rajagopalan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extracting Implicit Neural Representations (INRs) on video data poses unique
challenges due to the additional temporal dimension. In the context of videos,
INRs have predominantly relied on a frame-only parameterization, which
sacrifices the spatiotemporal continuity observed in pixel-level (spatial)
representations. To mitigate this, we introduce Polynomial Neural
Representation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR
for videos that preserves spatiotemporal continuity. PNeRV leverages the
modeling capabilities of Polynomial Neural Networks to perform the modulation
of a continuous spatial (patch) signal with a continuous time (frame) signal.
We further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme
that ensures spatial continuity while retaining parameter efficiency. We also
employ a carefully designed Positional Embedding methodology to further enhance
PNeRV's performance. Our extensive experimentation demonstrates that PNeRV
outperforms the baselines in conventional Implicit Neural Representation tasks
like compression along with downstream applications that require spatiotemporal
continuity in the underlying representation. PNeRV not only addresses the
challenges posed by video data in the realm of INRs but also opens new avenues
for advanced video processing and analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 17 figures, published at TMLR, Feb 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compositional Image Decomposition with Diffusion Models <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jocelin Su, Nan Liu, Yanbo Wang, Joshua B. Tenenbaum, Yilun Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given an image of a natural scene, we are able to quickly decompose it into a
set of components such as objects, lighting, shadows, and foreground. We can
then envision a scene where we combine certain components with those from other
images, for instance a set of objects from our bedroom and animals from a zoo
under the lighting conditions of a forest, even if we have never encountered
such a scene before. In this paper, we present a method to decompose an image
into such compositional components. Our approach, Decomp Diffusion, is an
unsupervised method which, when given a single image, infers a set of different
components in the image, each represented by a diffusion model. We demonstrate
how components can capture different factors of the scene, ranging from global
scene descriptors like shadows or facial expression to local scene descriptors
like constituent objects. We further illustrate how inferred factors can be
flexibly composed, even with factors inferred from other models, to generate a
variety of scenes sharply different than those seen in training time. Website
and code at https://energy-based-model.github.io/decomp-diffusion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024, Webpage:
  https://energy-based-model.github.io/decomp-diffusion</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Continual Learning in Visual Question Answering with
  Modality-Aware Feature Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Malvina Nikandrou, Georgios Pantazopoulos, Ioannis Konstas, Alessandro Suglia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Continual learning focuses on incrementally training a model on a sequence of
tasks with the aim of learning new tasks while minimizing performance drop on
previous tasks. Existing approaches at the intersection of Continual Learning
and Visual Question Answering (VQA) do not study how the multimodal nature of
the input affects the learning dynamics of a model. In this paper, we
demonstrate that each modality evolves at different rates across a continuum of
tasks and that this behavior occurs in established encoder-only models as well
as modern recipes for developing Vision & Language (VL) models. Motivated by
this observation, we propose a modality-aware feature distillation (MAFED)
approach which outperforms existing baselines across models of varying scale in
three multimodal continual learning settings. Furthermore, we provide ablations
showcasing that modality-aware distillation complements experience replay.
Overall, our results emphasize the importance of addressing modality-specific
dynamics to prevent forgetting in multimodal continual learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human Modelling and Pose Estimation <span class="highlight-title">Overview</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19290v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19290v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pawel Knap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human modelling and pose estimation stands at the crossroads of Computer
Vision, Computer Graphics, and Machine Learning. This paper presents a thorough
investigation of this interdisciplinary field, examining various algorithms,
methodologies, and practical applications. It explores the diverse range of
sensor technologies relevant to this domain and delves into a wide array of
application areas. Additionally, we discuss the challenges and advancements in
2D and 3D human modelling methodologies, along with popular datasets, metrics,
and future research directions. The main contribution of this paper lies in its
up-to-date comparison of state-of-the-art (SOTA) human pose estimation
algorithms in both 2D and 3D domains. By providing this comprehensive overview,
the paper aims to enhance understanding of 3D human modelling and pose
estimation, offering insights into current SOTA achievements, challenges, and
future prospects within the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Huatuo<span class="highlight-title">GPT</span>-Vision, Towards Injecting Medical Visual Knowledge into
  Multimodal LLMs at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19280v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19280v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens
  Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19263v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19263v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graphical User Interfaces (GUIs) are central to our interaction with digital
devices. Recently, growing efforts have been made to build models for various
GUI understanding tasks. However, these efforts largely overlook an important
GUI-referring task: screen reading based on user-indicated points, which we
name the Screen Point-and-Read (SPR) task. This task is predominantly handled
by rigid accessible screen reading tools, in great need of new models driven by
advancements in Multimodal Large Language Models (MLLMs). In this paper, we
propose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism,
to address the SPR task. Based on the input point coordinate and the
corresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout
Tree. Based on the tree, our ToL agent not only comprehends the content of the
indicated area but also articulates the layout and spatial relationships
between elements. Such layout information is crucial for accurately
interpreting information on the screen, distinguishing our ToL agent from other
screen reading tools. We also thoroughly evaluate the ToL agent against other
baselines on a newly proposed SPR benchmark, which includes GUIs from mobile,
web, and operating systems. Last but not least, we test the ToL agent on mobile
GUI navigation tasks, demonstrating its utility in identifying incorrect
actions along the path of agent execution trajectories. Code and data:
screen-point-and-read.github.io
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Video-Language Representations with Structural Spatio-Temporal
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19255v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19255v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE TPAMI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Local Manifold Learning for No-Reference Image Quality Assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19247v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19247v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timin Gao, Wensheng Pan, Yan Zhang, Sicheng Zhao, Shengchuan Zhang, Xiawu Zheng, Ke Li, Liujuan Cao, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive learning has considerably advanced the field of Image Quality
Assessment (IQA), emerging as a widely adopted technique. The core mechanism of
contrastive learning involves minimizing the distance between quality-similar
(positive) examples while maximizing the distance between quality-dissimilar
(negative) examples. Despite its successes, current contrastive learning
methods often neglect the importance of preserving the local manifold
structure. This oversight can result in a high degree of similarity among hard
examples within the feature space, thereby impeding effective differentiation
and assessment. To address this issue, we propose an innovative framework that
integrates local manifold learning with contrastive learning for No-Reference
Image Quality Assessment (NR-IQA). Our method begins by sampling multiple crops
from a given image, identifying the most visually salient crop. This crop is
then used to cluster other crops from the same image as the positive class,
while crops from different images are treated as negative classes to increase
inter-class distance. Uniquely, our approach also considers non-saliency crops
from the same image as intra-class negative classes to preserve their
distinctiveness. Additionally, we employ a mutual learning framework, which
further enhances the model's ability to adaptively learn and identify visual
saliency regions. Our approach demonstrates a better performance compared to
state-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942
(compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ALMA: a mathematics-driven approach for determining tuning parameters in
  generalized LASSO problems, with applications to MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19239v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19239v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gianluca Giacchi, Isidoros Iakovidis, Bastien Milani, Matthias Stuber, Micah Murray, Benedetta Franceschiello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetic Resonance Imaging (MRI) is a powerful technique employed for
non-invasive in vivo visualization of internal structures. Sparsity is often
deployed to accelerate the signal acquisition or overcome the presence of
motion artifacts, improving the quality of image reconstruction. Image
reconstruction algorithms use TV-regularized LASSO (Total Variation-regularized
LASSO) to retrieve the missing information of undersampled signals, by cleaning
the data of noise and while optimizing sparsity. A tuning parameter moderates
the balance between these two aspects; its choice affecting the quality of the
reconstructions. Currently, there is a lack of general deterministic techniques
to choose these parameters, which are oftentimes manually selected and thus
hinder the reliability of the reconstructions. Here, we present ALMA (Algorithm
for Lagrange Multipliers Approximation), an iterative mathematics-inspired
technique that computes tuning parameters for generalized LASSO problems during
MRI reconstruction. We analyze quantitatively the performance of these
parameters for imaging reconstructions via TV-LASSO in an MRI context on
phantoms. Although our study concentrates on TV-LASSO, the techniques developed
here hold significant promise for a wide array of applications. ALMA is not
only adaptable to more generalized LASSO problems but is also robust to
accommodate other forms of regularization beyond total variation. Moreover, it
extends effectively to handle non-Cartesian sampling trajectories, broadening
its utility in complex data reconstruction scenarios. More generally, ALMA
provides a powerful tool for numerically solving constrained optimization
problems across various disciplines, offering a versatile and impactful
solution for advanced computational challenges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human-Aware Vision-and-Language Navigation: Bridging Simulation to
  Reality with Dynamic Human Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19236v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19236v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghan Li, Heng Li, Zhi-Qi Cheng, Yifei Dong, Yuxuan Zhou, Jun-Yan He, Qi Dai, Teruko Mitamura, Alexander G. Hauptmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-and-Language Navigation (VLN) aims to develop embodied agents that
navigate based on human instructions. However, current VLN frameworks often
rely on static environments and optimal expert supervision, limiting their
real-world applicability. To address this, we introduce Human-Aware
Vision-and-Language Navigation (HA-VLN), extending traditional VLN by
incorporating dynamic human activities and relaxing key assumptions. We propose
the Human-Aware 3D (HA3D) simulator, which combines dynamic human activities
with the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R)
dataset, extending R2R with human activity descriptions. To tackle HA-VLN
challenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and
Non-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing
cross-modal fusion and diverse training strategies for effective navigation in
dynamic human environments. A comprehensive evaluation, including metrics
considering human activities, and systematic analysis of HA-VLN's unique
challenges, underscores the need for further research to enhance HA-VLN agents'
real-world robustness and adaptability. Ultimately, this work provides
benchmarks and insights for future research on embodied AI and Sim2Real
transfer, paving the way for more realistic and applicable VLN systems in
human-populated environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 18 figures, Project Page:
  https://lpercc.github.io/HA3D_simulator/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model
  for Semantic Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazanin Moradinasab, Laura S. Shankman, Rebecca A. Deaton, Gary K. Owens, Donald E. Brown
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain adaptive semantic segmentation aims to generate accurate and dense
predictions for an unlabeled target domain by leveraging a supervised model
trained on a labeled source domain. The prevalent self-training approach
involves retraining the dense discriminative classifier of $p(class|pixel
feature)$ using the pseudo-labels from the target domain. While many methods
focus on mitigating the issue of noisy pseudo-labels, they often overlook the
underlying data distribution p(pixel feature|class) in both the source and
target domains. To address this limitation, we propose the multi-prototype
Gaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into
contrastive losses to perform guided contrastive learning. Contrastive losses
are commonly executed in the literature using memory banks, which can lead to
class biases due to underrepresented classes. Furthermore, memory banks often
have fixed capacities, potentially restricting the model's ability to capture
diverse representations of the target/source domains. An alternative approach
is to use global class prototypes (i.e. averaged features per category).
However, the global prototypes are based on the unimodal distribution
assumption per class, disregarding within-class variation. To address these
challenges, we propose the ProtoGMM model. This novel approach involves
estimating the underlying multi-prototype source distribution by utilizing the
GMM on the feature space of the source samples. The components of the GMM model
act as representative prototypes. To achieve increased intra-class semantic
similarity, decreased inter-class similarity, and domain alignment between the
source and target domains, we employ multi-prototype contrastive learning
between source distribution and target samples. The experiments show the
effectiveness of our method on UDA benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Think Step by Step: Chain-of-Gesture <span class="highlight-title">Prompt</span>ing for Error Detection in
  Robotic Surgical Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhimin Shao, Jialang Xu, Danail Stoyanov, Evangelos B. Mazomenos, Yueming Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant advancements in robotic systems and surgical data
science, ensuring safe and optimal execution in robot-assisted minimally
invasive surgery (RMIS) remains a complex challenge. Current surgical error
detection methods involve two parts: identifying surgical gestures and then
detecting errors within each gesture clip. These methods seldom consider the
rich contextual and semantic information inherent in surgical videos, limiting
their performance due to reliance on accurate gesture identification. Motivated
by the chain-of-thought prompting in natural language processing, this letter
presents a novel and real-time end-to-end error detection framework,
Chain-of-Thought (COG) prompting, leveraging contextual information from
surgical videos. This encompasses two reasoning modules designed to mimic the
decision-making processes of expert surgeons. Concretely, we first design a
Gestural-Visual Reasoning module, which utilizes transformer and attention
architectures for gesture prompting, while the second, a Multi-Scale Temporal
Reasoning module, employs a multi-stage temporal convolutional network with
both slow and fast paths for temporal information extraction. We extensively
validate our method on the public benchmark RMIS dataset JIGSAWS. Our method
encapsulates the reasoning processes inherent to surgical activities enabling
it to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,
and 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on
average, demonstrating the great potential of our approach in enhancing the
safety and efficacy of RMIS procedures and surgical education. The code will be
available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Reducing Data Acquisition and Labeling for Defect Detection
  using Simulated Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19175v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19175v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Malte Kemeter, Rasmus Hvingelby, Paulina Sierak, Tobias Schön, Bishwajit Gosswam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many manufacturing settings, annotating data for machine learning and
computer vision is costly, but synthetic data can be generated at significantly
lower cost. Substituting the real-world data with synthetic data is therefore
appealing for many machine learning applications that require large amounts of
training data. However, relying solely on synthetic data is frequently
inadequate for effectively training models that perform well on real-world
data, primarily due to domain shifts between the synthetic and real-world data.
We discuss approaches for dealing with such a domain shift when detecting
defects in X-ray scans of aluminium wheels. Using both simulated and real-world
X-ray images, we train an object detection model with different strategies to
identify the training approach that generates the best detection results while
minimising the demand for annotated real-world training samples. Our
preliminary findings suggest that the sim-2-real domain adaptation approach is
more cost-efficient than a fully supervised oracle - if the total number of
available annotated samples is fixed. Given a certain number of labeled
real-world samples, training on a mix of synthetic and unlabeled real-world
data achieved comparable or even better detection results at significantly
lower cost. We argue that future research into the cost-efficiency of different
training strategies is important for a better understanding of how to allocate
budget in applied machine learning projects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Single Image Estimation of Cell Migration Direction by Deep Circular
  Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19162v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19162v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lennart Bruns, Lucas Lamparter, Milos Galic, Xiaoyi Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we study the problem of estimating the migration direction of
cells based on a single image. To the best of our knowledge, there is only one
related work that uses a classification CNN for four classes (quadrants). This
approach does not allow detailed directional resolution. We solve the single
image estimation problem using deep circular regression with special attention
to cycle-sensitive methods. On two databases we achieve an average accuracy of
$\sim$17 degrees, which is a significant improvement over the previous work.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAVEN: Multitask Retrieval Augmented Vision-Language Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scaling of large language models to encode all the world's knowledge in
model parameters is unsustainable and has exacerbated resource barriers.
Retrieval-Augmented Generation (RAG) presents a potential solution, yet its
application to vision-language models (VLMs) is under explored. Existing
methods focus on models designed for single tasks. Furthermore, they're limited
by the need for resource intensive pre training, additional parameter
requirements, unaddressed modality prioritization and lack of clear benefit
over non-retrieval baselines. This paper introduces RAVEN, a multitask
retrieval augmented VLM framework that enhances base VLMs through efficient,
task specific fine-tuning. By integrating retrieval augmented samples without
the need for additional retrieval-specific parameters, we show that the model
acquires retrieval properties that are effective across multiple tasks. Our
results and extensive ablations across retrieved modalities for the image
captioning and VQA tasks indicate significant performance improvements compared
to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a
+3\% accuracy on specific VQA question types. This underscores the efficacy of
applying RAG approaches to VLMs, marking a stride toward more efficient and
accessible multimodal learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Utilizing Adversarial Examples for Bias Mitigation and Accuracy
  Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11819v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11819v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pushkar Shukla, Dhruv Srikanth, Lee Cohen, Matthew Turk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel approach to mitigate biases in computer vision models by
utilizing counterfactual generation and fine-tuning. While counterfactuals have
been used to analyze and address biases in DNN models, the counterfactuals
themselves are often generated from biased generative models, which can
introduce additional biases or spurious correlations. To address this issue, we
propose using adversarial images, that is images that deceive a deep neural
network but not humans, as counterfactuals for fair model training. Our
approach leverages a curriculum learning framework combined with a fine-grained
adversarial loss to fine-tune the model using adversarial examples. By
incorporating adversarial images into the training data, we aim to prevent
biases from propagating through the pipeline. We validate our approach through
both qualitative and quantitative assessments, demonstrating improved bias
mitigation and accuracy compared to existing methods. Qualitatively, our
results indicate that post-training, the decisions made by the model are less
dependent on the sensitive attribute and our model better disentangles the
relationship between sensitive attributes and classification variables.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semi-supervised variational autoencoder for cell feature extraction in
  multiplexed immunofluorescence images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Piumi Sandarenu, Julia Chen, Iveta Slapetova, Lois Browne, Peter H. Graham, Alexander Swarbrick, Ewan K. A. Millar, Yang Song, Erik Meijering
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in digital imaging technologies have sparked increased interest
in using multiplexed immunofluorescence (mIF) images to visualise and identify
the interactions between specific immunophenotypes with the tumour
microenvironment at the cellular level. Current state-of-the-art multiplexed
immunofluorescence image analysis pipelines depend on cell feature
representations characterised by morphological and stain intensity-based
metrics generated using simple statistical and machine learning-based tools.
However, these methods are not capable of generating complex representations of
cells. We propose a deep learning-based cell feature extraction model using a
variational autoencoder with supervision using a latent subspace to extract
cell features in mIF images. We perform cell phenotype classification using a
cohort of more than 44,000 multiplexed immunofluorescence cell image patches
extracted across 1,093 tissue microarray cores of breast cancer patients, to
demonstrate the success of our model against current and alternative methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FishNet: Deep Neural Networks for Low-Cost Fish Stock Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10916v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10916v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moseli Mots'oehli, Anton Nikolaev, Wawan B. IGede, John Lynham, Peter J. Mous, Peter Sadowski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fish stock assessment often involves manual fish counting by taxonomy
specialists, which is both time-consuming and costly. We propose FishNet, an
automated computer vision system for both taxonomic classification and fish
size estimation from images captured with a low-cost digital camera. The system
first performs object detection and segmentation using a Mask R-CNN to identify
individual fish from images containing multiple fish, possibly consisting of
different species. Then each fish species is classified and the length is
predicted using separate machine learning models. To develop the model, we use
a dataset of 300,000 hand-labeled images containing 1.2M fish of 163 different
species and ranging in length from 10cm to 250cm, with additional annotations
and quality control methods used to curate high-quality training data. On
held-out test data sets, our system achieves a 92% intersection over union on
the fish segmentation task, a 89% top-1 classification accuracy on single fish
species classification, and a 2.3cm mean absolute error on the fish length
estimation task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE COINS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Step Differences in Instructional Video <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.16222v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.16222v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tushar Nagarajan, Lorenzo Torresani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Comparing a user video to a reference how-to video is a key requirement for
AR/VR technology delivering personalized assistance tailored to the user's
progress. However, current approaches for language-based assistance can only
answer questions about a single video. We propose an approach that first
automatically generates large amounts of visual instruction tuning data
involving pairs of videos from HowTo100M by leveraging existing step
annotations and accompanying narrations, and then trains a video-conditioned
language model to jointly reason across multiple raw videos. Our model achieves
state-of-the-art performance at identifying differences between video pairs and
ranking videos based on the severity of these differences, and shows promising
ability to perform general reasoning over multiple videos. Project page:
https://github.com/facebookresearch/stepdiff
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Stackable and Skippable LEGO Bricks for Efficient,
  Reconfigurable, and Variable-Resolution Diffusion Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06389v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06389v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huangjie Zheng, Zhendong Wang, Jianbo Yuan, Guanghan Ning, Pengcheng He, Quanzeng You, Hongxia Yang, Mingyuan Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models excel at generating photo-realistic images but come with
significant computational costs in both training and sampling. While various
techniques address these computational challenges, a less-explored issue is
designing an efficient and adaptable network backbone for iterative refinement.
Current options like U-Net and Vision Transformer often rely on
resource-intensive deep networks and lack the flexibility needed for generating
images at variable resolutions or with a smaller network than used in training.
This study introduces LEGO bricks, which seamlessly integrate Local-feature
Enrichment and Global-content Orchestration. These bricks can be stacked to
create a test-time reconfigurable diffusion backbone, allowing selective
skipping of bricks to reduce sampling costs and generate higher-resolution
images than the training data. LEGO bricks enrich local regions with an MLP and
transform them using a Transformer block while maintaining a consistent
full-resolution image across all bricks. Experimental results demonstrate that
LEGO bricks enhance training efficiency, expedite convergence, and facilitate
variable-resolution image generation while maintaining strong generative
performance. Moreover, LEGO significantly reduces sampling time compared to
other methods, establishing it as a valuable enhancement for diffusion models.
Our code and project page are available at
https://jegzheng.github.io/LEGODiffusion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Semantic Equivalence of Tokenization in Multimodal LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05127v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05127v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengqiong Wu, Hao Fei, Xiangtai Li, Jiayi Ji, Hanwang Zhang, Tat-Seng Chua, Shuicheng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have demonstrated exceptional
capabilities in processing vision-language tasks. One of the crux of MLLMs lies
in vision tokenization, which involves efficiently transforming input visual
signals into feature representations that are most beneficial for LLMs.
However, existing vision tokenizers, essential for semantic alignment between
vision and language, remain problematic. Existing methods aggressively fragment
visual input, corrupting the visual semantic integrity. To address this, this
paper proposes a novel dynamic Semantic-Equivalent Vision Tokenizer (SeTok),
which groups visual features into semantic units via a dynamic clustering
algorithm, flexibly determining the number of tokens based on image complexity.
The resulting vision tokens effectively preserve semantic integrity and capture
both low-frequency and high-frequency visual features. The proposed MLLM
(Setokim) equipped with SeTok significantly demonstrates superior performance
across various tasks, as evidenced by our experimental results. The project
page is at https://chocowu.github.io/SeTok-web/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report. The project page:
  https://chocowu.github.io/SeTok-web/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Physics-Guided Neural Networks for Intraventricular Vector Flow Mapping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13040v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13040v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Jung Ling, Salomé Bru, Julia Puig, Florian Vixège, Simon Mendez, Franck Nicoud, Pierre-Yves Courand, Olivier Bernard, Damien Garcia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intraventricular vector flow mapping (iVFM) seeks to enhance and quantify
color Doppler in cardiac imaging. In this study, we propose novel alternatives
to the traditional iVFM optimization scheme by utilizing physics-informed
neural networks (PINNs) and a physics-guided nnU-Net-based supervised approach.
When evaluated on simulated color Doppler images derived from a
patient-specific computational fluid dynamics model and in vivo Doppler
acquisitions, both approaches demonstrate comparable reconstruction performance
to the original iVFM algorithm. The efficiency of PINNs is boosted through
dual-stage optimization and pre-optimized weights. On the other hand, the
nnU-Net method excels in generalizability and real-time capabilities. Notably,
nnU-Net shows superior robustness on sparse and truncated Doppler data while
maintaining independence from explicit boundary conditions. Overall, our
results highlight the effectiveness of these methods in reconstructing
intraventricular vector blood flow. The study also suggests potential
applications of PINNs in ultrafast color Doppler imaging and the incorporation
of fluid dynamics equations to derive biomarkers for cardiovascular diseases
based on blood flow.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, accepted for publication in IEEE TUFFC; camera ready
  corrections, corrected acknowledgments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VDebugger: Harnessing Execution Feedback for Debugging Visual Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13444v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13444v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xueqing Wu, Zongyu Lin, Songyan Zhao, Te-Lin Wu, Pan Lu, Nanyun Peng, Kai-Wei Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual programs are executable code generated by large language models to
address visual reasoning problems. They decompose complex questions into
multiple reasoning steps and invoke specialized models for each step to solve
the problems. However, these programs are prone to logic errors, with our
preliminary evaluation showing that 58% of the total errors are caused by
program logic errors. Debugging complex visual programs remains a major
bottleneck for visual reasoning. To address this, we introduce VDebugger, a
novel critic-refiner framework trained to localize and debug visual programs by
tracking execution step by step. VDebugger identifies and corrects program
errors leveraging detailed execution feedback, improving interpretability and
accuracy. The training data is generated through an automated pipeline that
injects errors into correct visual programs using a novel mask-best decoding
technique. Evaluations on six datasets demonstrate VDebugger's effectiveness,
showing performance improvements of up to 3.2% in downstream task accuracy.
Further studies show VDebugger's ability to generalize to unseen tasks,
bringing a notable improvement of 2.3% on the unseen COVR task. Code, data and
models are made publicly available at https://github.com/shirley-wu/vdebugger/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>update reference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpatialBot: Precise Spatial Understanding with Vision Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13642v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13642v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenxiao Cai, Yaroslav Ponomarenko, Jianhao Yuan, Xiaoqi Li, Wankou Yang, Hao Dong, Bo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) have achieved impressive performance in 2D
image understanding, however they are still struggling with spatial
understanding which is the foundation of Embodied AI. In this paper, we propose
SpatialBot for better spatial understanding by feeding both RGB and depth
images. Additionally, we have constructed the SpatialQA dataset, which involves
multi-level depth-related questions to train VLMs for depth understanding.
Finally, we present SpatialBench to comprehensively evaluate VLMs' capabilities
in spatial understanding at different levels. Extensive experiments on our
spatial-understanding benchmark, general VLM benchmarks and Embodied AI tasks,
demonstrate the remarkable improvements of SpatialBot trained on SpatialQA. The
model, code and data are available at https://github.com/BAAI-DCAI/SpatialBot.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Muffin or Chihuahua? Challenging Multimodal Large Language Models with
  Multipanel VQA <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.15847v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.15847v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Fan, Jing Gu, Kaiwen Zhou, Qianqi Yan, Shan Jiang, Ching-Chen Kuo, Xinze Guan, Xin Eric Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multipanel images, commonly seen as web screenshots, posters, etc., pervade
our daily lives. These images, characterized by their composition of multiple
subfigures in distinct layouts, effectively convey information to people.
Toward building advanced multimodal AI applications, such as agents that
understand complex scenes and navigate through webpages, the skill of
multipanel visual reasoning is essential, and a comprehensive evaluation of
models in this regard is important. Therefore, we introduce Multipanel Visual
Question Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets
of questions, answers, and multipanel images that specifically challenge models
in comprehending multipanel images. Our evaluation shows that questions in the
MultipanelVQA benchmark pose significant challenges to the state-of-the-art
Multimodal Large Language Models (MLLMs) tested, even though humans can attain
approximately 99% accuracy on these questions. Distinctively, the MultipanelVQA
benchmark features synthetically generated multipanel images specifically
crafted to isolate and assess the impact of various factors, such as the
layout, on MLLMs' multipanel image comprehension abilities. As a result, in
addition to benchmarking the capabilities of MLLMs in understanding multipanel
images, we analyze various factors of the multipanel image that affect MLLMs'
performance with synthetic data and offer insights for enhancement. Code and
data are released at https://sites.google.com/view/multipanelvqa/home.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shortcut Learning in Medical Image Segmentation <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06748v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06748v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manxi Lin, Nina Weng, Kamil Mikolaj, Zahra Bashir, Morten Bo Søndergaard Svendsen, Martin Tolsgaard, Anders Nymark Christensen, Aasa Feragen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Shortcut learning is a phenomenon where machine learning models prioritize
learning simple, potentially misleading cues from data that do not generalize
well beyond the training set. While existing research primarily investigates
this in the realm of image classification, this study extends the exploration
of shortcut learning into medical image segmentation. We demonstrate that
clinical annotations such as calipers, and the combination of zero-padded
convolutions and center-cropped training sets in the dataset can inadvertently
serve as shortcuts, impacting segmentation accuracy. We identify and evaluate
the shortcut learning on two different but common medical image segmentation
tasks. In addition, we suggest strategies to mitigate the influence of shortcut
learning and improve the generalizability of the segmentation models. By
uncovering the presence and implications of shortcuts in medical image
segmentation, we provide insights and methodologies for evaluating and
overcoming this pervasive challenge and call for attention in the community for
shortcuts in segmentation. Our code is public at
https://github.com/nina-weng/shortcut_skinseg .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures, accepted at MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ S4: <span class="highlight-title">Self-Supervised</span> Sensing Across the Spectrum 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01656v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01656v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jayanth Shenoy, Xingjian Davis Zhang, Shlok Mehrotra, Bill Tao, Rem Yang, Han Zhao, Deepak Vasisht
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Satellite image time series (SITS) segmentation is crucial for many
applications like environmental monitoring, land cover mapping and agricultural
crop type classification. However, training models for SITS segmentation
remains a challenging task due to the lack of abundant training data, which
requires fine grained annotation. We propose S4 a new self-supervised
pre-training approach that significantly reduces the requirement for labeled
training data by utilizing two new insights: (a) Satellites capture images in
different parts of the spectrum such as radio frequencies, and visible
frequencies. (b) Satellite imagery is geo-registered allowing for fine-grained
spatial alignment. We use these insights to formulate pre-training tasks in S4.
We also curate m2s2-SITS, a large-scale dataset of unlabeled,
spatially-aligned, multi-modal and geographic specific SITS that serves as
representative pre-training data for S4. Finally, we evaluate S4 on multiple
SITS segmentation datasets and demonstrate its efficacy against competing
baselines while using limited labeled data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatic infant 2D pose estimation from videos: comparing seven deep
  neural network methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17382v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17382v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Filipe Gama, Matej Misar, Lukas Navara, Sergiu T. Popescu, Matej Hoffmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic markerless estimation of infant posture and motion from ordinary
videos carries great potential for movement studies "in the wild", facilitating
understanding of motor development and massively increasing the chances of
early diagnosis of disorders. There is rapid development of human pose
estimation methods in computer vision thanks to advances in deep learning and
machine learning. However, these methods are trained on datasets featuring
adults in different contexts. This work tests and compares seven popular
methods (AlphaPose, DeepLabCut/DeeperCut, Detectron2, HRNet,
MediaPipe/BlazePose, OpenPose, and ViTPose) on videos of infants in supine
position. Surprisingly, all methods except DeepLabCut and MediaPipe have
competitive performance without additional finetuning, with ViTPose performing
best. Next to standard performance metrics (object keypoint similarity, average
precision and recall), we introduce errors expressed in the neck-mid-hip ratio
and additionally study missed and redundant detections and the reliability of
the internal confidence ratings of the different methods, which are relevant
for downstream tasks. Among the networks with competitive performance, only
AlphaPose could run close to real time (27 fps) on our machine. We provide
documented Docker containers or instructions for all the methods we used, our
analysis scripts, and processed data at https://hub.docker.com/u/humanoidsctu
and https://osf.io/x465b/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 3 figures, 14 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SRC-Net: Bi-Temporal Spatial Relationship Concerned Network for Change
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05668v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05668v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjia Chen, Xin Xu, Fangling Pu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Change detection (CD) in remote sensing imagery is a crucial task with
applications in environmental monitoring, urban development, and disaster
management. CD involves utilizing bi-temporal images to identify changes over
time. The bi-temporal spatial relationships between features at the same
location at different times play a key role in this process. However, existing
change detection networks often do not fully leverage these spatial
relationships during bi-temporal feature extraction and fusion. In this work,
we propose SRC-Net: a bi-temporal spatial relationship concerned network for
CD. The proposed SRC-Net includes a Perception and Interaction Module that
incorporates spatial relationships and establishes a cross-branch perception
mechanism to enhance the precision and robustness of feature extraction.
Additionally, a Patch-Mode joint Feature Fusion Module is introduced to address
information loss in current methods. It considers different change modes and
concerns about spatial relationships, resulting in more expressive fusion
features. Furthermore, we construct a novel network using these two
relationship concerned modules and conducted experiments on the LEVIR-CD and
WHU Building datasets. The experimental results demonstrate that our network
outperforms state-of-the-art (SOTA) methods while maintaining a modest
parameter count. We believe our approach sets a new paradigm for change
detection and will inspire further advancements in the field. The code and
models are publicly available at https://github.com/Chnja/SRCNet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 12 figures, IEEE Journal of Selected Topics in Applied
  Earth Observations and Remote Sensing (2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with
  Lightweight Blocks <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06196v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06196v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manish Dhakal, Rabin Adhikari, Safal Thapaliya, Bishesh Khanal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation Vision-Language Models (VLMs) trained using large-scale
open-domain images and text pairs have recently been adapted to develop
Vision-Language Segmentation Models (VLSMs) that allow providing text prompts
during inference to guide image segmentation. If robust and powerful VLSMs can
be built for medical images, it could aid medical professionals in many
clinical tasks where they must spend substantial time delineating the target
structure of interest. VLSMs for medical images resort to fine-tuning base VLM
or VLSM pretrained on open-domain natural image datasets due to fewer annotated
medical image datasets; this fine-tuning is resource-consuming and expensive as
it usually requires updating all or a significant fraction of the pretrained
parameters. Recently, lightweight blocks called adapters have been proposed in
VLMs that keep the pretrained model frozen and only train adapters during
fine-tuning, substantially reducing the computing resources required. We
introduce a novel adapter, VLSM-Adapter, that can fine-tune pretrained
vision-language segmentation models using transformer encoders. Our experiments
in widely used CLIP-based segmentation models show that with only 3 million
trainable parameters, the VLSM-Adapter outperforms state-of-the-art and is
comparable to the upper bound end-to-end fine-tuning. The source code is
available at: https://github.com/naamiinepal/vlsm-adapter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at MICCAI 2024, the 27th International Conference on Medical
  Image Computing and Computer Assisted Intervention</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMGPL: Multimodal Medical Data Analysis with Graph <span class="highlight-title">Prompt</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.14574v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.14574v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Peng, Songyue Cai, Zongqian Wu, Huifang Shang, Xiaofeng Zhu, Xiaoxiao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning has demonstrated impressive efficacy in the fine-tuning of
multimodal large models to a wide range of downstream tasks. Nonetheless,
applying existing prompt learning methods for the diagnosis of neurological
disorder still suffers from two issues: (i) existing methods typically treat
all patches equally, despite the fact that only a small number of patches in
neuroimaging are relevant to the disease, and (ii) they ignore the structural
information inherent in the brain connection network which is crucial for
understanding and diagnosing neurological disorders. To tackle these issues, we
introduce a novel prompt learning model by learning graph prompts during the
fine-tuning process of multimodal large models for diagnosing neurological
disorders. Specifically, we first leverage GPT-4 to obtain relevant disease
concepts and compute semantic similarity between these concepts and all
patches. Secondly, we reduce the weight of irrelevant patches according to the
semantic similarity between each patch and disease-related concepts. Moreover,
we construct a graph among tokens based on these concepts and employ a graph
convolutional network layer to extract the structural information of the graph,
which is used to prompt the pre-trained multimodal large models for diagnosing
neurological disorders. Extensive experiments demonstrate that our method
achieves superior performance for neurological disorder diagnosis compared with
state-of-the-art methods and validated by clinicians.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Self-Supervised</span> Detection of Perfect and Partial Input-Dependent
  Symmetries 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.12223v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.12223v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alonso Urbano, David W. Romero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group equivariance can overly constrain models if the symmetries in the group
differ from those observed in data. While common methods address this by
determining the appropriate level of symmetry at the dataset level, they are
limited to supervised settings and ignore scenarios in which multiple levels of
symmetry co-exist in the same dataset. In this paper, we propose a method able
to detect the level of symmetry of each input without the need for labels. Our
framework is general enough to accommodate different families of both
continuous and discrete symmetry distributions, such as arbitrary unimodal,
symmetric distributions and discrete groups. We validate the effectiveness of
our approach on synthetic datasets with different per-class levels of
symmetries, and demonstrate practical applications such as the detection of
out-of-distribution symmetries. Our code is publicly available at
https://github.com/aurban0/ssl-sym.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 8 figures, corrected typos, revised argument in Appendix
  B.1, results unchanged</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toc<span class="highlight-title">BERT</span>: Medical Document Structure Extraction Using Bidirectional
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Majd Saleh, Sarra Baghdadi, Stéphane Paquelet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text segmentation holds paramount importance in the field of Natural Language
Processing (NLP). It plays an important role in several NLP downstream tasks
like information retrieval and document summarization. In this work, we propose
a new solution, namely TocBERT, for segmenting texts using bidirectional
transformers. TocBERT represents a supervised solution trained on the detection
of titles and sub-titles from their semantic representations. This task was
formulated as a named entity recognition (NER) problem. The solution has been
applied on a medical text segmentation use-case where the Bio-ClinicalBERT
model is fine-tuned to segment discharge summaries of the MIMIC-III dataset.
The performance of TocBERT has been evaluated on a human-labeled ground truth
corpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a
linear text segmentation problem and 72.8% on a hierarchical text segmentation
problem. It outperformed a carefully designed rule-based solution, particularly
in distinguishing titles from subtitles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Which Neurons Matter in IR? Applying Integrated Gradients-based Methods
  to Understand Cross-Encoders <span class="chip">ICTIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mathias Vast, Basile Van Cooten, Laure Soulier, Benjamin Piwowarski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the recent addition of Retrieval-Augmented Generation (RAG), the scope
and importance of Information Retrieval (IR) has expanded. As a result, the
importance of a deeper understanding of IR models also increases. However,
interpretability in IR remains under-explored, especially when it comes to the
models' inner mechanisms. In this paper, we explore the possibility of adapting
Integrated Gradient-based methods in an IR context to identify the role of
individual neurons within the model. In particular, we provide new insights
into the role of what we call "relevance" neurons, as well as how they deal
with unseen data. Finally, we carry out an in-depth pruning study to validate
our findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICTIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Grounded and Transparent Response Generation for Conversational
  Information-Seeking Systems <span class="chip">WSDM '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19281v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19281v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weronika Łajewska
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While previous conversational information-seeking (CIS) research has focused
on passage retrieval, reranking, and query rewriting, the challenge of
synthesizing retrieved information into coherent responses remains. The
proposed research delves into the intricacies of response generation in CIS
systems. Open-ended information-seeking dialogues introduce multiple challenges
that may lead to potential pitfalls in system responses. The study focuses on
generating responses grounded in the retrieved passages and being transparent
about the system's limitations. Specific research questions revolve around
obtaining confidence-enriched information nuggets, automatic detection of
incomplete or incorrect responses, generating responses communicating the
system's limitations, and evaluating enhanced responses. By addressing these
research tasks the study aspires to contribute to the advancement of
conversational response generation, fostering more trustworthy interactions in
CIS dialogues, and paving the way for grounded and transparent systems to meet
users' needs in an information-driven world.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 17th ACM International Conference on Web Search
  and Data Mining (WSDM '24), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAVEN: Multitask Retrieval Augmented Vision-Language Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scaling of large language models to encode all the world's knowledge in
model parameters is unsustainable and has exacerbated resource barriers.
Retrieval-Augmented Generation (RAG) presents a potential solution, yet its
application to vision-language models (VLMs) is under explored. Existing
methods focus on models designed for single tasks. Furthermore, they're limited
by the need for resource intensive pre training, additional parameter
requirements, unaddressed modality prioritization and lack of clear benefit
over non-retrieval baselines. This paper introduces RAVEN, a multitask
retrieval augmented VLM framework that enhances base VLMs through efficient,
task specific fine-tuning. By integrating retrieval augmented samples without
the need for additional retrieval-specific parameters, we show that the model
acquires retrieval properties that are effective across multiple tasks. Our
results and extensive ablations across retrieved modalities for the image
captioning and VQA tasks indicate significant performance improvements compared
to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a
+3\% accuracy on specific VQA question types. This underscores the efficacy of
applying RAG approaches to VLMs, marking a stride toward more efficient and
accessible multimodal learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Statements: Universal Information Extraction from Tables with Large
  Language Models for ESG KPIs <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19102v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19102v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, Peter Staar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Environment, Social, and Governance (ESG) KPIs assess an organization's
performance on issues such as climate change, greenhouse gas emissions, water
consumption, waste management, human rights, diversity, and policies. ESG
reports convey this valuable quantitative information through tables.
Unfortunately, extracting this information is difficult due to high variability
in the table structure as well as content. We propose Statements, a novel
domain agnostic data structure for extracting quantitative facts and related
information. We propose translating tables to statements as a new supervised
deep-learning universal information extraction task. We introduce SemTabNet - a
dataset of over 100K annotated tables. Investigating a family of T5-based
Statement Extraction Models, our best model generates statements which are 82%
similar to the ground-truth (compared to baseline of 21%). We demonstrate the
advantages of statements by applying our model to over 2700 tables from ESG
reports. The homogeneous nature of statements permits exploratory data analysis
on expansive information found in large collections of ESG reports.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the NLP4Climate workshop in the 62nd Annual Meeting of
  the Association for Computational Linguistics (ACL 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient course recommendations with T5-based ranking and summarization <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thijmen Bijl, Niels van Weeren, Suzan Verberne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we implement and evaluate a two-stage retrieval pipeline for a
course recommender system that ranks courses for skill-occupation pairs. The
in-production recommender system BrightFit provides course recommendations from
multiple sources. Some of the course descriptions are long and noisy, while
retrieval and ranking in an online system have to be highly efficient. We
developed a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as
re-ranker. We compare two summarizers for course descriptions: a LongT5 model
that we finetuned for the task, and a generative LLM (Vicuna) with in-context
learning. We experiment with quantization to reduce the size of the ranking
model and increase inference speed. We evaluate our rankers on two newly
labelled datasets, with an A/B test, and with a user questionnaire. On the two
labelled datasets, our proposed two-stage ranking with automatic summarization
achieves a substantial improvement over the in-production (BM25) ranker:
nDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two
datasets. We also achieve a 40% speed-up by using a quantized version of
RankT5. The improved quality of the ranking was confirmed by the questionnaire
completed by 29 respondents, but not by the A/B test. In the A/B test, a higher
clickthrough rate was observed for the BM25-ranking than for the proposed
two-stage retrieval. We conclude that T5-based re-ranking and summarization for
online course recommendation can obtain much better effectiveness than
single-step lexical retrieval, and that quantization has a large effect on
RankT5. In the online evaluation, however, other factors than relevance play a
role (such as speed and interpretability of the retrieval results), as well as
individual preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ReNeuIR 2024 (at SIGIR 2024) - 3rd Workshop on Reaching Efficiency in
  Neural Information Retrieval, 18 July, 2024, Washington D.C, USA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards a Formal Characterization of User Simulation Objectives in
  Conversational Information Access <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19007v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19007v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nolwenn Bernard, Krisztian Balog
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  User simulation is a promising approach for automatically training and
evaluating conversational information access agents, enabling the generation of
synthetic dialogues and facilitating reproducible experiments at scale.
However, the objectives of user simulation for the different uses remain
loosely defined, hindering the development of effective simulators. In this
work, we formally characterize the distinct objectives for user simulators:
training aims to maximize behavioral similarity to real users, while evaluation
focuses on the accurate prediction of real-world conversational agent
performance. Through an empirical study, we demonstrate that optimizing for one
objective does not necessarily lead to improved performance on the other. This
finding underscores the need for tailored design considerations depending on
the intended use of the simulator. By establishing clear objectives and
proposing concrete measures to evaluate user simulators against those
objectives, we pave the way for the development of simulators that are
specifically tailored to their intended use, ultimately leading to more
effective conversational agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 2024 ACM SIGIR International Conference on the
  Theory of Information Retrieval (ICTIR '24), July 13, 2024, Washington DC,
  DC, USA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Amplify Graph Learning for Recommendation via Sparsity Completion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18984v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18984v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Yuan, Haojie Li, Minying Fang, Xu Yu, Yongjing Hao, Junwei Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph learning models have been widely deployed in collaborative filtering
(CF) based recommendation systems. Due to the issue of data sparsity, the graph
structure of the original input lacks potential positive preference edges,
which significantly reduces the performance of recommendations. In this paper,
we study how to enhance the graph structure for CF more effectively, thereby
optimizing the representation of graph nodes. Previous works introduced matrix
completion techniques into CF, proposing the use of either stochastic
completion methods or superficial structure completion to address this issue.
However, most of these approaches employ random numerical filling that lack
control over noise perturbations and limit the in-depth exploration of
higher-order interaction features of nodes, resulting in biased graph
representations.
  In this paper, we propose an Amplify Graph Learning framework based on
Sparsity Completion (called AGL-SC). First, we utilize graph neural network to
mine direct interaction features between user and item nodes, which are used as
the inputs of the encoder. Second, we design a factorization-based method to
mine higher-order interaction features. These features serve as perturbation
factors in the latent space of the hidden layer to facilitate generative
enhancement. Finally, by employing the variational inference, the above
multi-order features are integrated to implement the completion and enhancement
of missing graph structures. We conducted benchmark and strategy experiments on
four real-world datasets related to recommendation tasks. The experimental
results demonstrate that AGL-SC significantly outperforms the state-of-the-art
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-modal Food Recommendation using Clustering and <span class="highlight-title">Self-supervised</span>
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18962v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18962v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Zhang, Xin Zhou, Qianwen Meng, Fanglin Zhu, Yonghui Xu, Zhiqi Shen, Lizhen Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Food recommendation systems serve as pivotal components in the realm of
digital lifestyle services, designed to assist users in discovering recipes and
food items that resonate with their unique dietary predilections. Typically,
multi-modal descriptions offer an exhaustive profile for each recipe, thereby
ensuring recommendations that are both personalized and accurate. Our
preliminary investigation of two datasets indicates that pre-trained
multi-modal dense representations might precipitate a deterioration in
performance compared to ID features when encapsulating interactive
relationships. This observation implies that ID features possess a relative
superiority in modeling interactive collaborative signals. Consequently,
contemporary cutting-edge methodologies augment ID features with multi-modal
information as supplementary features, overlooking the latent semantic
relations between recipes. To rectify this, we present CLUSSL, a novel food
recommendation framework that employs clustering and self-supervised learning.
Specifically, CLUSSL formulates a modality-specific graph tailored to each
modality with discrete/continuous features, thereby transforming semantic
features into structural representation. Furthermore, CLUSSL procures recipe
representations pertinent to different modalities via graph convolutional
operations. A self-supervised learning objective is proposed to foster
independence between recipe representations derived from different unimodal
graphs. Comprehensive experiments on real-world datasets substantiate that
CLUSSL consistently surpasses state-of-the-art recommendation benchmarks in
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Surprisingly Simple yet Effective Multi-Query Rewriting Method for
  Conversational Passage Retrieval <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18960v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18960v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivica Kostric, Krisztian Balog
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational passage retrieval is challenging as it often requires the
resolution of references to previous utterances and needs to deal with the
complexities of natural language, such as coreference and ellipsis. To address
these challenges, pre-trained sequence-to-sequence neural query rewriters are
commonly used to generate a single de-contextualized query based on
conversation history. Previous research shows that combining multiple query
rewrites for the same user utterance has a positive effect on retrieval
performance. We propose the use of a neural query rewriter to generate multiple
queries and show how to integrate those queries in the passage retrieval
pipeline efficiently. The main strength of our approach lies in its simplicity:
it leverages how the beam search algorithm works and can produce multiple query
rewrites at no additional cost. Our contributions further include devising ways
to utilize multi-query rewrites in both sparse and dense first-pass retrieval.
We demonstrate that applying our approach on top of a standard passage
retrieval pipeline delivers state-of-the-art performance without sacrificing
efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 47th International ACM SIGIR Conference on
  Research and Development in Information Retrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Personalized Federated Multi-scenario Multi-task Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18938v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18938v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Ding, Yanbiao Ji, Xun Cai, Xin Xin, Xiaofeng Gao, Hongtao Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In modern recommender system applications, such as e-commerce, predicting
multiple targets like click-through rate (CTR) and post-view click-through \&
conversion rate (CTCVR) is common. Multi-task recommender systems are gaining
traction in research and practical use. Existing multi-task recommender systems
tackle diverse business scenarios, merging and modeling these scenarios unlocks
shared knowledge to boost overall performance. As new and more complex
real-world recommendation scenarios have emerged, data privacy issues make it
difficult to train a single global multi-task recommendation model that
processes multiple separate scenarios.
  In this paper, we propose a novel framework for personalized federated
multi-scenario multi-task recommendation, called PF-MSMTrec. We assign each
scenario to a dedicated client, with each client utilizing the
Mixture-of-Experts (MMoE) structure. Our proposed method aims to tackle the
unique challenge posed by multiple optimization conflicts in this setting. We
introduce a bottom-up joint learning mechanism. Firstly, we design a parameter
template to decouple the parameters of the expert network. Thus, scenario
parameters are shared knowledge for federated parameter aggregation, while
task-specific parameters are personalized local parameters. Secondly, we
conduct personalized federated learning for the parameters of each expert
network through a federated communication round, utilizing three modules:
federated batch normalization, conflict coordination, and personalized
aggregation. Finally, we perform another round of personalized federated
parameter aggregation on the task tower network to obtain the prediction
results for multiple tasks. We conduct extensive experiments on two public
datasets, and the results demonstrate that our proposed method surpasses
state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-shot Composed Image Retrieval Considering Query-target Relationship
  Leveraging Masked Image-text Pairs <span class="chip">ICIP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18836v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18836v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huaying Zhang, Rintaro Yanagi, Ren Togo, Takahiro Ogawa, Miki Haseyama
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel zero-shot composed image retrieval (CIR) method
considering the query-target relationship by masked image-text pairs. The
objective of CIR is to retrieve the target image using a query image and a
query text. Existing methods use a textual inversion network to convert the
query image into a pseudo word to compose the image and text and use a
pre-trained visual-language model to realize the retrieval. However, they do
not consider the query-target relationship to train the textual inversion
network to acquire information for retrieval. In this paper, we propose a novel
zero-shot CIR method that is trained end-to-end using masked image-text pairs.
By exploiting the abundant image-text pairs that are convenient to obtain with
a masking strategy for learning the query-target relationship, it is expected
that accurate zero-shot CIR using a retrieval-focused textual inversion network
can be realized. Experimental results show the effectiveness of the proposed
method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a conference paper in IEEE ICIP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical
  and Categorical Features for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jizheng Chen, Kounianhua Du, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have been flourishing in the natural language
processing (NLP) domain, and their potential for recommendation has been paid
much attention to. Despite the intelligence shown by the
recommendation-oriented finetuned models, LLMs struggle to fully understand the
user behavior patterns due to their innate weakness in interpreting numerical
features and the overhead for long context, where the temporal relations among
user behaviors, subtle quantitative signals among different ratings, and
various side features of items are not well explored. Existing works only
fine-tune a sole LLM on given text data without introducing that important
information to it, leaving these problems unsolved. In this paper, we propose
ELCoRec to Enhance Language understanding with CoPropagation of numerical and
categorical features for Recommendation. Concretely, we propose to inject the
preference understanding capability into LLM via a GAT expert model where the
user preference is better encoded by parallelly propagating the temporal
relations, and rating signals as well as various side information of historical
items. The parallel propagation mechanism could stabilize heterogeneous
features and offer an informative user preference encoding, which is then
injected into the language models via soft prompting at the cost of a single
token embedding. To further obtain the user's recent interests, we proposed a
novel Recent interaction Augmented Prompt (RAP) template. Experiment results
over three datasets against strong baselines validate the effectiveness of
ELCoRec. The code is available at
https://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Hierarchical Neural Framework for Classification and its Explanation
  in Large Unstructured Legal Documents <span class="chip">CIKM 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10563v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10563v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishchal Prasad, Mohand Boughanem, Taoufik Dkaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic legal judgment prediction and its explanation suffer from the
problem of long case documents exceeding tens of thousands of words, in
general, and having a non-uniform structure. Predicting judgments from such
documents and extracting their explanation becomes a challenging task, more so
on documents with no structural annotation. We define this problem as "scarce
annotated legal documents" and explore their lack of structural information and
their long lengths with a deep-learning-based classification framework which we
call MESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgment
prediction. We explore the adaptability of LLMs with multi-billion parameters
(GPT-Neo, and GPT-J) to legal texts and their intra-domain(legal) transfer
learning capacity. Alongside this, we compare their performance and
adaptability with MESc and the impact of combining embeddings from their last
layers. For such hierarchical models, we also propose an explanation extraction
algorithm named ORSE; Occlusion sensitivity-based Relevant Sentence Extractor;
based on the input-occlusion sensitivity of the model, to explain the
predictions with the most relevant sentences from the document. We explore
these methods and test their effectiveness with extensive experiments and
ablation studies on legal documents from India, the European Union, and the
United States with the ILDC dataset and a subset of the LexGLUE dataset. MESc
achieves a minimum total performance gain of approximately 2 points over
previous state-of-the-art proposed methods, while ORSE applied on MESc achieves
a total average gain of 50% over the baseline explainability scores.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as non archival paper in the The 3rd International Workshop
  on Mining and Learning in the Legal Domain (MLLD-2023) at CIKM 2023,
  Birmingham, United Kingdom. (https://sites.google.com/view/mlld2023/)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bioptic -- A Target-Agnostic Efficacy-Based Small Molecules Search
  Engine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14572v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14572v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vlad Vinogradov, Ivan Izmailov, Simon Steshin, Kong T. Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent successes in virtual screening have been made possible by large models
and extensive chemical libraries. However, combining these elements is
challenging: the larger the model, the more expensive it is to run, making
ultra-large libraries unfeasible. To address this, we developed a
target-agnostic, efficacy-based molecule search model, which allows us to find
structurally dissimilar molecules with similar biological activities. We used
the best practices to design fast retrieval system, based on
processor-optimized SIMD instructions, enabling us to screen the ultra-large
40B Enamine REAL library with 100\% recall rate. We extensively benchmarked our
model and several state-of-the-art models for both speed performance and
retrieval quality of novel molecules.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Accelerating Complex Disease Treatment through Network Medicine and
  GenAI: A Case Study on Drug Repurposing for Breast Cancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13106v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13106v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed Abdeen Hamed, Tamer E. Fandy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The objective of this research is to introduce a network specialized in
predicting drugs that can be repurposed by investigating real-world evidence
sources, such as clinical trials and biomedical literature. Specifically, it
aims to generate drug combination therapies for complex diseases (e.g., cancer,
Alzheimer's). We present a multilayered network medicine approach, empowered by
a highly configured ChatGPT prompt engineering system, which is constructed on
the fly to extract drug mentions in clinical trials. Additionally, we introduce
a novel algorithm that connects real-world evidence with disease-specific
signaling pathways (e.g., KEGG database). This sheds light on the
repurposability of drugs if they are found to bind with one or more protein
constituents of a signaling pathway. To demonstrate, we instantiated the
framework for breast cancer and found that, out of 46 breast cancer signaling
pathways, the framework identified 38 pathways that were covered by at least
two drugs. This evidence signals the potential for combining those drugs.
Specifically, the most covered signaling pathway, ID hsa:2064, was covered by
108 drugs, some of which can be combined. Conversely, the signaling pathway ID
hsa:1499 was covered by only two drugs, indicating a significant gap for
further research. Our network medicine framework, empowered by GenAI, shows
promise in identifying drug combinations with a high degree of specificity,
knowing the exact signaling pathways and proteins that serve as targets. It is
noteworthy that ChatGPT successfully accelerated the process of identifying
drug mentions in clinical trials, though further investigations are required to
determine the relationships among the drug mentions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages double columns, 5 figures, 3 algorithms, 3 tables, and 1
  listing, Submitted to IEEE MedAI'24 Conference, to be held November 15-17,
  Chongqing, China</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Error Bounds of Supervised Classification from Information-Theoretic
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04567v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04567v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Binchuan Qi, Wei Gong, Li Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There remains a list of unanswered research questions on deep learning (DL),
including the remarkable generalization power of overparametrized neural
networks, the efficient optimization performance despite the non-convexity, and
the mechanisms behind flat minima in generalization. In this paper, we adopt an
information-theoretic perspective to explore the theoretical foundations of
supervised classification using deep neural networks (DNNs). Our analysis
introduces the concepts of fitting error and model risk, which, together with
generalization error, constitute an upper bound on the expected risk. We
demonstrate that the generalization errors are bounded by the complexity,
influenced by both the smoothness of distribution and the sample size.
Consequently, task complexity serves as a reliable indicator of the dataset's
quality, guiding the setting of regularization hyperparameters. Furthermore,
the derived upper bound fitting error links the back-propagated gradient,
Neural Tangent Kernel (NTK), and the model's parameter count with the fitting
error. Utilizing the triangle inequality, we establish an upper bound on the
expected risk. This bound offers valuable insights into the effects of
overparameterization, non-convex optimization, and the flat minima in
DNNs.Finally, empirical verification confirms a significant positive
correlation between the derived theoretical bounds and the practical expected
risk, confirming the practical relevance of the theoretical findings.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">18</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Private Zeroth-Order Nonsmooth Nonconvex Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinzi Zhang, Hoang Tran, Ashok Cutkosky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a new zeroth-order algorithm for private stochastic optimization
on nonconvex and nonsmooth objectives. Given a dataset of size $M$, our
algorithm ensures $(\alpha,\alpha\rho^2/2)$-R\'enyi differential privacy and
finds a $(\delta,\epsilon)$-stationary point so long as
$M=\tilde\Omega\left(\frac{d}{\delta\epsilon^3} +
\frac{d^{3/2}}{\rho\delta\epsilon^2}\right)$. This matches the optimal
complexity of its non-private zeroth-order analog. Notably, although the
objective is not smooth, we have privacy ``for free'' whenever $\rho \ge
\sqrt{d}\epsilon$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PathAlign: A vision-language model for whole slide images in
  histopathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 main pages and 19 pages of supplemental material; 3 main tables, 3
  main figures and 11 supplemental tables, 7 supplemental figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Temporal Sequence Classification and Mathematical Modeling for Cell
  Tracking in Dense 3D Microscopy Videos of Bacterial Biofilms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tanjin Taher Toma, Yibo Wang, Andreas Gahlmann, Scott T. Acton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic cell tracking in dense environments is plagued by inaccurate
correspondences and misidentification of parent-offspring relationships. In
this paper, we introduce a novel cell tracking algorithm named DenseTrack,
which integrates deep learning with mathematical model-based strategies to
effectively establish correspondences between consecutive frames and detect
cell division events in crowded scenarios. We formulate the cell tracking
problem as a deep learning-based temporal sequence classification task followed
by solving a constrained one-to-one matching optimization problem exploiting
the classifier's confidence scores. Additionally, we present an
eigendecomposition-based cell division detection strategy that leverages
knowledge of cellular geometry. The performance of the proposed approach has
been evaluated by tracking densely packed cells in 3D time-lapse image
sequences of bacterial biofilm development. The experimental results on
simulated as well as experimental fluorescence image sequences suggest that the
proposed tracking method achieves superior performance in terms of both
qualitative and quantitative evaluation measures compared to recent
state-of-the-art cell tracking approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Counterfactual Interventions in Vector Autoregressive Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19573v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19573v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kurt Butler, Marija Iloska, Petar M. Djuric
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Counterfactual reasoning allows us to explore hypothetical scenarios in order
to explain the impacts of our decisions. However, addressing such inquires is
impossible without establishing the appropriate mathematical framework. In this
work, we introduce the problem of counterfactual reasoning in the context of
vector autoregressive (VAR) processes. We also formulate the inference of a
causal model as a joint regression task where for inference we use both data
with and without interventions. After learning the model, we exploit linearity
of the VAR model to make exact predictions about the effects of counterfactual
interventions. Furthermore, we quantify the total causal effects of past
counterfactual interventions. The source code for this project is freely
available at https://github.com/KurtButler/counterfactual_interventions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instance-Optimal Private Density Estimation in the Wasserstein Distance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19566v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19566v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vitaly Feldman, Audra McMillan, Satchit Sivakumar, Kunal Talwar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the density of a distribution from samples is a fundamental
problem in statistics. In many practical settings, the Wasserstein distance is
an appropriate error metric for density estimation. For example, when
estimating population densities in a geographic region, a small Wasserstein
distance means that the estimate is able to capture roughly where the
population mass is. In this work we study differentially private density
estimation in the Wasserstein distance. We design and analyze instance-optimal
algorithms for this problem that can adapt to easy instances.
  For distributions $P$ over $\mathbb{R}$, we consider a strong notion of
instance-optimality: an algorithm that uniformly achieves the instance-optimal
estimation rate is competitive with an algorithm that is told that the
distribution is either $P$ or $Q_P$ for some distribution $Q_P$ whose
probability density function (pdf) is within a factor of 2 of the pdf of $P$.
For distributions over $\mathbb{R}^2$, we use a different notion of instance
optimality. We say that an algorithm is instance-optimal if it is competitive
with an algorithm that is given a constant-factor multiplicative approximation
of the density of the distribution. We characterize the instance-optimal
estimation rates in both these settings and show that they are uniformly
achievable (up to polylogarithmic factors). Our approach for $\mathbb{R}^2$
extends to arbitrary metric spaces as it goes via hierarchically separated
trees. As a special case our results lead to instance-optimal private learning
in TV distance for discrete distributions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-Gradient Search Control: A Method for Improving the Efficiency of
  Dyna-style Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bradley Burega, John D. Martin, Luke Kapeluck, Michael Bowling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study how a Reinforcement Learning (RL) system can remain sample-efficient
when learning from an imperfect model of the environment. This is particularly
challenging when the learning system is resource-constrained and in continual
settings, where the environment dynamics change. To address these challenges,
our paper introduces an online, meta-gradient algorithm that tunes a
probability with which states are queried during Dyna-style planning. Our study
compares the aggregate, empirical performance of this meta-gradient method to
baselines that employ conventional sampling strategies. Results indicate that
our method improves efficiency of the planning process, which, as a
consequence, improves the sample-efficiency of the overall learning process. On
the whole, we observe that our meta-learned solutions avoid several pathologies
of conventional planning approaches, such as sampling inaccurate transitions
and those that stall credit assignment. We believe these findings could prove
useful, in future work, for designing model-based RL systems at scale.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cost-efficient Active Illumination Camera For Hyper-spectral
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhang, T. M. Sazzad, Yangyang Song, Spencer J. Chang, Ritesh Chowdhry, Tomas Mejia, Anna Hampton, Shelby Kucharski, Stefan Gerber, Barry Tillman, Marcio F. R. Resende, William M. Hammond, Chris H. Wilson, Alina Zare, Sanjeev J. Koppal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hyper-spectral imaging has recently gained increasing attention for use in
different applications, including agricultural investigation, ground tracking,
remote sensing and many other. However, the high cost, large physical size and
complicated operation process stop hyperspectral cameras from being employed
for various applications and research fields. In this paper, we introduce a
cost-efficient, compact and easy to use active illumination camera that may
benefit many applications. We developed a fully functional prototype of such
camera. With the hope of helping with agricultural research, we tested our
camera for plant root imaging. In addition, a U-Net model for spectral
reconstruction was trained by using a reference hyperspectral camera's data as
ground truth and our camera's data as input. We demonstrated our camera's
ability to obtain additional information over a typical RGB camera. In
addition, the ability to reconstruct hyperspectral data from multi-spectral
input makes our device compatible to models and algorithms developed for
hyperspectral applications with no modifications required.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BOrg: A Brain Organoid-Based Mitosis <span class="highlight-title">Dataset</span> for Automatic Analysis of
  Brain Diseases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Awais, Mehaboobathunnisa Sahul Hameed, Bidisha Bhattacharya, Orly Reiner, Rao Muhammad Anwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances have enabled the study of human brain development using brain
organoids derived from stem cells. Quantifying cellular processes like mitosis
in these organoids offers insights into neurodevelopmental disorders, but the
manual analysis is time-consuming, and existing datasets lack specific details
for brain organoid studies. We introduce BOrg, a dataset designed to study
mitotic events in the embryonic development of the brain using confocal
microscopy images of brain organoids. BOrg utilizes an efficient annotation
pipeline with sparse point annotations and techniques that minimize expert
effort, overcoming limitations of standard deep learning approaches on sparse
data. We adapt and benchmark state-of-the-art object detection and cell
counting models on BOrg for detecting and analyzing mitotic cells across
prophase, metaphase, anaphase, and telophase stages. Our results demonstrate
these adapted models significantly improve mitosis analysis efficiency and
accuracy for brain organoid research compared to existing methods. BOrg
facilitates the development of automated tools to quantify statistics like
mitosis rates, aiding mechanistic studies of neurodevelopmental processes and
disorders. Data and code are available at https://github.com/awaisrauf/borg.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking harmless refusals when fine-tuning foundation models <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19552v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19552v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florin Pop, Judd Rosenblatt, Diogo Schwerz de Lucena, Michael Vaiana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the degree to which fine-tuning in Large
Language Models (LLMs) effectively mitigates versus merely conceals undesirable
behavior. Through the lens of semi-realistic role-playing exercises designed to
elicit such behaviors, we explore the response dynamics of LLMs post
fine-tuning interventions. Our methodology involves prompting models for
Chain-of-Thought (CoT) reasoning and analyzing the coherence between the
reasoning traces and the resultant outputs. Notably, we identify a pervasive
phenomenon we term \emph{reason-based deception}, where models either stop
producing reasoning traces or produce seemingly ethical reasoning traces that
belie the unethical nature of their final outputs. We further examine the
efficacy of response strategies (polite refusal versus explicit rebuttal) in
curbing the occurrence of undesired behavior in subsequent outputs of
multi-turn interactions. Our findings reveal that explicit rebuttals
significantly outperform polite refusals in preventing the continuation of
undesired outputs and nearly eliminate reason-based deception, challenging
current practices in model fine-tuning. Accordingly, the two key contributions
of this paper are (1) defining and studying reason-based deception, a new type
of hidden behavior, and (2) demonstrating that rebuttals provide a more robust
response model to harmful requests than refusals, thereby highlighting the need
to reconsider the response strategies in fine-tuning approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2024 AGI Workshop Poster</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ASCENT: Amplifying Power Side-Channel Resilience via Learning &
  Monte-Carlo Tree Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19549v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19549v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jitendra Bhandari, Animesh Basak Chowdhury, Ozgur Sinanoglu, Siddharth Garg, Ramesh Karri, Johann Knechtel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Power side-channel (PSC) analysis is pivotal for securing cryptographic
hardware. Prior art focused on securing gate-level netlists obtained as-is from
chip design automation, neglecting all the complexities and potential
side-effects for security arising from the design automation process. That is,
automation traditionally prioritizes power, performance, and area (PPA),
sidelining security. We propose a "security-first" approach, refining the logic
synthesis stage to enhance the overall resilience of PSC countermeasures. We
introduce ASCENT, a learning-and-search-based framework that (i) drastically
reduces the time for post-design PSC evaluation and (ii) explores the
security-vs-PPA design space. Thus, ASCENT enables an efficient exploration of
a large number of candidate netlists, leading to an improvement in PSC
resilience compared to regular PPA-optimized netlists. ASCENT is up to 120x
faster than traditional PSC analysis and yields a 3.11x improvement for PSC
resilience of state-of-the-art PSC countermeasures
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at 2024 ACM/IEEE International Conference on Computer-Aided
  Design</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dataless Quadratic Neural Networks for the Maximum Independent Set
  Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ismail Alkhouri, Cedric Le Denmat, Yingjie Li, Cunxi Yu, Jia Liu, Rongrong Wang, Alvaro Velasquez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Combinatorial Optimization (CO) plays a crucial role in addressing various
significant problems, among them the challenging Maximum Independent Set (MIS)
problem. In light of recent advancements in deep learning methods, efforts have
been directed towards leveraging data-driven learning approaches, typically
rooted in supervised learning and reinforcement learning, to tackle the NP-hard
MIS problem. However, these approaches rely on labeled datasets, exhibit weak
generalization, and often depend on problem-specific heuristics. Recently,
ReLU-based dataless neural networks were introduced to address combinatorial
optimization problems. This paper introduces a novel dataless quadratic neural
network formulation, featuring a continuous quadratic relaxation for the MIS
problem. Notably, our method eliminates the need for training data by treating
the given MIS instance as a trainable entity. More specifically, the graph
structure and constraints of the MIS instance are used to define the structure
and parameters of the neural network such that training it on a fixed input
provides a solution to the problem, thereby setting it apart from traditional
supervised or reinforcement learning approaches. By employing a gradient-based
optimization algorithm like ADAM and leveraging an efficient off-the-shelf GPU
parallel implementation, our straightforward yet effective approach
demonstrates competitive or superior performance compared to state-of-the-art
learning-based methods. Another significant advantage of our approach is that,
unlike exact and heuristic solvers, the running time of our method scales only
with the number of nodes in the graph, not the number of edges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Forward and Backward State Abstractions for Off-policy Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19531v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19531v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meiling Hao, Pingfan Su, Liyuan Hu, Zoltan Szabo, Qingyuan Zhao, Chengchun Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Off-policy evaluation (OPE) is crucial for evaluating a target policy's
impact offline before its deployment. However, achieving accurate OPE in large
state spaces remains challenging.This paper studies state
abstractions-originally designed for policy learning-in the context of OPE. Our
contributions are three-fold: (i) We define a set of irrelevance conditions
central to learning state abstractions for OPE. (ii) We derive sufficient
conditions for achieving irrelevance in Q-functions and marginalized importance
sampling ratios, the latter obtained by constructing a time-reversed Markov
decision process (MDP) based on the observed MDP. (iii) We propose a novel
two-step procedure that sequentially projects the original state space into a
smaller space, which substantially simplify the sample complexity of OPE
arising from high cardinality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toc<span class="highlight-title">BERT</span>: Medical Document Structure Extraction Using Bidirectional
  <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Majd Saleh, Sarra Baghdadi, Stéphane Paquelet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text segmentation holds paramount importance in the field of Natural Language
Processing (NLP). It plays an important role in several NLP downstream tasks
like information retrieval and document summarization. In this work, we propose
a new solution, namely TocBERT, for segmenting texts using bidirectional
transformers. TocBERT represents a supervised solution trained on the detection
of titles and sub-titles from their semantic representations. This task was
formulated as a named entity recognition (NER) problem. The solution has been
applied on a medical text segmentation use-case where the Bio-ClinicalBERT
model is fine-tuned to segment discharge summaries of the MIMIC-III dataset.
The performance of TocBERT has been evaluated on a human-labeled ground truth
corpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a
linear text segmentation problem and 72.8% on a hierarchical text segmentation
problem. It outperformed a carefully designed rule-based solution, particularly
in distinguishing titles from subtitles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Symbolic <span class="highlight-title">Prompt</span> Program Search: A Structure-Aware Approach to Efficient
  Compile-Time <span class="highlight-title">Prompt</span> Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.02319v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.02319v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Schnabel, Jennifer Neville
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many modern LLM applications, such as retrieval augmented generation,
prompts have become programs themselves. In these settings, prompt programs are
repeatedly called with different user queries or data instances. A big
practical challenge is optimizing such prompt programs. Recent work has mostly
focused on either simple prompt programs or assumed that the general structure
of a prompt program is fixed.
  We introduce SAMMO, a framework to perform symbolic prompt program search for
compile-time optimizations of prompt programs. SAMMO represents prompt programs
on a symbolic level which allows for a rich set of transformations that can be
searched over during optimization. We show that SAMMO generalizes previous
methods and improves the performance of complex prompts on (1) instruction
tuning, (2) RAG pipeline tuning, and (3) prompt compression, across several
different LLMs. We make all code available open-source at
https://github.com/microsoft/sammo .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Hierarchical Neural Framework for Classification and its Explanation
  in Large Unstructured Legal Documents <span class="chip">CIKM 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10563v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10563v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishchal Prasad, Mohand Boughanem, Taoufik Dkaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic legal judgment prediction and its explanation suffer from the
problem of long case documents exceeding tens of thousands of words, in
general, and having a non-uniform structure. Predicting judgments from such
documents and extracting their explanation becomes a challenging task, more so
on documents with no structural annotation. We define this problem as "scarce
annotated legal documents" and explore their lack of structural information and
their long lengths with a deep-learning-based classification framework which we
call MESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgment
prediction. We explore the adaptability of LLMs with multi-billion parameters
(GPT-Neo, and GPT-J) to legal texts and their intra-domain(legal) transfer
learning capacity. Alongside this, we compare their performance and
adaptability with MESc and the impact of combining embeddings from their last
layers. For such hierarchical models, we also propose an explanation extraction
algorithm named ORSE; Occlusion sensitivity-based Relevant Sentence Extractor;
based on the input-occlusion sensitivity of the model, to explain the
predictions with the most relevant sentences from the document. We explore
these methods and test their effectiveness with extensive experiments and
ablation studies on legal documents from India, the European Union, and the
United States with the ILDC dataset and a subset of the LexGLUE dataset. MESc
achieves a minimum total performance gain of approximately 2 points over
previous state-of-the-art proposed methods, while ORSE applied on MESc achieves
a total average gain of 50% over the baseline explainability scores.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as non archival paper in the The 3rd International Workshop
  on Mining and Learning in the Legal Domain (MLLD-2023) at CIKM 2023,
  Birmingham, United Kingdom. (https://sites.google.com/view/mlld2023/)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-Modality Program Representation Learning for Electronic Design
  Automation with High-Level Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09606v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09606v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongyue Qin, Yunsheng Bai, Atefeh Sohrabizadeh, Zijian Ding, Ziniu Hu, Yizhou Sun, Jason Cong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, domain-specific accelerators (DSAs) have gained popularity
for applications such as deep learning and autonomous driving. To facilitate
DSA designs, programmers use high-level synthesis (HLS) to compile a high-level
description written in C/C++ into a design with low-level hardware description
languages that eventually synthesize DSAs on circuits. However, creating a
high-quality HLS design still demands significant domain knowledge,
particularly in microarchitecture decisions expressed as \textit{pragmas}.
Thus, it is desirable to automate such decisions with the help of machine
learning for predicting the quality of HLS designs, requiring a deeper
understanding of the program that consists of original code and pragmas.
Naturally, these programs can be considered as sequence data. In addition,
these programs can be compiled and converted into a control data flow graph
(CDFG). But existing works either fail to leverage both modalities or combine
the two in shallow or coarse ways. We propose ProgSG, a model that allows
interaction between the source code sequence modality and the graph modality in
a deep and fine-grained way. To alleviate the scarcity of labeled designs, a
pre-training method is proposed based on a suite of compiler's data flow
analysis tasks. Experimental results show that ProgSG reduces the RMSE of
design performance predictions by up to $22\%$, and identifies designs with an
average of $1.10\times$ and $1.26\times$ (up to $8.17\times$ and $13.31\times$)
performance improvement in design space exploration (DSE) task compared to HARP
and AutoDSE, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:2305.10838</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Condition Monitoring with Incomplete Data: An Integrated Variational
  Autoencoder and Distance Metric Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.05891v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.05891v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maryam Ahang, Mostafa Abbasi, Todd Charter, Homayoun Najjaran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Condition monitoring of industrial systems is crucial for ensuring safety and
maintenance planning, yet notable challenges arise in real-world settings due
to the limited or non-existent availability of fault samples. This paper
introduces an innovative solution to this problem by proposing a new method for
fault detection and condition monitoring for unseen data. Adopting an approach
inspired by zero-shot learning, our method can identify faults and assign a
relative health index to various operational conditions. Typically, we have
plenty of data on normal operations, some data on compromised conditions, and
very few (if any) samples of severe faults. We use a variational autoencoder to
capture the probabilistic distribution of previously seen and new unseen
conditions. The health status is determined by comparing each sample's
deviation from a normal operation reference distribution in the latent space.
Faults are detected by establishing a threshold for the health indexes,
allowing the model to identify severe, unseen faults with high accuracy, even
amidst noise. We validate our approach using the run-to-failure IMS-bearing
dataset and compare it with other methods. The health indexes generated by our
model closely match the established descriptive model of bearing wear,
attesting to the robustness and reliability of our method. These findings
highlight the potential of our methodology in augmenting fault detection
capabilities within industrial domains, thereby contributing to heightened
safety protocols and optimized maintenance practices.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in the 2024 IEEE 20th International Conference on Automation
  Science and Engineering (CASE 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Directions of Curvature as an Explanation for Loss of Plasticity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00246v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00246v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Lewandowski, Haruto Tanaka, Dale Schuurmans, Marlos C. Machado
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Loss of plasticity is a phenomenon in which neural networks lose their
ability to learn from new experience. Despite being empirically observed in
several problem settings, little is understood about the mechanisms that lead
to loss of plasticity. In this paper, we offer a consistent explanation for
loss of plasticity: Neural networks lose directions of curvature during
training and that loss of plasticity can be attributed to this reduction in
curvature. To support such a claim, we provide a systematic investigation of
loss of plasticity across continual learning tasks using MNIST, CIFAR-10 and
ImageNet. Our findings illustrate that loss of curvature directions coincides
with loss of plasticity, while also showing that previous explanations are
insufficient to explain loss of plasticity in all settings. Lastly, we show
that regularizers which mitigate loss of plasticity also preserve curvature,
motivating a simple distributional regularizer that proves to be effective
across the problem settings we considered.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Taming Data and <span class="highlight-title">Transformer</span>s for Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19388v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19388v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating ambient sounds and effects is a challenging problem due to data
scarcity and often insufficient caption quality, making it difficult to employ
large-scale generative models for the task. In this work, we tackle the problem
by introducing two new models. First, we propose AutoCap, a high-quality and
efficient automatic audio captioning model. We show that by leveraging metadata
available with the audio modality, we can substantially improve the quality of
captions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from
the best available captioning model at four times faster inference speed. We
then use AutoCap to caption clips from existing datasets, obtaining 761,000
audio clips with high-quality captions, forming the largest available
audio-text dataset. Second, we propose GenAu, a scalable transformer-based
audio generation architecture that we scale up to 1.25B parameters and train
with our new dataset. When compared to state-of-the-art audio generators, GenAu
obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5%
in CLAP score, indicating significantly improved quality of generated audio
compared to previous works. This shows that the quality of data is often as
important as its quantity. Besides, since AutoCap is fully automatic, new audio
samples can be added to the training dataset, unlocking the training of even
larger generative models for audio synthesis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Webpage: https://snap-research.github.io/GenAU/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Alleviating Text-to-Image Retrieval Hallucination for CLIP in
  Zero-shot Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18400v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18400v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanyao Wang, Yibing Zhan, Liu Liu, Liang Ding, Yan Yang, Jun Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretrained cross-modal models, for instance, the most representative CLIP,
have recently led to a boom in using pre-trained models for cross-modal
zero-shot tasks, considering the generalization properties. However, we
analytically discover that CLIP suffers from the text-to-image retrieval
hallucination, adversely limiting its capabilities under zero-shot learning:
CLIP would select the image with the highest score when asked to figure out
which image perfectly matches one given query text among several candidate
images even though CLIP knows contents in the image. Accordingly, we propose a
Balanced Score with Auxiliary Prompts (BSAP) to mitigate the CLIP's
text-to-image retrieval hallucination under zero-shot learning. Specifically,
we first design auxiliary prompts to provide multiple reference outcomes for
every single image retrieval, then the outcomes derived from each retrieved
image in conjunction with the target text are normalized to obtain the final
similarity, which alleviates hallucinations in the model. Additionally, we can
merge CLIP's original results and BSAP to obtain a more robust hybrid outcome
(BSAP-H). Extensive experiments on two typical zero-shot learning tasks, i.e.,
Referring Expression Comprehension (REC) and Referring Image Segmentation
(RIS), are conducted to demonstrate the effectiveness of our BSAP.
Specifically, when evaluated on the validation dataset of RefCOCO in REC, BSAP
increases CLIP's performance by 20.6%. Further, we validate that our strategy
could be applied in other types of pretrained cross-modal models, such as ALBEF
and BLIP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the lEEE for possible publication.
  Copyright may betransferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-06-26T00:00:00Z">2024-06-26</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">14</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond
  Four Stems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18747v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18747v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Karn N. Watcharasupat, Alexander Lerch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant recent progress across multiple subtasks of audio source
separation, few music source separation systems support separation beyond the
four-stem vocals, drums, bass, and other (VDBO) setup. Of the very few current
systems that support source separation beyond this setup, most continue to rely
on an inflexible decoder setup that can only support a fixed pre-defined set of
stems. Increasing stem support in these inflexible systems correspondingly
requires increasing computational complexity, rendering extensions of these
systems computationally infeasible for long-tail instruments. In this work, we
propose Banquet, a system that allows source separation of multiple stems using
just one decoder. A bandsplit source separation model is extended to work in a
query-based setup in tandem with a music instrument recognition PaSST model. On
the MoisesDB dataset, Banquet, at only 24.9 M trainable parameters, approached
the performance level of the significantly more complex 6-stem Hybrid
Transformer Demucs on VDBO stems and outperformed it on guitar and piano. The
query-based setup allows for the separation of narrow instrument classes such
as clean acoustic guitars, and can be successfully applied to the extraction of
less common stems such as reeds and organs. Implementation is available at
https://github.com/kwatcharasupat/query-bandit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to the 25th International Society for Music Information
  Retrieval Conference (ISMIR 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18740v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18740v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baharan Nouriinanloo, Maxime Lamothe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have been revolutionizing a myriad of natural
language processing tasks with their diverse zero-shot capabilities. Indeed,
existing work has shown that LLMs can be used to great effect for many tasks,
such as information retrieval (IR), and passage ranking. However, current
state-of-the-art results heavily lean on the capabilities of the LLM being
used. Currently, proprietary, and very large LLMs such as GPT-4 are the highest
performing passage re-rankers. Hence, users without the resources to leverage
top of the line LLMs, or ones that are closed source, are at a disadvantage. In
this paper, we investigate the use of a pre-filtering step before passage
re-ranking in IR. Our experiments show that by using a small number of human
generated relevance scores, coupled with LLM relevance scoring, it is
effectively possible to filter out irrelevant passages before re-ranking. Our
experiments also show that this pre-filtering then allows the LLM to perform
significantly better at the re-ranking task. Indeed, our results show that
smaller models such as Mixtral can become competitive with much larger
proprietary models (e.g., ChatGPT and GPT-4).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential
  Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Liu, Yitong Wang, Chenyue Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representation learning in sequential recommendation is critical for
accurately modeling user interaction patterns and improving recommendation
precision. However, existing approaches predominantly emphasize item-to-item
transitions, often neglecting the time intervals between interactions, which
are closely related to behavior pattern changes. Additionally, broader
interaction attributes, such as item frequency, are frequently overlooked. We
found that both sequences with more uniform time intervals and items with
higher frequency yield better prediction performance. Conversely, non-uniform
sequences exacerbate user interest drift and less-frequent items are difficult
to model due to sparse sampling, presenting unique challenges inadequately
addressed by current methods. In this paper, we propose UniRec, a novel
bidirectional enhancement sequential recommendation method. UniRec leverages
sequence uniformity and item frequency to enhance performance, particularly
improving the representation of non-uniform sequences and less-frequent items.
These two branches mutually reinforce each other, driving comprehensive
performance optimization in complex sequential recommendation scenarios.
Additionally, we present a multidimensional time module to further enhance
adaptability. To the best of our knowledge, UniRec is the first method to
utilize the characteristics of uniformity and frequency for feature
augmentation. Comparing with eleven advanced models across four datasets, we
demonstrate that UniRec outperforms SOTA models significantly. The code is
available at https://github.com/Linxi000/UniRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 8 figures, for source code, see
  https://github.com/Linxi000/UniRec</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Effects of Data Split Strategies on the Offline Experiments for CTR
  Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18320v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18320v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramazan Tarik Turksoy, Beyza Turkmen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Click-through rate (CTR) prediction is a crucial task in online advertising
to recommend products that users are likely to be interested in. To identify
the best-performing models, rigorous model evaluation is necessary. Offline
experimentation plays a significant role in selecting models for live user-item
interactions, despite the value of online experimentation like A/B testing,
which has its own limitations and risks. Often, the correlation between offline
performance metrics and actual online model performance is inadequate. One main
reason for this discrepancy is the common practice of using random splits to
create training, validation, and test datasets in CTR prediction. In contrast,
real-world CTR prediction follows a temporal order. Therefore, the methodology
used in offline evaluation, particularly the data splitting strategy, is
crucial. This study aims to address the inconsistency between current offline
evaluation methods and real-world use cases, by focusing on data splitting
strategies. To examine the impact of different data split strategies on offline
performance, we conduct extensive experiments using both random and temporal
splits on a large open benchmark dataset, Criteo.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Effects of Using Synthetic Data on Deep Recommender Models' Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18286v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18286v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fatih Cihan Taskin, Ilknur Akcay, Muhammed Pesen, Said Aldemir, Ipek Iraz Esin, Furkan Durmus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems are essential for enhancing user experiences by
suggesting items based on individual preferences. However, these systems
frequently face the challenge of data imbalance, characterized by a
predominance of negative interactions over positive ones. This imbalance can
result in biased recommendations favoring popular items. This study
investigates the effectiveness of synthetic data generation in addressing data
imbalances within recommender systems. Six different methods were used to
generate synthetic data. Our experimental approach involved generating
synthetic data using these methods and integrating the generated samples into
the original dataset. Our results show that the inclusion of generated negative
samples consistently improves the Area Under the Curve (AUC) scores. The
significant impact of synthetic negative samples highlights the potential of
data augmentation strategies to address issues of data sparsity and imbalance,
ultimately leading to improved performance of recommender systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving the Consistency in Cross-Lingual Cross-Modal Retrieval with
  1-to-K Contrastive Learning <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijie Nie, Richong Zhang, Zhangchi Feng, Hailang Huang, Xudong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-lingual Cross-modal Retrieval (CCR) is an essential task in web search,
which aims to break the barriers between modality and language simultaneously
and achieves image-text retrieval in the multi-lingual scenario with a single
model. In recent years, excellent progress has been made based on cross-lingual
cross-modal pre-training; particularly, the methods based on contrastive
learning on large-scale data have significantly improved retrieval tasks.
However, these methods directly follow the existing pre-training methods in the
cross-lingual or cross-modal domain, leading to two problems of inconsistency
in CCR: The methods with cross-lingual style suffer from the intra-modal error
propagation, resulting in inconsistent recall performance across languages in
the whole dataset. The methods with cross-modal style suffer from the
inter-modal optimization direction bias, resulting in inconsistent rank across
languages within each instance, which cannot be reflected by Recall@K. To solve
these problems, we propose a simple but effective 1-to-K contrastive learning
method, which treats each language equally and eliminates error propagation and
optimization bias. In addition, we propose a new evaluation metric, Mean Rank
Variance (MRV), to reflect the rank inconsistency across languages within each
instance. Extensive experiments on four CCR datasets show that our method
improves both recall rates and MRV with smaller-scale pre-trained data,
achieving the new state-of-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2024 Research Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Concordance in basal cell carcinoma diagnosis. Building a proper ground
  truth to train Artificial Intelligence tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisca Silva-Clavería, Carmen Serrano, Iván Matas, Amalia Serrano, Tomás Toledo-Pastrana, David Moreno-Ramírez, Begoña Acha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background: The existence of different basal cell carcinoma (BCC) clinical
criteria cannot be objectively validated. An adequate ground-truth is needed to
train an artificial intelligence (AI) tool that explains the BCC diagnosis by
providing its dermoscopic features. Objectives: To determine the consensus
among dermatologists on dermoscopic criteria of 204 BCC. To analyze the
performance of an AI tool when the ground-truth is inferred. Methods: A single
center, diagnostic and prospective study was conducted to analyze the agreement
in dermoscopic criteria by four dermatologists and then derive a reference
standard. 1434 dermoscopic images have been used, that were taken by a primary
health physician, sent via teledermatology, and diagnosed by a dermatologist.
They were randomly selected from the teledermatology platform (2019-2021). 204
of them were tested with an AI tool; the remainder trained it. The performance
of the AI tool trained using the ground-truth of one dermatologist versus the
ground-truth statistically inferred from the consensus of four dermatologists
was analyzed using McNemar's test and Hamming distance. Results: Dermatologists
achieve perfect agreement in the diagnosis of BCC (Fleiss-Kappa=0.9079), and a
high correlation with the biopsy (PPV=0.9670). However, there is low agreement
in detecting some dermoscopic criteria. Statistical differences were found in
the performance of the AI tool trained using the ground-truth of one
dermatologist versus the ground-truth statistically inferred from the consensus
of four dermatologists. Conclusions: Care should be taken when training an AI
tool to determine the BCC patterns present in a lesion. Ground-truth should be
established from multiple dermatologists.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Manuscript word count: 3000, Number of figures: 2, Number of tables:
  3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Graph Enhanced Retrieval-Augmented Generation for Failure Mode
  and Effects Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18114v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18114v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Bahr, Christoph Wehner, Judith Wewerka, José Bittencourt, Ute Schmid, Rüdiger Daub
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Failure mode and effects analysis (FMEA) is a critical tool for mitigating
potential failures, particular during ramp-up phases of new products. However,
its effectiveness is often limited by the missing reasoning capabilities of the
FMEA tools, which are usually tabular structured. Meanwhile, large language
models (LLMs) offer novel prospects for fine-tuning on custom datasets for
reasoning within FMEA contexts. However, LLMs face challenges in tasks that
require factual knowledge, a gap that retrieval-augmented generation (RAG)
approaches aim to fill. RAG retrieves information from a non-parametric data
store and uses a language model to generate responses. Building on this idea,
we propose to advance the non-parametric data store with a knowledge graph
(KG). By enhancing the RAG framework with a KG, our objective is to leverage
analytical and semantic question-answering capabilities on FMEA data. This
paper contributes by presenting a new ontology for FMEA observations, an
algorithm for creating vector embeddings from the FMEA KG, and a KG enhanced
RAG framework. Our approach is validated through a human study and we measure
the performance of the context retrieval recall and precision.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Retrieval Augmented Zero-Shot Text Classification <span class="chip">SIGIR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15241v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15241v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tassallah Abdullahi, Ritambhara Singh, Carsten Eickhoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot text learning enables text classifiers to handle unseen classes
efficiently, alleviating the need for task-specific training data. A simple
approach often relies on comparing embeddings of query (text) to those of
potential classes. However, the embeddings of a simple query sometimes lack
rich contextual information, which hinders the classification performance.
Traditionally, this has been addressed by improving the embedding model with
expensive training. We introduce QZero, a novel training-free knowledge
augmentation approach that reformulates queries by retrieving supporting
categories from Wikipedia to improve zero-shot text classification performance.
Our experiments across six diverse datasets demonstrate that QZero enhances
performance for state-of-the-art static and contextual embedding models without
the need for retraining. Notably, in News and medical topic classification
tasks, QZero improves the performance of even the largest OpenAI embedding
model by at least 5% and 3%, respectively. Acting as a knowledge amplifier,
QZero enables small word embedding models to achieve performance levels
comparable to those of larger contextual models, offering the potential for
significant computational savings. Additionally, QZero offers meaningful
insights that illuminate query context and verify topic relevance, aiding in
understanding model predictions. Overall, QZero improves embedding-based
zero-shot classifiers while maintaining their simplicity. This makes it
particularly valuable for resource-constrained environments and domains with
constantly evolving information.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of the 2024 ACM SIGIR International Conference on the
  Theory of Information Retrieval (ICTIR '24), July 13, 2024, Washington DC,
  DC, USA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generate then Retrieve: Conversational Response Retrieval Using LLMs as
  Answer and Query Generators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19302v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19302v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zahra Abbasiantaeb, Mohammad Aliannejadi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  CIS is a prominent area in IR which focuses on developing interactive
knowledge assistants. These systems must adeptly comprehend the user's
information requirements within the conversational context and retrieve the
relevant information. To this aim, the existing approaches model the user's
information needs by generating a single query rewrite or a single
representation of the query in the query space embedding. However, to answer
complex questions, a single query rewrite or representation is often
ineffective. To address this, a system needs to do reasoning over multiple
passages. In this work, we propose using a generate-then-retrieve approach to
improve the passage retrieval performance for complex user queries. In this
approach, we utilize large language models (LLMs) to (i) generate an initial
answer to the user's information need by doing reasoning over the context of
the conversation, and (ii) ground this answer to the collection. Based on the
experiments, our proposed approach significantly improves the retrieval
performance on TREC iKAT 23, TREC CAsT 20 and 22 datasets, under various
setups. Also, we show that grounding the LLM's answer requires more than one
searchable query, where an average of 3 queries outperforms human rewrites.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ General Distribution Learning: A theoretical framework for Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05666v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05666v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Binchuan Qi, Li Li, Wei Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There remain numerous unanswered research questions on deep learning (DL)
within the classical learning theory framework. These include the remarkable
generalization capabilities of overparametrized neural networks (NNs), the
efficient optimization performance despite non-convexity of objectives, the
mechanism of flat minima for generalization, and the exceptional performance of
deep architectures in solving physical problems. This paper introduces General
Distribution Learning (GD Learning), a novel theoretical learning framework
designed to address a comprehensive range of machine learning and statistical
tasks, including classification, regression and parameter estimation. Departing
from traditional statistical machine learning, GD Learning focuses on the true
underlying distribution. In GD Learning, learning error, corresponding to the
expected error in classical statistical learning framework, is divided into
fitting errors due to models and algorithms, as well as sampling errors
introduced by limited sampling data. The framework significantly incorporates
prior knowledge, especially in scenarios characterized by data scarcity,
thereby enhancing performance. Within the GD Learning framework, we demonstrate
that the global optimal solutions in non-convex optimization can be approached
by minimizing the gradient norm and the non-uniformity of the eigenvalues of
the model's Jacobian matrix. This insight leads to the development of the
gradient structure control algorithm. GD Learning also offers fresh insights
into the questions on deep learning, including overparameterization and
non-convex optimization, bias-variance trade-off, and the mechanism of flat
minima.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other
  authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Jina CLIP: Your CLIP Model Is Also Your Text Retriever <span class="chip">ICML2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20204v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20204v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andreas Koukounas, Georgios Mastrapas, Michael Günther, Bo Wang, Scott Martens, Isabelle Mohr, Saba Sturua, Mohammad Kalim Akram, Joan Fontanals Martínez, Saahil Ognawala, Susana Guzman, Maximilian Werk, Nan Wang, Han Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive Language-Image Pretraining (CLIP) is widely used to train models
to align images and texts in a common embedding space by mapping them to
fixed-sized vectors. These models are key to multimodal information retrieval
and related tasks. However, CLIP models generally underperform in text-only
tasks compared to specialized text models. This creates inefficiencies for
information retrieval systems that keep separate embeddings and models for
text-only and multimodal tasks. We propose a novel, multi-task contrastive
training method to address this issue, which we use to train the jina-clip-v1
model to achieve the state-of-the-art performance on both text-image and
text-text retrieval tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, MFM-EAI@ICML2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Click<span class="highlight-title">Prompt</span>: CTR Models are Strong <span class="highlight-title">Prompt</span> Generators for Adapting
  Language Models to CTR Prediction <span class="chip">WWW 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09234v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09234v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianghao Lin, Bo Chen, Hangyu Wang, Yunjia Xi, Yanru Qu, Xinyi Dai, Kangning Zhang, Ruiming Tang, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Click-through rate (CTR) prediction has become increasingly indispensable for
various Internet applications. Traditional CTR models convert the multi-field
categorical data into ID features via one-hot encoding, and extract the
collaborative signals among features. Such a paradigm suffers from the problem
of semantic information loss. Another line of research explores the potential
of pretrained language models (PLMs) for CTR prediction by converting input
data into textual sentences through hard prompt templates. Although semantic
signals are preserved, they generally fail to capture the collaborative
information (e.g., feature interactions, pure ID features), not to mention the
unacceptable inference overhead brought by the huge model size. In this paper,
we aim to model both the semantic knowledge and collaborative knowledge for
accurate CTR estimation, and meanwhile address the inference inefficiency
issue. To benefit from both worlds and close their gaps, we propose a novel
model-agnostic framework (i.e., ClickPrompt), where we incorporate CTR models
to generate interaction-aware soft prompts for PLMs. We design a
prompt-augmented masked language modeling (PA-MLM) pretraining task, where PLM
has to recover the masked tokens based on the language context, as well as the
soft prompts generated by CTR model. The collaborative and semantic knowledge
from ID and textual features would be explicitly aligned and interacted via the
prompt interface. Then, we can either tune the CTR model with PLM for superior
performance, or solely tune the CTR model without PLM for inference efficiency.
Experiments on four real-world datasets validate the effectiveness of
ClickPrompt compared with existing baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continual Collaborative Distillation for Recommender System <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19046v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19046v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gyuseok Lee, SeongKu Kang, Wonbin Kweon, Hwanjo Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge distillation (KD) has emerged as a promising technique for
addressing the computational challenges associated with deploying large-scale
recommender systems. KD transfers the knowledge of a massive teacher system to
a compact student model, to reduce the huge computational burdens for inference
while retaining high accuracy. The existing KD studies primarily focus on
one-time distillation in static environments, leaving a substantial gap in
their applicability to real-world scenarios dealing with continuously incoming
users, items, and their interactions. In this work, we delve into a systematic
approach to operating the teacher-student KD in a non-stationary data stream.
Our goal is to enable efficient deployment through a compact student, which
preserves the high performance of the massive teacher, while effectively
adapting to continuously incoming data. We propose Continual Collaborative
Distillation (CCD) framework, where both the teacher and the student
continually and collaboratively evolve along the data stream. CCD facilitates
the student in effectively adapting to new data, while also enabling the
teacher to fully leverage accumulated knowledge. We validate the effectiveness
of CCD through extensive quantitative, ablative, and exploratory experiments on
two real-world datasets. We expect this research direction to contribute to
narrowing the gap between existing KD studies and practical applications,
thereby enhancing the applicability of KD in real-world systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2024 research track. 9 main pages + 1 appendix page,
  5 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving the Consistency in Cross-Lingual Cross-Modal Retrieval with
  1-to-K Contrastive Learning <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijie Nie, Richong Zhang, Zhangchi Feng, Hailang Huang, Xudong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-lingual Cross-modal Retrieval (CCR) is an essential task in web search,
which aims to break the barriers between modality and language simultaneously
and achieves image-text retrieval in the multi-lingual scenario with a single
model. In recent years, excellent progress has been made based on cross-lingual
cross-modal pre-training; particularly, the methods based on contrastive
learning on large-scale data have significantly improved retrieval tasks.
However, these methods directly follow the existing pre-training methods in the
cross-lingual or cross-modal domain, leading to two problems of inconsistency
in CCR: The methods with cross-lingual style suffer from the intra-modal error
propagation, resulting in inconsistent recall performance across languages in
the whole dataset. The methods with cross-modal style suffer from the
inter-modal optimization direction bias, resulting in inconsistent rank across
languages within each instance, which cannot be reflected by Recall@K. To solve
these problems, we propose a simple but effective 1-to-K contrastive learning
method, which treats each language equally and eliminates error propagation and
optimization bias. In addition, we propose a new evaluation metric, Mean Rank
Variance (MRV), to reflect the rank inconsistency across languages within each
instance. Extensive experiments on four CCR datasets show that our method
improves both recall rates and MRV with smaller-scale pre-trained data,
achieving the new state-of-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD 2024 Research Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Study on Synthesizing Expressive Violin Performances: Approaches and
  Comparisons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18089v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18089v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tzu-Yun Hung, Jui-Te Wu, Yu-Chia Kuo, Yo-Wei Hsiao, Ting-Wei Lin, Li Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expressive music synthesis (EMS) for violin performance is a challenging task
due to the disagreement among music performers in the interpretation of
expressive musical terms (EMTs), scarcity of labeled recordings, and limited
generalization ability of the synthesis model. These challenges create
trade-offs between model effectiveness, diversity of generated results, and
controllability of the synthesis system, making it essential to conduct a
comparative study on EMS model design. This paper explores two violin EMS
approaches. The end-to-end approach is a modification of a state-of-the-art
text-to-speech generator. The parameter-controlled approach is based on a
simple parameter sampling process that can render note lengths and other
parameters compatible with MIDI-DDSP. We study these two approaches (in total,
three model variants) through objective and subjective experiments and discuss
several key issues of EMS based on the results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 2 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ObjFormer: Learning Land-Cover Changes From Paired OSM Data and Optical
  High-Resolution Imagery via Object-Guided <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.02674v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.02674v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongruixuan Chen, Cuiling Lan, Jian Song, Clifford Broni-Bediako, Junshi Xia, Naoto Yokoya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optical high-resolution imagery and OSM data are two important data sources
of change detection (CD). Previous related studies focus on utilizing the
information in OSM data to aid the CD on optical high-resolution images. This
paper pioneers the direct detection of land-cover changes utilizing paired OSM
data and optical imagery, thereby expanding the scope of CD tasks. To this end,
we propose an object-guided Transformer (ObjFormer) by naturally combining the
object-based image analysis (OBIA) technique with the advanced vision
Transformer architecture. This combination can significantly reduce the
computational overhead in the self-attention module without adding extra
parameters or layers. ObjFormer has a hierarchical pseudo-siamese encoder
consisting of object-guided self-attention modules that extracts multi-level
heterogeneous features from OSM data and optical images; a decoder consisting
of object-guided cross-attention modules can recover land-cover changes from
the extracted heterogeneous features. Beyond basic binary change detection,
this paper raises a new semi-supervised semantic change detection task that
does not require any manually annotated land-cover labels to train semantic
change detectors. Two lightweight semantic decoders are added to ObjFormer to
accomplish this task efficiently. A converse cross-entropy loss is designed to
fully utilize negative samples, contributing to the great performance
improvement in this task. A large-scale benchmark dataset called OpenMapCD
containing 1,287 samples covering 40 regions on six continents is constructed
to conduct detailed experiments. The results show the effectiveness of our
methods in this new kind of CD task. Additionally, case studies in Japanese
cities demonstrate the framework's generalizability and practical potential.
The OpenMapCD and source code are available in
https://github.com/ChenHongruixuan/ObjFormer
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE TGRS</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-06-25T00:00:00Z">2024-06-25</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Document Ranking with Learnable Late Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17968v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17968v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziwei Ji, Himanshu Jain, Andreas Veit, Sashank J. Reddi, Sadeep Jayasumana, Ankit Singh Rawat, Aditya Krishna Menon, Felix Yu, Sanjiv Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Encoder (CE) and Dual-Encoder (DE) models are two fundamental
approaches for query-document relevance in information retrieval. To predict
relevance, CE models use joint query-document embeddings, while DE models
maintain factorized query and document embeddings; usually, the former has
higher quality while the latter benefits from lower latency. Recently,
late-interaction models have been proposed to realize more favorable
latency-quality tradeoffs, by using a DE structure followed by a lightweight
scorer based on query and document token embeddings. However, these lightweight
scorers are often hand-crafted, and there is no understanding of their
approximation power; further, such scorers require access to individual
document token embeddings, which imposes an increased latency and storage
burden. In this paper, we propose novel learnable late-interaction models
(LITE) that resolve these issues. Theoretically, we prove that LITE is a
universal approximator of continuous scoring functions, even for relatively
small embedding dimension. Empirically, LITE outperforms previous
late-interaction models such as ColBERT on both in-domain and zero-shot
re-ranking tasks. For instance, experiments on MS MARCO passage re-ranking show
that LITE not only yields a model with better generalization, but also lowers
latency and requires 0.25x storage compared to ColBERT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data
  Normalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17961v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17961v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Mahadi Hasan Nahid, Davood Rafiei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Large Language Models (LLMs) have demonstrated remarkable
capabilities in parsing textual data and generating code. However, their
performance in tasks involving tabular data, especially those requiring
symbolic reasoning, faces challenges due to the structural variance and
inconsistency in table cell values often found in web tables. In this paper, we
introduce NormTab, a novel framework aimed at enhancing the symbolic reasoning
performance of LLMs by normalizing web tables. We study table normalization as
a stand-alone, one-time preprocessing step using LLMs to support symbolic
reasoning on tabular data. Our experimental evaluation, conducted on
challenging web table datasets such as WikiTableQuestion and TabFact,
demonstrates that leveraging NormTab significantly improves symbolic reasoning
performance, showcasing the importance and effectiveness of web table
normalization for enhancing LLM-based symbolic reasoning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Light-weight End-to-End Graph Interest Network for CTR Prediction in
  E-commerce Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17745v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17745v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pai Peng, Quanxiang Jia, Ziqiang Zhou, Shuang Hong, Zichong Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Click-through-rate (CTR) prediction has an essential impact on improving user
experience and revenue in e-commerce search. With the development of deep
learning, graph-based methods are well exploited to utilize graph structure
extracted from user behaviors and other information to help embedding learning.
However, most of the previous graph-based methods mainly focus on
recommendation scenarios, and therefore their graph structures highly depend on
item's sequential information from user behaviors, ignoring query's sequential
signal and query-item correlation. In this paper, we propose a new approach
named Light-weight End-to-End Graph Interest Network (EGIN) to effectively mine
users' search interests and tackle previous challenges. (i) EGIN utilizes query
and item's correlation and sequential information from the search system to
build a heterogeneous graph for better CTR prediction in e-commerce search.
(ii) EGIN's graph embedding learning shares the same training input and is
jointly trained with CTR prediction, making the end-to-end framework effortless
to deploy in large-scale search systems. The proposed EGIN is composed of three
parts: query-item heterogeneous graph, light-weight graph sampling, and
multi-interest network. The query-item heterogeneous graph captures correlation
and sequential information of query and item efficiently by the proposed
light-weight graph sampling. The multi-interest network is well designed to
utilize graph embedding to capture various similarity relationships between
query and item to enhance the final CTR prediction. We conduct extensive
experiments on both public and industrial datasets to demonstrate the
effectiveness of the proposed EGIN. At the same time, the training cost of
graph learning is relatively low compared with the main CTR prediction task,
ensuring efficiency in practical applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LumberChunker: Long-Form Narrative Document Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        André V. Duarte, João Marques, Miguel Graça, Miguel Freire, Lei Li, Arlindo L. Oliveira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern NLP tasks increasingly rely on dense retrieval methods to access
up-to-date and relevant contextual information. We are motivated by the premise
that retrieval benefits from segments that can vary in size such that a
content's semantic independence is better captured. We propose LumberChunker, a
method leveraging an LLM to dynamically segment documents, which iteratively
prompts the LLM to identify the point within a group of sequential passages
where the content begins to shift. To evaluate our method, we introduce
GutenQA, a benchmark with 3000 "needle in a haystack" type of question-answer
pairs derived from 100 public domain narrative books available on Project
Gutenberg. Our experiments show that LumberChunker not only outperforms the
most competitive baseline by 7.37% in retrieval performance (DCG@20) but also
that, when integrated into a RAG pipeline, LumberChunker proves to be more
effective than other chunking methods and competitive baselines, such as the
Gemini 1.5M Pro. Our Code and Data are available at
https://github.com/joaodsmarques/LumberChunker
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ACE: A Generative Cross-Modal Retrieval Framework with Coarse-To-Fine
  Semantic Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17507v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17507v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghui Fang, Shengpeng Ji, Jialong Zuo, Hai Huang, Yan Xia, Jieming Zhu, Xize Cheng, Xiaoda Yang, Wenrui Liu, Gang Wang, Zhenhua Dong, Zhou Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative retrieval, which has demonstrated effectiveness in text-to-text
retrieval, utilizes a sequence-to-sequence model to directly generate candidate
identifiers based on natural language queries. Without explicitly computing the
similarity between queries and candidates, generative retrieval surpasses
dual-tower models in both speed and accuracy on large-scale corpora, providing
new insights for cross-modal retrieval. However, constructing identifiers for
multimodal data remains an untapped problem, and the modality gap between
natural language queries and multimodal candidates hinders retrieval
performance due to the absence of additional encoders. To this end, we propose
a pioneering generAtive Cross-modal rEtrieval framework (ACE), which is a
comprehensive framework for end-to-end cross-modal retrieval based on
coarse-to-fine semantic modeling. We propose combining K-Means and RQ-VAE to
construct coarse and fine tokens, serving as identifiers for multimodal data.
Correspondingly, we design the coarse-to-fine feature fusion strategy to
efficiently align natural language queries and candidate identifiers. ACE is
the first work to comprehensively demonstrate the feasibility of generative
approach on text-to-image/audio/video retrieval, challenging the dominance of
the embedding-based dual-tower architecture. Extensive experiments show that
ACE achieves state-of-the-art performance in cross-modal retrieval and
outperforms the strong baselines on Recall@1 by 15.27% on average.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performative Debias with Fair-exposure Optimization Driven by Strategic
  Agents in Recommender Systems <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhichen Xiang, Hongke Zhao, Chuang Zhao, Ming He, Jianping Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data bias, e.g., popularity impairs the dynamics of two-sided markets within
recommender systems. This overshadows the less visible but potentially
intriguing long-tail items that could capture user interest. Despite the
abundance of research surrounding this issue, it still poses challenges and
remains a hot topic in academic circles. Along this line, in this paper, we
developed a re-ranking approach in dynamic settings with fair-exposure
optimization driven by strategic agents. Designed for the producer side, the
execution of agents assumes content creators can modify item features based on
strategic incentives to maximize their exposure. This iterative process entails
an end-to-end optimization, employing differentiable ranking operators that
simultaneously target accuracy and fairness. Joint objectives ensure the
performance of recommendations while enhancing the visibility of tail items. We
also leveraged the performativity nature of predictions to illustrate how
strategic learning influences content creators to shift towards fairness
efficiently, thereby incentivizing features of tail items. Through
comprehensive experiments on both public and industrial datasets, we have
substantiated the effectiveness and dominance of the proposed method especially
on unveiling the potential of tail items.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGKDD 2024 accepted paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns
  Well with The Key Tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17378v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17378v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijie Nie, Richong Zhang, Zhanyu Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text embeddings from large language models (LLMs) have achieved excellent
results in tasks such as information retrieval, semantic textual similarity,
etc. In this work, we show an interesting finding: when feeding a text into the
embedding LLMs, the obtained text embedding will be able to be aligned with the
key tokens in the input text. We first fully analyze this phenomenon on eight
embedding LLMs and show that this phenomenon is universal and is not affected
by model architecture, training strategy, and embedding method. With a deeper
analysis, we then find that the main change in embedding space between the
embedding LLMs and their original generative LLMs is in the first principal
component. By adjusting the first principal component, we can align text
embedding with the key tokens. Finally, we give several examples to demonstrate
the vast application potential of this finding: (1) we propose a simple and
practical sparse retrieval method based on the aligned tokens, which can
achieve 80\% of the dense retrieval effect of the same model while reducing the
computation significantly; (2) we show that our findings provide a fresh
perspective to help understand fuzzy concepts (e.g., semantic relatedness vs.
semantic similarity) and emerging technologies (e.g., instruction-following
embedding) in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Thorough Performance Benchmarking on Lightweight Embedding-based
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hung Vinh Tran, Tong Chen, Quoc Viet Hung Nguyen, Zi Huang, Lizhen Cui, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since the creation of the Web, recommender systems (RSs) have been an
indispensable mechanism in information filtering. State-of-the-art RSs
primarily depend on categorical features, which ecoded by embedding vectors,
resulting in excessively large embedding tables. To prevent over-parameterized
embedding tables from harming scalability, both academia and industry have seen
increasing efforts in compressing RS embeddings. However, despite the
prosperity of lightweight embedding-based RSs (LERSs), a wide diversity is seen
in evaluation protocols, resulting in obstacles when relating LERS performance
to real-world usability. Moreover, despite the common goal of lightweight
embeddings, LERSs are evaluated with a single choice between the two main
recommendation tasks -- collaborative filtering and content-based
recommendation. This lack of discussions on cross-task transferability hinders
the development of unified, more scalable solutions. Motivated by these issues,
this study investigates various LERSs' performance, efficiency, and cross-task
transferability via a thorough benchmarking process. Additionally, we propose
an efficient embedding compression method using magnitude pruning, which is an
easy-to-deploy yet highly competitive baseline that outperforms various complex
LERSs. Our study reveals the distinct performance of LERSs across the two
tasks, shedding light on their effectiveness and generalizability. To support
edge-based recommendations, we tested all LERSs on a Raspberry Pi 4, where the
efficiency bottleneck is exposed. Finally, we conclude this paper with critical
summaries of LERS performance, model selection suggestions, and underexplored
challenges around LERSs for future research. To encourage future research, we
publish source codes and artifacts at \href{this
link}{https://github.com/chenxing1999/recsys-benchmark}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hyperbolic Knowledge Transfer in Cross-Domain Recommendation System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17289v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17289v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Yang, Heng Chang, Zhijian La, Jinze Yang, Xingrun Li, Yu Lu, Shuaiqiang Wang, Dawei Yin, Erxue Min
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Recommendation (CDR) seeks to utilize knowledge from different
domains to alleviate the problem of data sparsity in the target recommendation
domain, and it has been gaining more attention in recent years. Although there
have been notable advancements in this area, most current methods represent
users and items in Euclidean space, which is not ideal for handling long-tail
distributed data in recommendation systems. Additionally, adding data from
other domains can worsen the long-tail characteristics of the entire dataset,
making it harder to train CDR models effectively. Recent studies have shown
that hyperbolic methods are particularly suitable for modeling long-tail
distributions, which has led us to explore hyperbolic representations for users
and items in CDR scenarios. However, due to the distinct characteristics of the
different domains, applying hyperbolic representation learning to CDR tasks is
quite challenging. In this paper, we introduce a new framework called
Hyperbolic Contrastive Learning (HCTS), designed to capture the unique features
of each domain while enabling efficient knowledge transfer between domains. We
achieve this by embedding users and items from each domain separately and
mapping them onto distinct hyperbolic manifolds with adjustable curvatures for
prediction. To improve the representations of users and items in the target
domain, we develop a hyperbolic contrastive learning module for knowledge
transfer. Extensive experiments on real-world datasets demonstrate that
hyperbolic manifolds are a promising alternative to Euclidean space for CDR
tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gradient Coding with Iterative Block Leverage Score Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.03096v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.03096v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neophytos Charalambides, Mert Pilanci, Alfred Hero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We generalize the leverage score sampling sketch for $\ell_2$-subspace
embeddings, to accommodate sampling subsets of the transformed data, so that
the sketching approach is appropriate for distributed settings. This is then
used to derive an approximate coded computing approach for first-order methods;
known as gradient coding, to accelerate linear regression in the presence of
failures in distributed computational networks, \textit{i.e.} stragglers. We
replicate the data across the distributed network, to attain the approximation
guarantees through the induced sampling distribution. The significance and main
contribution of this work, is that it unifies randomized numerical linear
algebra with approximate coded computing, while attaining an induced
$\ell_2$-subspace embedding through uniform sampling. The transition to uniform
sampling is done without applying a random projection, as in the case of the
subsampled randomized Hadamard transform. Furthermore, by incorporating this
technique to coded computing, our scheme is an iterative sketching approach to
approximately solving linear regression. We also propose weighting when
sketching takes place through sampling with replacement, for further
compression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 6 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Neural Optimization with Adaptive Heuristics for Intelligent Marketing
  System <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.10490v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.10490v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changshuai Wei, Benjamin Zelditch, Joyce Chen, Andre Assuncao Silva T Ribeiro, Jingyi Kenneth Tay, Borja Ocejo Elizondo, Keerthi Selvaraj, Aman Gupta, Licurgo Benemann De Almeida
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computational marketing has become increasingly important in today's digital
world, facing challenges such as massive heterogeneous data, multi-channel
customer journeys, and limited marketing budgets. In this paper, we propose a
general framework for marketing AI systems, the Neural Optimization with
Adaptive Heuristics (NOAH) framework. NOAH is the first general framework for
marketing optimization that considers both to-business (2B) and to-consumer
(2C) products, as well as both owned and paid channels. We describe key modules
of the NOAH framework, including prediction, optimization, and adaptive
heuristics, providing examples for bidding and content optimization. We then
detail the successful application of NOAH to LinkedIn's email marketing system,
showcasing significant wins over the legacy ranking system. Additionally, we
share details and insights that are broadly useful, particularly on: (i)
addressing delayed feedback with lifetime value, (ii) performing large-scale
linear programming with randomization, (iii) improving retrieval with audience
expansion, (iv) reducing signal dilution in targeting tests, and (v) handling
zero-inflated heavy-tail metrics in statistical testing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do Large Language Models Rank Fairly? An Empirical Study on the Fairness
  of LLMs as Rankers <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03192v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03192v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Wang, Xuyang Wu, Hsin-Tai Wu, Zhiqiang Tao, Yi Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of Large Language Models (LLMs) in information retrieval has
raised a critical reevaluation of fairness in the text-ranking models. LLMs,
such as GPT models and Llama2, have shown effectiveness in natural language
understanding tasks, and prior works (e.g., RankGPT) have also demonstrated
that the LLMs exhibit better performance than the traditional ranking models in
the ranking task. However, their fairness remains largely unexplored. This
paper presents an empirical study evaluating these LLMs using the TREC Fair
Ranking dataset, focusing on the representation of binary protected attributes
such as gender and geographic location, which are historically underrepresented
in search outcomes. Our analysis delves into how these LLMs handle queries and
documents related to these attributes, aiming to uncover biases in their
ranking algorithms. We assess fairness from both user and content perspectives,
contributing an empirical benchmark for evaluating LLMs as the fair ranker.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NAACL 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SonicSense: Object Perception from In-Hand Acoustic Vibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17932v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17932v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxun Liu, Boyuan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce SonicSense, a holistic design of hardware and software to enable
rich robot object perception through in-hand acoustic vibration sensing. While
previous studies have shown promising results with acoustic sensing for object
perception, current solutions are constrained to a handful of objects with
simple geometries and homogeneous materials, single-finger sensing, and mixing
training and testing on the same objects. SonicSense enables container
inventory status differentiation, heterogeneous material prediction, 3D shape
reconstruction, and object re-identification from a diverse set of 83
real-world objects. Our system employs a simple but effective heuristic
exploration policy to interact with the objects as well as end-to-end
learning-based algorithms to fuse vibration signals to infer object properties.
Our framework underscores the significance of in-hand acoustic vibration
sensing in advancing robot tactile perception.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our project website is at: http://generalroboticslab.com/SonicSense</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MSRS: Training Multimodal Speech Recognition Models from Scratch with
  Sparse Mask Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adriana Fernandez-Lopez, Honglie Chen, Pingchuan Ma, Lu Yin, Qiao Xiao, Stavros Petridis, Shiwei Liu, Maja Pantic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained models have been a foundational approach in speech recognition,
albeit with associated additional costs. In this study, we propose a
regularization technique that facilitates the training of visual and
audio-visual speech recognition models (VSR and AVSR) from scratch. This
approach, abbreviated as \textbf{MSRS} (Multimodal Speech Recognition from
Scratch), introduces a sparse regularization that rapidly learns sparse
structures within the dense model at the very beginning of training, which
receives healthier gradient flow than the dense equivalent. Once the sparse
mask stabilizes, our method allows transitioning to a dense model or keeping a
sparse model by updating non-zero values. MSRS achieves competitive results in
VSR and AVSR with 21.1% and 0.9% WER on the LRS3 benchmark, while reducing
training time by at least 2x. We explore other sparse approaches and show that
only MSRS enables training from scratch by implicitly masking the weights
affected by vanishing gradients.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Interspeech 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Soundify: Matching Sound Effects to Video 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2112.09726v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2112.09726v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Chuan-En Lin, Anastasis Germanidis, Cristóbal Valenzuela, Yining Shi, Nikolas Martelaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the art of video editing, sound helps add character to an object and
immerse the viewer within a space. Through formative interviews with
professional editors (N=10), we found that the task of adding sounds to video
can be challenging. This paper presents Soundify, a system that assists editors
in matching sounds to video. Given a video, Soundify identifies matching
sounds, synchronizes the sounds to the video, and dynamically adjusts panning
and volume to create spatial audio. In a human evaluation study (N=889), we
show that Soundify is capable of matching sounds to video out-of-the-box for a
diverse range of audio categories. In a within-subjects expert study (N=12), we
demonstrate the usefulness of Soundify in helping video editors match sounds to
video with lighter workload, reduced task completion time, and improved
usability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://soundify.cc</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VideoMap: Supporting Video Editing Exploration, Brainstorming, and
  Prototyping in the Latent Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.12492v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.12492v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Chuan-En Lin, Fabian Caba Heilbron, Joon-Young Lee, Oliver Wang, Nikolas Martelaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video editing is a creative and complex endeavor and we believe that there is
potential for reimagining a new video editing interface to better support the
creative and exploratory nature of video editing. We take inspiration from
latent space exploration tools that help users find patterns and connections
within complex datasets. We present VideoMap, a proof-of-concept video editing
interface that operates on video frames projected onto a latent space. We
support intuitive navigation through map-inspired navigational elements and
facilitate transitioning between different latent spaces through swappable
lenses. We built three VideoMap components to support editors in three common
video tasks. In a user study with both professionals and non-professionals,
editors found that VideoMap helps reduce grunt work, offers a user-friendly
experience, provides an inspirational way of editing, and effectively supports
the exploratory nature of video editing. We further demonstrate the versatility
of VideoMap by implementing three extended applications. For interactive
examples, we invite you to visit our project page:
https://humanvideointeraction.github.io/videomap.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://humanvideointeraction.github.io/videomap</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Videogenic: Identifying Highlight Moments in Videos with Professional
  Photographs as a Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.12493v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.12493v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Chuan-En Lin, Fabian Caba Heilbron, Joon-Young Lee, Oliver Wang, Nikolas Martelaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the challenge of extracting highlight moments from
videos. To perform this task, we need to understand what constitutes a
highlight for arbitrary video domains while at the same time being able to
scale across different domains. Our key insight is that photographs taken by
photographers tend to capture the most remarkable or photogenic moments of an
activity. Drawing on this insight, we present Videogenic, a technique capable
of creating domain-specific highlight videos for a diverse range of domains. In
a human evaluation study (N=50), we show that a high-quality photograph
collection combined with CLIP-based retrieval (which uses a neural network with
semantic knowledge of images) can serve as an excellent prior for finding video
highlights. In a within-subjects expert study (N=12), we demonstrate the
usefulness of Videogenic in helping video editors create highlight videos with
lighter workload, shorter task completion time, and better usability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://humanvideointeraction.github.io/videogenic</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-06-24T00:00:00Z">2024-06-24</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">20</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Debiased Recommendation with Noisy Feedback <span class="chip">KDD 24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17182v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17182v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxuan Li, Chunyuan Zheng, Wenjie Wang, Hao Wang, Fuli Feng, Xiao-Hua Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ratings of a user to most items in recommender systems are usually missing
not at random (MNAR), largely because users are free to choose which items to
rate. To achieve unbiased learning of the prediction model under MNAR data,
three typical solutions have been proposed, including error-imputation-based
(EIB), inverse-propensity-scoring (IPS), and doubly robust (DR) methods.
However, these methods ignore an alternative form of bias caused by the
inconsistency between the observed ratings and the users' true preferences,
also known as noisy feedback or outcome measurement errors (OME), e.g., due to
public opinion or low-quality data collection process. In this work, we study
intersectional threats to the unbiased learning of the prediction model from
data MNAR and OME in the collected data. First, we design OME-EIB, OME-IPS, and
OME-DR estimators, which largely extend the existing estimators to combat OME
in real-world recommendation scenarios. Next, we theoretically prove the
unbiasedness and generalization bound of the proposed estimators. We further
propose an alternate denoising training approach to achieve unbiased learning
of the prediction model under MNAR data with OME. Extensive experiments are
conducted on three real-world datasets and one semi-synthetic dataset to show
the effectiveness of our proposed approaches. The code is available at
https://github.com/haoxuanli-pku/KDD24-OME-DR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD 24 Research Track Paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DEXTER: A Benchmark for open-domain Complex Question Answering using
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17158v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17158v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Venktesh V. Deepali Prabhu, Avishek Anand
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open-domain complex Question Answering (QA) is a difficult task with
challenges in evidence retrieval and reasoning. The complexity of such
questions could stem from questions being compositional, hybrid evidence, or
ambiguity in questions. While retrieval performance for classical QA tasks is
well explored, their capabilities for heterogeneous complex retrieval tasks,
especially in an open-domain setting, and the impact on downstream QA
performance, are relatively unexplored. To address this, in this work, we
propose a benchmark composing diverse complex QA tasks and provide a toolkit to
evaluate state-of-the-art pre-trained dense and sparse retrieval models in an
open-domain setting. We observe that late interaction models and surprisingly
lexical models like BM25 perform well compared to other pre-trained dense
retrieval models. In addition, since context-based reasoning is critical for
solving complex QA tasks, we also evaluate the reasoning capabilities of LLMs
and the impact of retrieval performance on their reasoning capabilities.
Through experiments, we observe that much progress is to be made in retrieval
for complex QA to improve downstream QA performance. Our software and related
data can be accessed at https://github.com/VenkteshV/DEXTER
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under submission, 22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024
  Retrieval-Augmented Generation Track 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16828v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16828v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan Nguyen, Daniel Campos, Nick Craswell, Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Did you try out the new Bing Search? Or maybe you fiddled around with Google
AI~Overviews? These might sound familiar because the modern-day search stack
has recently evolved to include retrieval-augmented generation (RAG) systems.
They allow searching and incorporating real-time data into large language
models (LLMs) to provide a well-informed, attributed, concise summary in
contrast to the traditional search paradigm that relies on displaying a ranked
list of documents. Therefore, given these recent advancements, it is crucial to
have an arena to build, test, visualize, and systematically evaluate RAG-based
search systems. With this in mind, we propose the TREC 2024 RAG Track to foster
innovation in evaluating RAG systems. In our work, we lay out the steps we've
made towards making this track a reality -- we describe the details of our
reusable framework, Ragnar\"ok, explain the curation of the new MS MARCO V2.1
collection choice, release the development topics for the track, and
standardize the I/O definitions which assist the end user. Next, using
Ragnar\"ok, we identify and provide key industrial baselines such as OpenAI's
GPT-4o or Cohere's Command R+. Further, we introduce a web-based user interface
for an interactive arena allowing benchmarking pairwise RAG systems by
crowdsourcing. We open-source our Ragnar\"ok framework and baselines to achieve
a unified standard for future RAG systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-experiments: Improving experimentation through experimentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Melanie J. I. Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A/B testing is widexly used in the industry to optimize customer facing
websites. Many companies employ experimentation specialists to facilitate and
improve the process of A/B testing. Here, we present the application of A/B
testing to this improvement effort itself, by running experiments on the
experimentation process, which we call 'meta-experiments'. We discuss the
challenges of this approach using the example of one of our meta-experiments,
which helped experimenters to run more sufficiently powered A/B tests. We also
point out the benefits of 'dog fooding' for the experimentation specialists
when running their own experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Star+: A New Multi-Domain Model for CTR Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16568v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16568v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Çağrı Yeşil, Kaya Turgut
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce Star+, a novel multi-domain model for
click-through rate (CTR) prediction inspired by the Star model. Traditional
single-domain approaches and existing multi-task learning techniques face
challenges in multi-domain environments due to their inability to capture
domain-specific data distributions and complex inter-domain relationships.
Star+ addresses these limitations by enhancing the interaction between shared
and domain-specific information through various fusion strategies, such as add,
adaptive add, concatenation, and gating fusions, to find the optimal balance
between domain-specific and shared information. We also investigate the impact
of different normalization techniques, including layer normalization, batch
normalization, and partition normalization, on the performance of our model.
Our extensive experiments on both industrial and public datasets demonstrate
that Star+ significantly improves prediction accuracy and efficiency. This work
contributes to the advancement of recommendation systems by providing a robust,
scalable, and adaptive solution for multi-domain environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-domain Transfer of Valence Preferences via a Meta-optimization
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16494v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16494v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuang Zhao, Hongke Zhao, Ming He, Xiaomeng Li, Jianping Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-domain recommendation offers a potential avenue for alleviating data
sparsity and cold-start problems. Embedding and mapping, as a classic
cross-domain research genre, aims to identify a common mapping function to
perform representation transformation between two domains. Nevertheless,
previous coarse-grained preference representations, non-personalized mapping
functions, and excessive reliance on overlapping users limit their performance,
especially in scenarios where overlapping users are sparse. To address
aforementioned challenges, we propose a novel cross-domain approach, namely
CVPM. CVPM formalizes cross-domain interest transfer as a hybrid architecture
of parametric meta-learning and self-supervised learning, which not only
transfers user preferences at a finer level, but also enables signal
enhancement with the knowledge of non-overlapping users. Specifically, with
deep insights into user preferences and valence preference theory, we believe
that there exists significant difference between users' positive preferences
and negative behaviors, and thus employ differentiated encoders to learn their
distributions. In particular, we further utilize the pre-trained model and item
popularity to sample pseudo-interaction items to ensure the integrity of both
distributions. To guarantee the personalization of preference transfer, we
treat each user's mapping as two parts, the common transformation and the
personalized bias, where the network used to generate the personalized bias is
output by a meta-learner. Furthermore, in addition to the supervised loss for
overlapping users, we design contrastive tasks for non-overlapping users from
both group and individual-levels to avoid model skew and enhance the semantics
of representations. Exhaustive data analysis and extensive experimental results
demonstrate the effectiveness and advancement of our proposed framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context-augmented Retrieval: A Novel Framework for Fast Information
  Retrieval based Response Generation using Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16383v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16383v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sai Ganesh, Anupam Purwar, Gautam B
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating high-quality answers consistently by providing contextual
information embedded in the prompt passed to the Large Language Model (LLM) is
dependent on the quality of information retrieval. As the corpus of contextual
information grows, the answer/inference quality of Retrieval Augmented
Generation (RAG) based Question Answering (QA) systems declines. This work
solves this problem by combining classical text classification with the Large
Language Model (LLM) to enable quick information retrieval from the vector
store and ensure the relevancy of retrieved information. For the same, this
work proposes a new approach Context Augmented retrieval (CAR), where
partitioning of vector database by real-time classification of information
flowing into the corpus is done. CAR demonstrates good quality answer
generation along with significant reduction in information retrieval and answer
generation time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Role of Long-tail Knowledge in Retrieval Augmented Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongyang Li, Junbing Yan, Taolin Zhang, Chengyu Wang, Xiaofeng He, Longtao Huang, Hui Xue, Jun Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval augmented generation (RAG) exhibits outstanding performance in
promoting the knowledge capabilities of large language models (LLMs) with
retrieved documents related to user queries. However, RAG only focuses on
improving the response quality of LLMs via enhancing queries indiscriminately
with retrieved information, paying little attention to what type of knowledge
LLMs really need to answer original queries more accurately. In this paper, we
suggest that long-tail knowledge is crucial for RAG as LLMs have already
remembered common world knowledge during large-scale pre-training. Based on our
observation, we propose a simple but effective long-tail knowledge detection
method for LLMs. Specifically, the novel Generative Expected Calibration Error
(GECE) metric is derived to measure the ``long-tailness'' of knowledge based on
both statistics and semantics. Hence, we retrieve relevant documents and infuse
them into the model for patching knowledge loopholes only when the input query
relates to long-tail knowledge. Experiments show that, compared to existing RAG
pipelines, our method achieves over 4x speedup in average inference time and
consistent performance improvement in downstream tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Intent-aware Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16350v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16350v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dietmar Jannach, Markus Zanker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many modern online services feature personalized recommendations. A central
challenge when providing such recommendations is that the reason why an
individual user accesses the service may change from visit to visit or even
during an ongoing usage session. To be effective, a recommender system should
therefore aim to take the users' probable intent of using the service at a
certain point in time into account. In recent years, researchers have thus
started to address this challenge by incorporating intent-awareness into
recommender systems. Correspondingly, a number of technical approaches were put
forward, including diversification techniques, intent prediction models or
latent intent modeling approaches. In this paper, we survey and categorize
existing approaches to building the next generation of Intent-Aware Recommender
Systems (IARS). Based on an analysis of current evaluation practices, we
outline open gaps and possible future directions in this area, which in
particular include the consideration of additional interaction signals and
contextual information to further improve the effectiveness of such systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DemoRank: Selecting Effective Demonstrations for Large Language Models
  in Ranking Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16332v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16332v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhan Liu, Yutao Zhu, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, there has been increasing interest in applying large language
models (LLMs) as zero-shot passage rankers. However, few studies have explored
how to select appropriate in-context demonstrations for the passage ranking
task, which is the focus of this paper. Previous studies mainly apply a
demonstration retriever to retrieve demonstrations and use top-$k$
demonstrations for in-context learning (ICL). Although effective, this approach
overlooks the dependencies between demonstrations, leading to inferior
performance of few-shot ICL in the passage ranking task. In this paper, we
formulate the demonstration selection as a \textit{retrieve-then-rerank}
process and introduce the DemoRank framework. In this framework, we first use
LLM feedback to train a demonstration retriever and construct a novel
dependency-aware training samples to train a demonstration reranker to improve
few-shot ICL. The construction of such training samples not only considers
demonstration dependencies but also performs in an efficient way. Extensive
experiments demonstrate DemoRank's effectiveness in in-domain scenarios and
strong generalization to out-of-domain scenarios. Our codes are available
at~\url{https://github.com/8421BCD/DemoRank}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10289v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10289v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng Niu, Yang Guan, Yuanhao Wu, Juno Zhu, Juntong Song, Randy Zhong, Kaihua Zhu, Siliang Xu, Shizhe Diao, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proliferation of fake news poses a significant threat not only by
disseminating misleading information but also by undermining the very
foundations of democracy. The recent advance of generative artificial
intelligence has further exacerbated the challenge of distinguishing genuine
news from fabricated stories. In response to this challenge, we introduce
VeraCT Scan, a novel retrieval-augmented system for fake news detection. This
system operates by extracting the core facts from a given piece of news and
subsequently conducting an internet-wide search to identify corroborating or
conflicting reports. Then sources' credibility is leveraged for information
verification. Besides determining the veracity of news, we also provide
transparent evidence and reasoning to support its conclusions, resulting in the
interpretability and trust in the results. In addition to GPT-4 Turbo, Llama-2
13B is also fine-tuned for news content understanding, information
verification, and reasoning. Both implementations have demonstrated
state-of-the-art accuracy in the realm of fake news detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MagicLens: <span class="highlight-title">Self-Supervised</span> Image Retrieval with Open-Ended Instructions <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19651v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19651v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Zhang, Yi Luan, Hexiang Hu, Kenton Lee, Siyuan Qiao, Wenhu Chen, Yu Su, Ming-Wei Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image retrieval, i.e., finding desired images given a reference image,
inherently encompasses rich, multi-faceted search intents that are difficult to
capture solely using image-based measures. Recent works leverage text
instructions to allow users to more freely express their search intents.
However, they primarily focus on image pairs that are visually similar and/or
can be characterized by a small set of pre-defined relations. The core thesis
of this paper is that text instructions can enable retrieving images with
richer relations beyond visual similarity. To show this, we introduce
MagicLens, a series of self-supervised image retrieval models that support
open-ended instructions. MagicLens is built on a key novel insight: image pairs
that naturally occur on the same web pages contain a wide range of implicit
relations (e.g., inside view of), and we can bring those implicit relations
explicit by synthesizing instructions via foundation models. Trained on 36.7M
(query image, instruction, target image) triplets with rich semantic relations
mined from the web, MagicLens achieves results comparable with or better than
prior best on eight benchmarks of various image retrieval tasks, while
maintaining high parameter efficiency with a significantly smaller model size.
Additional human analyses on a 1.4M-image unseen corpus further demonstrate the
diversity of search intents supported by MagicLens. Code and models are
publicly available at https://open-vision-language.github.io/MagicLens/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024 (Oral); Project Website:
  https://open-vision-language.github.io/MagicLens/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Make Large Language Model a Better Ranker 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19181v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19181v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenshuo Chao, Zhi Zheng, Hengshu Zhu, Hao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) demonstrate robust capabilities across various
fields, leading to a paradigm shift in LLM-enhanced Recommender System (RS).
Research to date focuses on point-wise and pair-wise recommendation paradigms,
which are inefficient for LLM-based recommenders due to high computational
costs. However, existing list-wise approaches also fall short in ranking tasks
due to misalignment between ranking objectives and next-token prediction.
Moreover, these LLM-based methods struggle to effectively address the order
relation among candidates, particularly given the scale of ratings. To address
these challenges, this paper introduces the large language model framework with
Aligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap
between the capabilities of LLMs and the nuanced requirements of ranking tasks.
Specifically, ALRO employs explicit feedback in a listwise manner by
introducing soft lambda loss, a customized adaptation of lambda loss designed
for optimizing order relations. This mechanism provides more accurate
optimization goals, enhancing the ranking process. Additionally, ALRO
incorporates a permutation-sensitive learning mechanism that addresses position
bias, a prevalent issue in generative models, without imposing additional
computational burdens during inference. Our evaluative studies reveal that ALRO
outperforms both existing embedding-based recommendation methods and LLM-based
recommendation baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> on Neural Topic Models: Methods, Applications, and Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.15351v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.15351v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaobao Wu, Thong Nguyen, Anh Tuan Luu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic models have been prevalent for decades to discover latent topics and
infer topic proportions of documents in an unsupervised fashion. They have been
widely used in various applications like text analysis and context
recommendation. Recently, the rise of neural networks has facilitated the
emergence of a new research field -- Neural Topic Models (NTMs). Different from
conventional topic models, NTMs directly optimize parameters without requiring
model-specific derivations. This endows NTMs with better scalability and
flexibility, resulting in significant research attention and plentiful new
methods and applications. In this paper, we present a comprehensive survey on
neural topic models concerning methods, applications, and challenges.
Specifically, we systematically organize current NTM methods according to their
network structures and introduce the NTMs for various scenarios like short
texts and bilingual documents. We also discuss a wide range of popular
applications built on NTMs. Finally, we highlight the challenges confronted by
NTMs to inspire future research. We accompany this survey with a repository for
easier access to the mentioned paper resources:
https://github.com/bobxwu/Paper-Neural-Topic-Models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Artificial Intelligence Review. See
  https://doi.org/10.1007/s10462-023-10661-7 and a paper list at
  https://github.com/BobXWu/Paper-Neural-Topic-Models</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generation of Asset Administration Shell with Large Language Model
  Agents: Toward Semantic Interoperability in Digital Twins in the Context of
  Industry 4.0 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17209v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17209v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchen Xia, Zhewen Xiao, Nasser Jazdi, Michael Weyrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This research introduces a novel approach for achieving semantic
interoperability in digital twins and assisting the creation of Asset
Administration Shell (AAS) as digital twin model within the context of Industry
4.0. The foundational idea of our research is that the communication based on
semantics and the generation of meaningful textual data are directly linked,
and we posit that these processes are equivalent if the exchanged information
can be serialized in text form. Based on this, we construct a "semantic node"
data structure in our research to capture the semantic essence of textual data.
Then, a system powered by large language models is designed and implemented to
process the "semantic node" and generate standardized digital twin models from
raw textual data collected from datasheets describing technical assets. Our
evaluation demonstrates an effective generation rate of 62-79%, indicating a
substantial proportion of the information from the source text can be
translated error-free to the target digital twin instance model with the
generative capability of large language models. This result has a direct
application in the context of Industry 4.0, and the designed system is
implemented as a data model generation tool for reducing the manual effort in
creating AAS model. In our evaluation, a comparative analysis of different LLMs
and an in-depth ablation study of Retrieval-Augmented Generation (RAG)
mechanisms provide insights into the effectiveness of LLM systems for
interpreting technical concepts and translating data. Our findings emphasize
LLMs' capability to automate AAS instance creation and contribute to the
broader field of semantic interoperability for digital twins in industrial
applications. The prototype implementation and evaluation results are presented
on our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in IEEE Access</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fundus: A Simple-to-Use News Scraper Optimized for High Quality
  Extractions <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.15279v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.15279v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Max Dallabetta, Conrad Dobberstein, Adrian Breiding, Alan Akbik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Fundus, a user-friendly news scraper that enables users
to obtain millions of high-quality news articles with just a few lines of code.
Unlike existing news scrapers, we use manually crafted, bespoke content
extractors that are specifically tailored to the formatting guidelines of each
supported online newspaper. This allows us to optimize our scraping for quality
such that retrieved news articles are textually complete and without HTML
artifacts. Further, our framework combines both crawling (retrieving HTML from
the web or large web archives) and content extraction into a single pipeline.
By providing a unified interface for a predefined collection of newspapers, we
aim to make Fundus broadly usable even for non-technical users. This paper
gives an overview of the framework, discusses our design choices, and presents
a comparative evaluation against other popular news scrapers. Our evaluation
shows that Fundus yields significantly higher quality extractions (complete and
artifact-free news articles) than prior work. The framework is available on
GitHub under https://github.com/flairNLP/fundus and can be simply installed
using pip.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures, ACL 2024, for a screencast see
  https://www.youtube.com/watch?v=9GJExMelhdI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continuous-time Autoencoders for Regular and Irregular Time Series
  Imputation <span class="chip">WSDM'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16581v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16581v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyowon Wi, Yehjin Shin, Noseong Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series imputation is one of the most fundamental tasks for time series.
Real-world time series datasets are frequently incomplete (or irregular with
missing observations), in which case imputation is strongly required. Many
different time series imputation methods have been proposed. Recent
self-attention-based methods show the state-of-the-art imputation performance.
However, it has been overlooked for a long time to design an imputation method
based on continuous-time recurrent neural networks (RNNs), i.e., neural
controlled differential equations (NCDEs). To this end, we redesign time series
(variational) autoencoders based on NCDEs. Our method, called continuous-time
autoencoder (CTA), encodes an input time series sample into a continuous hidden
path (rather than a hidden vector) and decodes it to reconstruct and impute the
input. In our experiments with 4 datasets and 19 baselines, our method shows
the best imputation performance in almost all cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a WSDM'24 full paper (oral presentation)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential
  Behavior Comprehension in Recommendation <span class="chip">WWW 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.11131v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.11131v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With large language models (LLMs) achieving remarkable breakthroughs in
natural language processing (NLP) domains, LLM-enhanced recommender systems
have received much attention and have been actively explored currently. In this
paper, we focus on adapting and empowering a pure large language model for
zero-shot and few-shot recommendation tasks. First and foremost, we identify
and formulate the lifelong sequential behavior incomprehension problem for LLMs
in recommendation domains, i.e., LLMs fail to extract useful information from a
textual context of long user behavior sequence, even if the length of context
is far from reaching the context limitation of LLMs. To address such an issue
and improve the recommendation performance of LLMs, we propose a novel
framework, namely Retrieval-enhanced Large Language models (ReLLa) for
recommendation tasks in both zero-shot and few-shot settings. For zero-shot
recommendation, we perform semantic user behavior retrieval (SUBR) to improve
the data quality of testing samples, which greatly reduces the difficulty for
LLMs to extract the essential knowledge from user behavior sequences. As for
few-shot recommendation, we further design retrieval-enhanced instruction
tuning (ReiT) by adopting SUBR as a data augmentation technique for training
samples. Specifically, we develop a mixed training dataset consisting of both
the original data samples and their retrieval-enhanced counterparts. We conduct
extensive experiments on three real-world public datasets to demonstrate the
superiority of ReLLa compared with existing baseline models, as well as its
capability for lifelong sequential behavior comprehension. To be highlighted,
with only less than 10% training samples, few-shot ReLLa can outperform
traditional CTR models that are trained on the entire training set (e.g.,
DCNv2, DIN, SIM). The code is available
\url{https://github.com/LaVieEnRose365/ReLLa}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2024. Full and More Readable Version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language
  Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.07269v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.07269v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Wang, Ningyu Zhang, Bozhong Tian, Zekun Xi, Yunzhi Yao, Ziwen Xu, Mengru Wang, Shengyu Mao, Xiaohan Wang, Siyuan Cheng, Kangwei Liu, Yuansheng Ni, Guozhou Zheng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy
issues, which means they are unaware of unseen events or generate text with
incorrect facts owing to outdated/noisy data. To this end, many knowledge
editing approaches for LLMs have emerged -- aiming to subtly inject/edit
updated knowledge or adjust undesired behavior while minimizing the impact on
unrelated inputs. Nevertheless, due to significant differences among various
knowledge editing methods and the variations in task setups, there is no
standard implementation framework available for the community, which hinders
practitioners from applying knowledge editing to applications. To address these
issues, we propose EasyEdit, an easy-to-use knowledge editing framework for
LLMs. It supports various cutting-edge knowledge editing approaches and can be
readily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc.
Empirically, we report the knowledge editing results on LlaMA-2 with EasyEdit,
demonstrating that knowledge editing surpasses traditional fine-tuning in terms
of reliability and generalization. We have released the source code on GitHub,
along with Google Colab tutorials and comprehensive documentation for beginners
to get started. Besides, we present an online system for real-time knowledge
editing, and a demo video.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 System Demonstrations; Code:
  https://github.com/zjunlp/EasyEdit HF Demo:
  https://huggingface.co/spaces/zjunlp/EasyEdit Video:
  https://youtu.be/Gm6T0QaaskU Docs: https://zjunlp.gitbook.io/easyedit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EasyInstruct: An Easy-to-use Instruction Processing Framework for Large
  Language Models <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03049v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03049v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Ou, Ningyu Zhang, Honghao Gui, Ziwen Xu, Shuofei Qiao, Yida Xue, Runnan Fang, Kangwei Liu, Lei Li, Zhen Bi, Guozhou Zheng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, instruction tuning has gained increasing attention and
emerged as a crucial technique to enhance the capabilities of Large Language
Models (LLMs). To construct high-quality instruction datasets, many instruction
processing approaches have been proposed, aiming to achieve a delicate balance
between data quantity and data quality. Nevertheless, due to inconsistencies
that persist among various instruction processing methods, there is no standard
open-source instruction processing implementation framework available for the
community, which hinders practitioners from further developing and advancing.
To facilitate instruction processing research and development, we present
EasyInstruct, an easy-to-use instruction processing framework for LLMs, which
modularizes instruction generation, selection, and prompting, while also
considering their combination and interaction. EasyInstruct is publicly
released and actively maintained at https://github.com/zjunlp/EasyInstruct,
along with an online demo app and a demo video for quick-start, calling for
broader research centered on instruction data and synthetic data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL 2024 System Demonstrations; Project website:
  https://zjunlp.github.io/project/EasyInstruct Code:
  https://github.com/zjunlp/EasyInstruct Video: https://youtu.be/rfQOWYfziFo
  Demo: https://huggingface.co/spaces/zjunlp/EasyInstruct</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring compressibility of <span class="highlight-title">transformer</span> based text-to-music (TTM)
  models <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vasileios Moschopoulos, Thanasis Kotsiopoulos, Pablo Peso Parada, Konstantinos Nikiforidis, Alexandros Stergiadis, Gerasimos Papakostas, Md Asif Jalal, Jisi Zhang, Anastasios Drosou, Karthikeyan Saravanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the art Text-To-Music (TTM) generative AI models are large and
require desktop or server class compute, making them infeasible for deployment
on mobile phones. This paper presents an analysis of trade-offs between model
compression and generation performance of TTM models. We study compression
through knowledge distillation and specific modifications that enable
applicability over the various components of the TTM model (encoder, generative
model and the decoder). Leveraging these methods we create TinyTTM (89.2M
params) that achieves a FAD of 3.66 and KL of 1.32 on MusicBench dataset,
better than MusicGen-Small (557.6M params) but not lower than MusicGen-small
fine-tuned on MusicBench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos <span class="chip">ICMR'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16301v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16301v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuting Mei, Linli Yao, Qin Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the surge in the amount of video data, video summarization techniques,
including visual-modal(VM) and textual-modal(TM) summarization, are attracting
more and more attention. However, unimodal summarization inevitably loses the
rich semantics of the video. In this paper, we focus on a more comprehensive
video summarization task named Bimodal Semantic Summarization of Videos
(BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in
(video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing
methods, our construction procedure contains a VM-Summary extraction algorithm
aiming to preserve the most salient content within long videos. Based on BIDS,
we propose a Unified framework UBiSS for the BiSSV task, which models the
saliency information in the video and generates a TM-summary and VM-summary
simultaneously. We further optimize our model with a list-wise ranking-based
objective to improve its capacity to capture highlights. Lastly, we propose a
metric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary.
Experiments show that our unified framework achieves better performance than
multi-stage summarization pipelines. Code and data are available at
https://github.com/MeiYutingg/UBiSS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM International Conference on Multimedia Retrieval
  (ICMR'24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MagicLens: <span class="highlight-title">Self-Supervised</span> Image Retrieval with Open-Ended Instructions <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19651v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19651v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Zhang, Yi Luan, Hexiang Hu, Kenton Lee, Siyuan Qiao, Wenhu Chen, Yu Su, Ming-Wei Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image retrieval, i.e., finding desired images given a reference image,
inherently encompasses rich, multi-faceted search intents that are difficult to
capture solely using image-based measures. Recent works leverage text
instructions to allow users to more freely express their search intents.
However, they primarily focus on image pairs that are visually similar and/or
can be characterized by a small set of pre-defined relations. The core thesis
of this paper is that text instructions can enable retrieving images with
richer relations beyond visual similarity. To show this, we introduce
MagicLens, a series of self-supervised image retrieval models that support
open-ended instructions. MagicLens is built on a key novel insight: image pairs
that naturally occur on the same web pages contain a wide range of implicit
relations (e.g., inside view of), and we can bring those implicit relations
explicit by synthesizing instructions via foundation models. Trained on 36.7M
(query image, instruction, target image) triplets with rich semantic relations
mined from the web, MagicLens achieves results comparable with or better than
prior best on eight benchmarks of various image retrieval tasks, while
maintaining high parameter efficiency with a significantly smaller model size.
Additional human analyses on a 1.4M-image unseen corpus further demonstrate the
diversity of search intents supported by MagicLens. Code and models are
publicly available at https://open-vision-language.github.io/MagicLens/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024 (Oral); Project Website:
  https://open-vision-language.github.io/MagicLens/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation
  with Consistency Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10740v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10740v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yatong Bai, Trung Dang, Dung Tran, Kazuhito Koishida, Somayeh Sojoudi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models are instrumental in text-to-audio (TTA) generation.
Unfortunately, they suffer from slow inference due to an excessive number of
queries to the underlying denoising network per generation. To address this
bottleneck, we introduce ConsistencyTTA, a framework requiring only a single
non-autoregressive network query, thereby accelerating TTA by hundreds of
times. We achieve so by proposing "CFG-aware latent consistency model," which
adapts consistency generation into a latent space and incorporates
classifier-free guidance (CFG) into model training. Moreover, unlike diffusion
models, ConsistencyTTA can be finetuned closed-loop with audio-space text-aware
metrics, such as CLAP score, to further enhance the generations. Our objective
and subjective evaluation on the AudioCaps dataset shows that compared to
diffusion-based counterparts, ConsistencyTTA reduces inference computation by
400x while retaining generation quality and diversity.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-06-23T00:00:00Z">2024-06-23</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Mechanism for Optimizing Media Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16212v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16212v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian McFadden
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A mechanism is described that addresses the fundamental trade off between
media producers who want to increase reach and consumers who provide attention
based on the rate of utility received, and where overreach negatively impacts
that rate. An optimal solution can be achieved when the media source considers
the impact of overreach in a cost function used in determining the optimal
distribution of content to maximize individual consumer utility and
participation. The result is a Nash equilibrium between producer and consumer
that is also Pareto efficient. Comparison with the literature on Recommender
systems highlights the advantages of the mechanism.The review suggests
advancements over that literature including identifying an optimal content
volume for the consumer and improvements for handling multiple objectives A
practical algorithm to generate the optimal distribution for each consumer is
provided.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main Paper: 20 pages, Appendix with proofs and additional material:
  26 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SimCE: Simplifying Cross-Entropy Loss for Collaborative Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodong Yang, Huiyuan Chen, Yuchen Yan, Yuxin Tang, Yuying Zhao, Eric Xu, Yiwei Cai, Hanghang Tong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The learning objective is integral to collaborative filtering systems, where
the Bayesian Personalized Ranking (BPR) loss is widely used for learning
informative backbones. However, BPR often experiences slow convergence and
suboptimal local optima, partially because it only considers one negative item
for each positive item, neglecting the potential impacts of other unobserved
items. To address this issue, the recently proposed Sampled Softmax
Cross-Entropy (SSM) compares one positive sample with multiple negative
samples, leading to better performance. Our comprehensive experiments confirm
that recommender systems consistently benefit from multiple negative samples
during training. Furthermore, we introduce a \underline{Sim}plified Sampled
Softmax \underline{C}ross-\underline{E}ntropy Loss (SimCE), which simplifies
the SSM using its upper bound. Our validation on 12 benchmark datasets, using
both MF and LightGCN backbones, shows that SimCE significantly outperforms both
BPR and SSM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Ensemble Methods for News Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16106v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16106v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Gray, Noorhan Abbas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  News recommendation is crucial for facilitating individuals' access to
articles, particularly amid the increasingly digital landscape of news
consumption. Consequently, extensive research is dedicated to News Recommender
Systems (NRS) with increasingly sophisticated algorithms. Despite this
sustained scholarly inquiry, there exists a notable research gap regarding the
potential synergy achievable by amalgamating these algorithms to yield superior
outcomes. This paper endeavours to address this gap by demonstrating how
ensemble methods can be used to combine many diverse state-of-the-art
algorithms to achieve superior results on the Microsoft News dataset (MIND).
Additionally, we identify scenarios where ensemble methods fail to improve
results and offer explanations for this occurrence. Our findings demonstrate
that a combination of NRS algorithms can outperform individual algorithms,
provided that the base learners are sufficiently diverse, with improvements of
up to 5\% observed for an ensemble consisting of a content-based BERT approach
and the collaborative filtering LSTUR algorithm. Additionally, our results
demonstrate the absence of any improvement when combining insufficiently
distinct methods. These findings provide insight into successful approaches of
ensemble methods in NRS and advocates for the development of better systems
through appropriate ensemble solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating D-MERIT of Partial-annotation on Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16048v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16048v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Royi Rassin, Yaron Fairstein, Oren Kalinsky, Guy Kushilevitz, Nachshon Cohen, Alexander Libov, Yoav Goldberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval models are often evaluated on partially-annotated datasets. Each
query is mapped to a few relevant texts and the remaining corpus is assumed to
be irrelevant. As a result, models that successfully retrieve false negatives
are punished in evaluation. Unfortunately, completely annotating all texts for
every query is not resource efficient. In this work, we show that using
partially-annotated datasets in evaluation can paint a distorted picture. We
curate D-MERIT, a passage retrieval evaluation set from Wikipedia, aspiring to
contain all relevant passages for each query. Queries describe a group (e.g.,
``journals about linguistics'') and relevant passages are evidence that
entities belong to the group (e.g., a passage indicating that Language is a
journal about linguistics). We show that evaluating on a dataset containing
annotations for only a subset of the relevant passages might result in
misleading ranking of the retrieval systems and that as more relevant texts are
included in the evaluation set, the rankings converge. We propose our dataset
as a resource for evaluation and our study as a recommendation for balance
between resource-efficiency and reliable evaluation when annotating evaluation
sets for text retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our dataset can be downloaded from https://D-MERIT.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Database-Augmented Query Representation for Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong C. Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval models that aim to search for the documents relevant to
the given query have shown many successes, which have been applied to diverse
tasks. However, the query provided by the user is oftentimes very short, which
challenges the retrievers to correctly fetch relevant documents. To tackle
this, existing studies have proposed expanding the query with a couple of
additional (user-related) features related to the query. Yet, they may be
suboptimal to effectively augment the query, though there is plenty of
information available to augment it in a relational database. Motivated by
this, we present a novel retrieval framework called Database-Augmented Query
representation (DAQu), which augments the original query with various
(query-related) metadata across multiple tables. In addition, as the number of
features in the metadata can be very large and there is no order among them, we
encode them with our graph-based set encoding strategy, which considers
hierarchies of features in the database without order. We validate DAQu in
diverse retrieval scenarios that can incorporate metadata from the relational
database, demonstrating that ours significantly enhances overall retrieval
performance, compared to existing query augmentation methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning k-Determinantal Point Processes for Personalized Ranking <span class="chip">ICDE 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15983v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15983v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuli Liu, Christian Walder, Lexing Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The key to personalized recommendation is to predict a personalized ranking
on a catalog of items by modeling the user's preferences. There are many
personalized ranking approaches for item recommendation from implicit feedback
like Bayesian Personalized Ranking (BPR) and listwise ranking. Despite these
methods have shown performance benefits, there are still limitations affecting
recommendation performance. First, none of them directly optimize ranking of
sets, causing inadequate exploitation of correlations among multiple items.
Second, the diversity aspect of recommendations is insufficiently addressed
compared to relevance.
  In this work, we present a new optimization criterion LkP based on set
probability comparison for personalized ranking that moves beyond traditional
ranking-based methods. It formalizes set-level relevance and diversity ranking
comparisons through a Determinantal Point Process (DPP) kernel decomposition.
To confer ranking interpretability to the DPP set probabilities and prioritize
the practicality of LkP, we condition the standard DPP on the cardinality k of
the DPP-distributed set, known as k-DPP, a less-explored extension of DPP. The
generic stochastic gradient descent based technique can be directly applied to
optimizing models that employ LkP. We implement LkP in the context of both
Matrix Factorization (MF) and neural networks approaches, on three real-world
datasets, obtaining improved relevance and diversity performances. LkP is
broadly applicable, and when applied to existing recommendation models it also
yields strong performance improvements, suggesting that LkP holds significant
value to the field of recommender systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, accepted at ICDE 2024 (40th IEEE International Conference
  on Data Engineering)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Margin Loss: Proposal and Application in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04614v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04614v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Makbule Gulcin Ozsoy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems guide users through vast amounts of information by
suggesting items based on their predicted preferences. Collaborative
filtering-based deep learning techniques have regained popularity due to their
simplicity, using only user-item interactions. Typically, these systems consist
of three main components: an interaction module, a loss function, and a
negative sampling strategy. Initially, researchers focused on enhancing
performance by developing complex interaction modules with techniques like
multi-layer perceptrons, transformers, or graph neural networks. However, there
has been a recent shift toward refining loss functions and negative sampling
strategies. This shift has increased interest in contrastive learning, which
pulls similar pairs closer while pushing dissimilar ones apart. Contrastive
learning involves key practices such as heavy data augmentation, large batch
sizes, and hard-negative sampling, but these also bring challenges like high
memory demands and under-utilization of some negative samples. The proposed
Multi-Margin Loss (MML) addresses these challenges by introducing multiple
margins and varying weights for negative samples. MML efficiently utilizes not
only the hardest negatives but also other non-trivial negatives, offering a
simpler yet effective loss function that outperforms more complex methods,
especially when resources are limited. Experiments on two well-known datasets
showed MML achieved up to a 20\% performance improvement compared to a baseline
contrastive loss function with fewer negative samples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLMs in the Loop: Leveraging Large Language Model Annotations for Active
  Learning in Low-Resource Languages <span class="chip">ECML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.02261v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.02261v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nataliia Kholodna, Sahib Julka, Mohammad Khodadadi, Muhammed Nurullah Gumus, Michael Granitzer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-resource languages face significant barriers in AI development due to
limited linguistic resources and expertise for data labeling, rendering them
rare and costly. The scarcity of data and the absence of preexisting tools
exacerbate these challenges, especially since these languages may not be
adequately represented in various NLP datasets. To address this gap, we propose
leveraging the potential of LLMs in the active learning loop for data
annotation. Initially, we conduct evaluations to assess inter-annotator
agreement and consistency, facilitating the selection of a suitable LLM
annotator. The chosen annotator is then integrated into a training loop for a
classifier using an active learning paradigm, minimizing the amount of queried
data required. Empirical evaluations, notably employing GPT-4-Turbo,
demonstrate near-state-of-the-art performance with significantly reduced data
requirements, as indicated by estimated potential cost savings of at least
42.45 times compared to human annotation. Our proposed solution shows promising
potential to substantially reduce both the monetary and computational costs
associated with automation in low-resource settings. By bridging the gap
between low-resource languages and AI, this approach fosters broader inclusion
and shows the potential to enable automation across diverse linguistic
landscapes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 tables. The source code related to this paper is
  available at https://github.com/mkandai/llms-in-the-loop. This paper has been
  accepted for publication at ECML PKDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spiral of Silence: How is Large Language Model Killing Information
  Retrieval? -- A Case Study on Open Domain Question Answering <span class="chip">ACL2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10496v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10496v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyang Chen, Ben He, Hongyu Lin, Xianpei Han, Tianshu Wang, Boxi Cao, Le Sun, Yingfei Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The practice of Retrieval-Augmented Generation (RAG), which integrates Large
Language Models (LLMs) with retrieval systems, has become increasingly
prevalent. However, the repercussions of LLM-derived content infiltrating the
web and influencing the retrieval-generation feedback loop are largely
uncharted territories. In this study, we construct and iteratively run a
simulation pipeline to deeply investigate the short-term and long-term effects
of LLM text on RAG systems. Taking the trending Open Domain Question Answering
(ODQA) task as a point of entry, our findings reveal a potential digital
"Spiral of Silence" effect, with LLM-generated text consistently outperforming
human-authored content in search rankings, thereby diminishing the presence and
impact of human contributions online. This trend risks creating an imbalanced
information ecosystem, where the unchecked proliferation of erroneous
LLM-generated content may result in the marginalization of accurate
information. We urge the academic community to take heed of this potential
issue, ensuring a diverse and authentic digital information landscape.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACL2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Async Learned User Embeddings for Ads Delivery Optimization <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05898v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05898v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingwei Tang, Meng Liu, Hong Li, Junjie Yang, Chenglin Wei, Boyang Li, Dai Li, Rengan Xu, Yifan Xu, Zehua Zhang, Xiangyu Wang, Linfeng Liu, Yuelei Xie, Chengye Liu, Labib Fawaz, Li Li, Hongnan Wang, Bill Zhu, Sri Reddy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recommendation systems, high-quality user embeddings can capture subtle
preferences, enable precise similarity calculations, and adapt to changing
preferences over time to maintain relevance. The effectiveness of
recommendation systems depends on the quality of user embedding. We propose to
asynchronously learn high fidelity user embeddings for billions of users each
day from sequence based multimodal user activities through a Transformer-like
large scale feature learning module. The async learned user representations
embeddings (ALURE) are further converted to user similarity graphs through
graph learning and then combined with user realtime activities to retrieval
highly related ads candidates for the ads delivery system. Our method shows
significant gains in both offline and online experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by workshop on Multimodal Representation and Retrieval at
  SIGIR 2024, Washington DC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Collaborative Filtering: A Relook at Task Formulation in
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13375v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13375v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aixin Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender Systems (RecSys) have become indispensable in numerous
applications, profoundly influencing our everyday experiences. Despite their
practical significance, academic research in RecSys often abstracts the
formulation of research tasks from real-world contexts, aiming for a clean
problem formulation and more generalizable findings. However, it is observed
that there is a lack of collective understanding in RecSys academic research.
The root of this issue may lie in the simplification of research task
definitions, and an overemphasis on modeling the decision outcomes rather than
the decision-making process. That is, we often conceptualize RecSys as the task
of predicting missing values in a static user-item interaction matrix, rather
than predicting a user's decision on the next interaction within a dynamic,
changing, and application-specific context. There exists a mismatch between the
inputs accessible to a model and the information available to users during
their decision-making process, yet the model is tasked to predict users'
decisions. While collaborative filtering is effective in learning general
preferences from historical records, it is crucial to also consider the dynamic
contextual factors in practical settings. Defining research tasks based on
application scenarios using domain-specific datasets may lead to more
insightful findings. Accordingly, viable solutions and effective evaluations
can emerge for different application scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in ACM SIGWEB Newsletter, Spring 2024:
  https://dl.acm.org/doi/10.1145/3663752.3663756</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Group-aware Search Success 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17313v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17313v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haolun Wu, Bhaskar Mitra, Nick Craswell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional measures of search success often overlook the varying information
needs of different demographic groups. To address this gap, we introduce a
novel metric, named Group-aware Search Success (GA-SS). GA-SS redefines search
success to ensure that all demographic groups achieve satisfaction from search
outcomes. We introduce a comprehensive mathematical framework to calculate
GA-SS, incorporating both static and stochastic ranking policies and
integrating user browsing models for a more accurate assessment. In addition,
we have proposed Group-aware Most Popular Completion (gMPC) ranking model to
account for demographic variances in user intent, aligning more closely with
the diverse needs of all user groups. We empirically validate our metric and
approach with two real-world datasets: one focusing on query auto-completion
and the other on movie recommendations, where the results highlight the impact
of stochasticity and the complex interplay among various search success
metrics. Our findings advocate for a more inclusive approach in measuring
search success, as well as inspiring future investigations into the quality of
service of search.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Real-Time Neural Volumetric Rendering on Mobile Devices: A
  Measurement Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16068v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16068v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhe Wang, Yifei Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Radiance Fields (NeRF) is an emerging technique to synthesize 3D
objects from 2D images with a wide range of potential applications. However,
rendering existing NeRF models is extremely computation intensive, making it
challenging to support real-time interaction on mobile devices. In this paper,
we take the first initiative to examine the state-of-the-art real-time NeRF
rendering technique from a system perspective. We first define the entire
working pipeline of the NeRF serving system. We then identify possible control
knobs that are critical to the system from the communication, computation, and
visual performance perspective. Furthermore, an extensive measurement study is
conducted to reveal the effects of these control knobs on system performance.
Our measurement results reveal that different control knobs contribute
differently towards improving the system performance, with the mesh granularity
being the most effective knob and the quantization being the least effective
knob. In addition, diverse hardware device settings and network conditions have
to be considered to fully unleash the benefit of operating under the
appropriate knobs
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted by ACM SIGCOMM Workshop on Emerging Multimedia
  Systems 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diffusion Models, Image Super-Resolution And Everything: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00736v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00736v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian B. Moser, Arundhati S. Shanbhag, Federico Raue, Stanislav Frolov, Sebastian Palacio, Andreas Dengel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion Models (DMs) have disrupted the image Super-Resolution (SR) field
and further closed the gap between image quality and human perceptual
preferences. They are easy to train and can produce very high-quality samples
that exceed the realism of those produced by previous generative methods.
Despite their promising results, they also come with new challenges that need
further research: high computational demands, comparability, lack of
explainability, color shifts, and more. Unfortunately, entry into this field is
overwhelming because of the abundance of publications. To address this, we
provide a unified recount of the theoretical foundations underlying DMs applied
to image SR and offer a detailed analysis that underscores the unique
characteristics and methodologies within this domain, distinct from broader
existing reviews in the field. This survey articulates a cohesive understanding
of DM principles and explores current research avenues, including alternative
input domains, conditioning techniques, guidance mechanisms, corruption spaces,
and zero-shot learning approaches. By offering a detailed examination of the
evolution and current trends in image SR through the lens of DMs, this survey
sheds light on the existing challenges and charts potential future directions,
aiming to inspire further innovation in this rapidly advancing area.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2024-07-01T05:27:54.135944052Z">
            2024-07-01 05:27:54 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
